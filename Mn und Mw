{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM6viJ1X4oRLwr65SDqw9Ni",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elhamshaerirahbar-bot/my-colab-project/blob/main/Untitled13.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8S8VCECinI2",
        "outputId": "442f5205-7a69-49da-a8a5-1f42a4fc8e16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.14.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.74.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.8.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy pandas tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np, pandas as pd, re, unicodedata\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, callbacks\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.metrics import mean_absolute_percentage_error"
      ],
      "metadata": {
        "id": "0Syqe_mYiwTx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd, re, unicodedata\n",
        "from difflib import get_close_matches\n",
        "\n",
        "WANTED = ['factor A','factor B','factor C','factor D','Response 2 (Mw)', 'Response 1 (Mn)']\n",
        "\n",
        "def norm(s: str) -> str:\n",
        "    s = unicodedata.normalize(\"NFKC\", str(s))\n",
        "    s = s.replace(\"\\ufeff\",\"\").replace(\"\\u00a0\",\" \")\n",
        "    s = re.sub(r\"\\s+\",\" \", s).strip()\n",
        "    return s.lower()\n",
        "\n",
        "df = pd.read_csv('Python.csv', sep=';', encoding='utf-8-sig')\n",
        "\n",
        "\n",
        "name_map = {norm(c): c for c in df.columns}\n",
        "\n",
        "def map_col(wanted: str):\n",
        "    k = norm(wanted)\n",
        "    if k in name_map:\n",
        "        return name_map[k]\n",
        "\n",
        "    cand = get_close_matches(k, list(name_map.keys()), n=1, cutoff=0.7)\n",
        "    return name_map[cand[0]] if cand else None\n",
        "\n",
        "mapped = [(w, map_col(w)) for w in WANTED]\n",
        "missing = [w for w,c in mapped if c is None]\n",
        "cols    = [c for _,c in mapped if c is not None]\n",
        "\n",
        "print(f\"Missing: {missing}\")\n",
        "\n",
        "n = 5\n",
        "view = df[cols].head(n)\n",
        "try:\n",
        "    display(view)\n",
        "except NameError:\n",
        "    print(view.to_string(index=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "mQM3DjQNi0he",
        "outputId": "b018038a-6aec-4a81-e135-9ae3d186ce03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing: []\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   factor A  factor B  factor C  factor D       Response 2 (Mw)  \\\n",
              "0       110         7        50        10               1321.65   \n",
              "1        85         4        50        30               1321.66   \n",
              "2       101         1       500        60               1321.67   \n",
              "3        79         1       219        10               1321.68   \n",
              "4        50         1       500        20               1321.69   \n",
              "\n",
              "         Response 1 (Mn)  \n",
              "0                1127.19  \n",
              "1                1127.20  \n",
              "2                1127.21  \n",
              "3                1127.22  \n",
              "4                1127.23  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6ea41b3a-1996-405a-b8b7-1ff279cca2d7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>factor A</th>\n",
              "      <th>factor B</th>\n",
              "      <th>factor C</th>\n",
              "      <th>factor D</th>\n",
              "      <th>Response 2 (Mw)</th>\n",
              "      <th>Response 1 (Mn)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>110</td>\n",
              "      <td>7</td>\n",
              "      <td>50</td>\n",
              "      <td>10</td>\n",
              "      <td>1321.65</td>\n",
              "      <td>1127.19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>85</td>\n",
              "      <td>4</td>\n",
              "      <td>50</td>\n",
              "      <td>30</td>\n",
              "      <td>1321.66</td>\n",
              "      <td>1127.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>101</td>\n",
              "      <td>1</td>\n",
              "      <td>500</td>\n",
              "      <td>60</td>\n",
              "      <td>1321.67</td>\n",
              "      <td>1127.21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>79</td>\n",
              "      <td>1</td>\n",
              "      <td>219</td>\n",
              "      <td>10</td>\n",
              "      <td>1321.68</td>\n",
              "      <td>1127.22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "      <td>500</td>\n",
              "      <td>20</td>\n",
              "      <td>1321.69</td>\n",
              "      <td>1127.23</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6ea41b3a-1996-405a-b8b7-1ff279cca2d7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6ea41b3a-1996-405a-b8b7-1ff279cca2d7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6ea41b3a-1996-405a-b8b7-1ff279cca2d7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-d34d7136-853c-4ac3-a522-14fbcbc57aec\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d34d7136-853c-4ac3-a522-14fbcbc57aec')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-d34d7136-853c-4ac3-a522-14fbcbc57aec button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_bfd074eb-b91a-4487-a4f1-ab6b01719fc8\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('view')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_bfd074eb-b91a-4487-a4f1-ab6b01719fc8 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('view');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "view",
              "summary": "{\n  \"name\": \"view\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"factor A\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 23,\n        \"min\": 50,\n        \"max\": 110,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          85,\n          50,\n          101\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"factor B\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 1,\n        \"max\": 7,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          7,\n          4,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"factor C\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 226,\n        \"min\": 50,\n        \"max\": 500,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          50,\n          500,\n          219\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"factor D\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 20,\n        \"min\": 10,\n        \"max\": 60,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          30,\n          20,\n          10\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"     Response 2 (Mw)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.015811388300827515,\n        \"min\": 1321.65,\n        \"max\": 1321.69,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1321.66,\n          1321.69,\n          1321.67\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"      Response 1 (Mn)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.015811388300827515,\n        \"min\": 1127.19,\n        \"max\": 1127.23,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1127.2,\n          1127.23,\n          1127.21\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- pick columns via your map_col ----\n",
        "FEATURES = [map_col('factor A'), map_col('factor B'),\n",
        "            map_col('factor C'), map_col('factor D')]\n",
        "\n",
        "TARGETS  = [map_col('Response 1 (Mn)'), map_col('Response 2 (Mw)')]  # دو خروجی\n",
        "\n",
        "X = df[FEATURES].astype(float).to_numpy()   # shape: (n, 4)\n",
        "y = df[TARGETS].astype(float).to_numpy()    # shape: (n, 2)\n",
        "\n",
        "print(\"X:\", X.shape, \" y:\", y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Y9BwNofi4-T",
        "outputId": "92a5901e-bb2a-48a0-bd86-613b27ddaa22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X: (25, 4)  y: (25, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# X: (n, 4), y: (n, 2)  -> z.B. y = df[['Response 1 (Mn)','Response 2 (Mw)']].to_numpy()\n",
        "SEED = 55\n",
        "\n",
        "# 1) 20% Test\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.35, shuffle=True, random_state=SEED\n",
        ")\n",
        "# 2) 20% von Train für Val  -> insgesamt: Train 64%, Val 16%, Test 20%\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train, y_train, test_size=0.35, shuffle=True, random_state=SEED\n",
        ")\n",
        "\n",
        "print(X_train.shape, X_val.shape, X_test.shape)  # Kontrolle\n",
        "print(y_train.shape, y_val.shape, y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2AA1C6Wi77R",
        "outputId": "187af667-98c6-49ba-857a-f7dab735a70b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10, 4) (6, 4) (9, 4)\n",
            "(10, 2) (6, 2) (9, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "\n",
        "# X: (n,4), y: (n,2)  -> z.B. y[:,0]=Mn, y[:,1]=Mw\n",
        "assert y_train.ndim == 2 and y_train.shape[1] == 2, \"y muss (n,2) sein\"\n",
        "\n",
        "# --- X skalieren (nur auf Train fitten) ---\n",
        "x_scaler = StandardScaler().fit(X_train)\n",
        "X_train_z = x_scaler.transform(X_train)\n",
        "X_val_z   = x_scaler.transform(X_val)\n",
        "X_test_z  = x_scaler.transform(X_test)\n",
        "\n",
        "# --- y skalieren (für tanh: [-1,1]) -> spaltenweise, automatisch ---\n",
        "y_scaler  = MinMaxScaler(feature_range=(-1, 1)).fit(y_train)  # y_train: (n,2)\n",
        "y_train_s = y_scaler.transform(y_train)\n",
        "y_val_s   = y_scaler.transform(y_val)\n",
        "y_test_s  = y_scaler.transform(y_test)\n",
        "\n",
        "def inv_y(y_s):\n",
        "    \"\"\"Skalierung der Targets rückgängig machen -> echte Einheiten (Mn, Mw).\"\"\"\n",
        "    return y_scaler.inverse_transform(y_s)"
      ],
      "metadata": {
        "id": "WAeiXioBjGXg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ann = tf.keras.models.Sequential()"
      ],
      "metadata": {
        "id": "dBaYl7yWjKR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras import layers, regularizers, callbacks\n",
        "\n",
        "# Annahmen:\n",
        "# X_train_z, X_val_z, X_test_z = standardisierte Features\n",
        "# y_train_s, y_val_s, y_test_s = MinMax(-1,1) skalierte Targets, Form (n, 2)\n",
        "# inv_y(...)  -> macht die Skalierung von y rückgängig (zurück in echte Einheiten)\n",
        "\n",
        "assert y_train_s.ndim == 2 and y_train_s.shape[1] == 2, \"y muss (n,2) sein!\"\n",
        "\n",
        "model = Sequential([\n",
        "    layers.Dense(16, activation='relu',\n",
        "                 kernel_regularizer=regularizers.l2(1e-5),\n",
        "                 input_shape=(X_train_z.shape[1],)),\n",
        "    Dropout(0.1),\n",
        "        layers.Dense(8, activation='relu', kernel_regularizer=regularizers.l2(1e-5)),\n",
        "    Dropout(0.1),\n",
        "        layers.Dense(8, activation='relu', kernel_regularizer=regularizers.l2(1e-5)),\n",
        "    Dropout(0.1),\n",
        "    layers.Dense(2, activation='tanh')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae', 'mape'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otPjam8rjLqF",
        "outputId": "c6ef832c-fff8-46ad-d52a-389edaf598dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='mse', metrics=['mae', 'mape'])\n",
        "\n",
        "early = EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True)\n",
        "\n",
        "history = model.fit(\n",
        "    X_train_z, y_train_s,\n",
        "    validation_data=(X_val_z, y_val_s),\n",
        "    epochs=500, batch_size=16, verbose=1, callbacks=[early]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SiGI9kdjLoU",
        "outputId": "a56e7194-c800-4b0d-945d-a91716792ef7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 0.4703 - mae: 0.5892 - mape: 94.0726 - val_loss: 0.2191 - val_mae: 0.4106 - val_mape: 109.0286\n",
            "Epoch 2/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340ms/step - loss: 0.5254 - mae: 0.6263 - mape: 107.9062 - val_loss: 0.2182 - val_mae: 0.4101 - val_mape: 109.6387\n",
            "Epoch 3/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.5216 - mae: 0.6209 - mape: 97.0257 - val_loss: 0.2176 - val_mae: 0.4098 - val_mape: 110.0855\n",
            "Epoch 4/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 0.5895 - mae: 0.6735 - mape: 119.1619 - val_loss: 0.2171 - val_mae: 0.4095 - val_mape: 110.3172\n",
            "Epoch 5/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.5522 - mae: 0.6582 - mape: 118.7439 - val_loss: 0.2166 - val_mae: 0.4091 - val_mape: 110.6435\n",
            "Epoch 6/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.5221 - mae: 0.6218 - mape: 108.6447 - val_loss: 0.2162 - val_mae: 0.4089 - val_mape: 110.9795\n",
            "Epoch 7/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.5390 - mae: 0.6521 - mape: 118.8715 - val_loss: 0.2158 - val_mae: 0.4086 - val_mape: 111.3363\n",
            "Epoch 8/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.5657 - mae: 0.6771 - mape: 138.1758 - val_loss: 0.2154 - val_mae: 0.4083 - val_mape: 111.7031\n",
            "Epoch 9/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.4804 - mae: 0.5990 - mape: 96.9536 - val_loss: 0.2150 - val_mae: 0.4079 - val_mape: 112.0339\n",
            "Epoch 10/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.5444 - mae: 0.6246 - mape: 93.6112 - val_loss: 0.2145 - val_mae: 0.4074 - val_mape: 112.3310\n",
            "Epoch 11/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - loss: 0.5179 - mae: 0.6239 - mape: 102.1501 - val_loss: 0.2140 - val_mae: 0.4069 - val_mape: 112.6597\n",
            "Epoch 12/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.5191 - mae: 0.6300 - mape: 112.1231 - val_loss: 0.2134 - val_mae: 0.4063 - val_mape: 112.9575\n",
            "Epoch 13/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.4769 - mae: 0.5942 - mape: 95.8854 - val_loss: 0.2128 - val_mae: 0.4057 - val_mape: 113.2454\n",
            "Epoch 14/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.4865 - mae: 0.6121 - mape: 100.5765 - val_loss: 0.2120 - val_mae: 0.4050 - val_mape: 113.5939\n",
            "Epoch 15/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 0.5264 - mae: 0.6383 - mape: 112.2820 - val_loss: 0.2113 - val_mae: 0.4043 - val_mape: 113.9537\n",
            "Epoch 16/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.5333 - mae: 0.6519 - mape: 119.8247 - val_loss: 0.2105 - val_mae: 0.4035 - val_mape: 114.2987\n",
            "Epoch 17/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.5137 - mae: 0.6170 - mape: 101.8474 - val_loss: 0.2099 - val_mae: 0.4028 - val_mape: 114.6516\n",
            "Epoch 18/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.5187 - mae: 0.6303 - mape: 108.5554 - val_loss: 0.2095 - val_mae: 0.4024 - val_mape: 115.0205\n",
            "Epoch 19/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 0.5088 - mae: 0.6194 - mape: 99.9983 - val_loss: 0.2091 - val_mae: 0.4019 - val_mape: 115.3421\n",
            "Epoch 20/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.4616 - mae: 0.5965 - mape: 101.9118 - val_loss: 0.2087 - val_mae: 0.4014 - val_mape: 115.6847\n",
            "Epoch 21/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.4796 - mae: 0.6091 - mape: 111.2860 - val_loss: 0.2080 - val_mae: 0.4007 - val_mape: 116.0165\n",
            "Epoch 22/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.5201 - mae: 0.6185 - mape: 97.6413 - val_loss: 0.2074 - val_mae: 0.4000 - val_mape: 116.3202\n",
            "Epoch 23/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.5279 - mae: 0.6412 - mape: 107.0589 - val_loss: 0.2069 - val_mae: 0.3994 - val_mape: 116.6079\n",
            "Epoch 24/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.5156 - mae: 0.6523 - mape: 130.0480 - val_loss: 0.2065 - val_mae: 0.3988 - val_mape: 116.8947\n",
            "Epoch 25/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.4641 - mae: 0.5945 - mape: 99.4841 - val_loss: 0.2061 - val_mae: 0.3984 - val_mape: 117.2333\n",
            "Epoch 26/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - loss: 0.4446 - mae: 0.5918 - mape: 105.6910 - val_loss: 0.2058 - val_mae: 0.3979 - val_mape: 117.6120\n",
            "Epoch 27/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step - loss: 0.4859 - mae: 0.6129 - mape: 109.6316 - val_loss: 0.2056 - val_mae: 0.3977 - val_mape: 118.0179\n",
            "Epoch 28/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272ms/step - loss: 0.4667 - mae: 0.6052 - mape: 106.2765 - val_loss: 0.2053 - val_mae: 0.3972 - val_mape: 118.4016\n",
            "Epoch 29/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 246ms/step - loss: 0.4412 - mae: 0.5599 - mape: 81.1577 - val_loss: 0.2048 - val_mae: 0.3966 - val_mape: 118.7826\n",
            "Epoch 30/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - loss: 0.4649 - mae: 0.6035 - mape: 105.6503 - val_loss: 0.2042 - val_mae: 0.3960 - val_mape: 119.1946\n",
            "Epoch 31/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 314ms/step - loss: 0.4943 - mae: 0.6150 - mape: 102.5723 - val_loss: 0.2038 - val_mae: 0.3956 - val_mape: 119.9399\n",
            "Epoch 32/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - loss: 0.4863 - mae: 0.6285 - mape: 119.7847 - val_loss: 0.2035 - val_mae: 0.3953 - val_mape: 120.6377\n",
            "Epoch 33/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - loss: 0.4773 - mae: 0.6020 - mape: 106.5294 - val_loss: 0.2032 - val_mae: 0.3949 - val_mape: 121.2614\n",
            "Epoch 34/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - loss: 0.4324 - mae: 0.5699 - mape: 92.0753 - val_loss: 0.2030 - val_mae: 0.3945 - val_mape: 121.8893\n",
            "Epoch 35/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324ms/step - loss: 0.4179 - mae: 0.5744 - mape: 104.6250 - val_loss: 0.2027 - val_mae: 0.3941 - val_mape: 122.5616\n",
            "Epoch 36/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 0.4492 - mae: 0.5899 - mape: 100.2715 - val_loss: 0.2026 - val_mae: 0.3938 - val_mape: 123.2349\n",
            "Epoch 37/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.4340 - mae: 0.5633 - mape: 83.8907 - val_loss: 0.2025 - val_mae: 0.3936 - val_mape: 123.9464\n",
            "Epoch 38/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.4596 - mae: 0.5863 - mape: 105.8178 - val_loss: 0.2026 - val_mae: 0.3935 - val_mape: 124.6840\n",
            "Epoch 39/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.4034 - mae: 0.5377 - mape: 81.3400 - val_loss: 0.2026 - val_mae: 0.3934 - val_mape: 125.3696\n",
            "Epoch 40/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 0.4083 - mae: 0.5591 - mape: 94.6214 - val_loss: 0.2025 - val_mae: 0.3931 - val_mape: 126.0600\n",
            "Epoch 41/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 0.3977 - mae: 0.5578 - mape: 95.8464 - val_loss: 0.2025 - val_mae: 0.3929 - val_mape: 126.6939\n",
            "Epoch 42/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step - loss: 0.4132 - mae: 0.5587 - mape: 97.5807 - val_loss: 0.2024 - val_mae: 0.3925 - val_mape: 127.2792\n",
            "Epoch 43/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.4550 - mae: 0.5862 - mape: 112.3120 - val_loss: 0.2023 - val_mae: 0.3922 - val_mape: 127.8773\n",
            "Epoch 44/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.4371 - mae: 0.5863 - mape: 103.5447 - val_loss: 0.2025 - val_mae: 0.3920 - val_mape: 128.4586\n",
            "Epoch 45/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 0.3820 - mae: 0.5369 - mape: 94.6692 - val_loss: 0.2025 - val_mae: 0.3918 - val_mape: 129.0574\n",
            "Epoch 46/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.4250 - mae: 0.5590 - mape: 87.9619 - val_loss: 0.2025 - val_mae: 0.3914 - val_mape: 129.6019\n",
            "Epoch 47/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.3695 - mae: 0.5416 - mape: 115.1861 - val_loss: 0.2023 - val_mae: 0.3908 - val_mape: 130.1304\n",
            "Epoch 48/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 0.4079 - mae: 0.5628 - mape: 98.5513 - val_loss: 0.2021 - val_mae: 0.3904 - val_mape: 130.6257\n",
            "Epoch 49/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - loss: 0.3884 - mae: 0.5355 - mape: 96.5480 - val_loss: 0.2019 - val_mae: 0.3898 - val_mape: 131.0772\n",
            "Epoch 50/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.4187 - mae: 0.5679 - mape: 97.8745 - val_loss: 0.2016 - val_mae: 0.3892 - val_mape: 131.5024\n",
            "Epoch 51/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.3961 - mae: 0.5480 - mape: 100.9112 - val_loss: 0.2012 - val_mae: 0.3885 - val_mape: 131.9070\n",
            "Epoch 52/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.4106 - mae: 0.5484 - mape: 95.9296 - val_loss: 0.2008 - val_mae: 0.3878 - val_mape: 132.2968\n",
            "Epoch 53/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.3907 - mae: 0.5423 - mape: 94.7219 - val_loss: 0.2003 - val_mae: 0.3871 - val_mape: 132.6832\n",
            "Epoch 54/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.4069 - mae: 0.5515 - mape: 87.8663 - val_loss: 0.1999 - val_mae: 0.3864 - val_mape: 133.0886\n",
            "Epoch 55/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.4144 - mae: 0.5667 - mape: 108.3704 - val_loss: 0.1995 - val_mae: 0.3857 - val_mape: 133.5282\n",
            "Epoch 56/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.3992 - mae: 0.5427 - mape: 89.7557 - val_loss: 0.1990 - val_mae: 0.3850 - val_mape: 133.9464\n",
            "Epoch 57/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.3786 - mae: 0.5452 - mape: 106.2839 - val_loss: 0.1987 - val_mae: 0.3844 - val_mape: 134.3655\n",
            "Epoch 58/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.3949 - mae: 0.5593 - mape: 118.9781 - val_loss: 0.1984 - val_mae: 0.3838 - val_mape: 134.7968\n",
            "Epoch 59/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.4077 - mae: 0.5527 - mape: 101.0055 - val_loss: 0.1981 - val_mae: 0.3832 - val_mape: 135.1729\n",
            "Epoch 60/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.4398 - mae: 0.5802 - mape: 102.6893 - val_loss: 0.1978 - val_mae: 0.3826 - val_mape: 135.6055\n",
            "Epoch 61/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.4068 - mae: 0.5622 - mape: 100.3710 - val_loss: 0.1977 - val_mae: 0.3821 - val_mape: 136.0006\n",
            "Epoch 62/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.3688 - mae: 0.5284 - mape: 87.5476 - val_loss: 0.1977 - val_mae: 0.3816 - val_mape: 136.4256\n",
            "Epoch 63/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.3498 - mae: 0.5066 - mape: 89.3929 - val_loss: 0.1976 - val_mae: 0.3811 - val_mape: 136.8745\n",
            "Epoch 64/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.3539 - mae: 0.5263 - mape: 108.1130 - val_loss: 0.1974 - val_mae: 0.3805 - val_mape: 137.3177\n",
            "Epoch 65/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.3839 - mae: 0.5235 - mape: 105.7679 - val_loss: 0.1973 - val_mae: 0.3800 - val_mape: 137.8145\n",
            "Epoch 66/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 0.3407 - mae: 0.5205 - mape: 115.9140 - val_loss: 0.1971 - val_mae: 0.3793 - val_mape: 138.3450\n",
            "Epoch 67/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.3394 - mae: 0.5286 - mape: 115.3419 - val_loss: 0.1969 - val_mae: 0.3787 - val_mape: 138.8932\n",
            "Epoch 68/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.4036 - mae: 0.5642 - mape: 106.8570 - val_loss: 0.1968 - val_mae: 0.3781 - val_mape: 139.4630\n",
            "Epoch 69/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.3648 - mae: 0.5267 - mape: 96.6191 - val_loss: 0.1966 - val_mae: 0.3775 - val_mape: 140.0522\n",
            "Epoch 70/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.3467 - mae: 0.5119 - mape: 105.1631 - val_loss: 0.1964 - val_mae: 0.3764 - val_mape: 140.4483\n",
            "Epoch 71/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.3114 - mae: 0.5029 - mape: 117.2995 - val_loss: 0.1960 - val_mae: 0.3753 - val_mape: 140.8499\n",
            "Epoch 72/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.3374 - mae: 0.4872 - mape: 109.8370 - val_loss: 0.1957 - val_mae: 0.3751 - val_mape: 141.5715\n",
            "Epoch 73/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.3887 - mae: 0.5388 - mape: 106.3730 - val_loss: 0.1954 - val_mae: 0.3750 - val_mape: 142.3561\n",
            "Epoch 74/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.4024 - mae: 0.5232 - mape: 77.6775 - val_loss: 0.1950 - val_mae: 0.3748 - val_mape: 143.1081\n",
            "Epoch 75/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.3505 - mae: 0.5265 - mape: 122.6549 - val_loss: 0.1946 - val_mae: 0.3746 - val_mape: 143.8702\n",
            "Epoch 76/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.3773 - mae: 0.5432 - mape: 130.5083 - val_loss: 0.1941 - val_mae: 0.3743 - val_mape: 144.6360\n",
            "Epoch 77/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.2868 - mae: 0.4589 - mape: 82.1511 - val_loss: 0.1936 - val_mae: 0.3740 - val_mape: 145.4303\n",
            "Epoch 78/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.3566 - mae: 0.5067 - mape: 107.2746 - val_loss: 0.1933 - val_mae: 0.3738 - val_mape: 146.2107\n",
            "Epoch 79/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.3591 - mae: 0.5105 - mape: 114.4099 - val_loss: 0.1929 - val_mae: 0.3736 - val_mape: 146.9748\n",
            "Epoch 80/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.2962 - mae: 0.4497 - mape: 78.2169 - val_loss: 0.1924 - val_mae: 0.3733 - val_mape: 147.7589\n",
            "Epoch 81/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.3002 - mae: 0.4755 - mape: 111.9356 - val_loss: 0.1920 - val_mae: 0.3730 - val_mape: 148.6131\n",
            "Epoch 82/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.3179 - mae: 0.4975 - mape: 115.6886 - val_loss: 0.1916 - val_mae: 0.3728 - val_mape: 149.5297\n",
            "Epoch 83/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.3342 - mae: 0.4912 - mape: 107.7787 - val_loss: 0.1913 - val_mae: 0.3726 - val_mape: 150.3671\n",
            "Epoch 84/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.3650 - mae: 0.5032 - mape: 103.6976 - val_loss: 0.1910 - val_mae: 0.3724 - val_mape: 151.1494\n",
            "Epoch 85/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.3147 - mae: 0.4925 - mape: 113.1384 - val_loss: 0.1907 - val_mae: 0.3722 - val_mape: 151.8574\n",
            "Epoch 86/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.3676 - mae: 0.5278 - mape: 118.9475 - val_loss: 0.1905 - val_mae: 0.3721 - val_mape: 152.6694\n",
            "Epoch 87/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.4337 - mae: 0.5597 - mape: 133.0349 - val_loss: 0.1907 - val_mae: 0.3724 - val_mape: 154.1764\n",
            "Epoch 88/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.3106 - mae: 0.4875 - mape: 106.1359 - val_loss: 0.1909 - val_mae: 0.3727 - val_mape: 155.8343\n",
            "Epoch 89/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.4263 - mae: 0.5244 - mape: 97.5620 - val_loss: 0.1912 - val_mae: 0.3729 - val_mape: 157.2313\n",
            "Epoch 90/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.3094 - mae: 0.4757 - mape: 72.3317 - val_loss: 0.1914 - val_mae: 0.3729 - val_mape: 158.6869\n",
            "Epoch 91/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.2591 - mae: 0.4402 - mape: 100.5935 - val_loss: 0.1915 - val_mae: 0.3728 - val_mape: 160.1364\n",
            "Epoch 92/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.3137 - mae: 0.4838 - mape: 114.9886 - val_loss: 0.1916 - val_mae: 0.3727 - val_mape: 161.5597\n",
            "Epoch 93/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.3160 - mae: 0.5057 - mape: 123.5507 - val_loss: 0.1919 - val_mae: 0.3727 - val_mape: 162.8261\n",
            "Epoch 94/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.2820 - mae: 0.4705 - mape: 147.2683 - val_loss: 0.1919 - val_mae: 0.3726 - val_mape: 163.9887\n",
            "Epoch 95/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.4038 - mae: 0.5466 - mape: 126.7743 - val_loss: 0.1921 - val_mae: 0.3725 - val_mape: 164.8985\n",
            "Epoch 96/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 0.3521 - mae: 0.4826 - mape: 106.8716 - val_loss: 0.1924 - val_mae: 0.3726 - val_mape: 165.6050\n",
            "Epoch 97/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.3108 - mae: 0.4869 - mape: 127.0278 - val_loss: 0.1927 - val_mae: 0.3727 - val_mape: 166.1280\n",
            "Epoch 98/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.2630 - mae: 0.4410 - mape: 104.5265 - val_loss: 0.1929 - val_mae: 0.3728 - val_mape: 166.6178\n",
            "Epoch 99/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.2792 - mae: 0.4471 - mape: 94.0344 - val_loss: 0.1932 - val_mae: 0.3729 - val_mape: 167.2219\n",
            "Epoch 100/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.3094 - mae: 0.4886 - mape: 122.3539 - val_loss: 0.1933 - val_mae: 0.3729 - val_mape: 167.6920\n",
            "Epoch 101/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.3185 - mae: 0.4813 - mape: 108.4187 - val_loss: 0.1935 - val_mae: 0.3729 - val_mape: 168.0963\n",
            "Epoch 102/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.3355 - mae: 0.5336 - mape: 130.2888 - val_loss: 0.1936 - val_mae: 0.3728 - val_mape: 168.4303\n",
            "Epoch 103/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.3061 - mae: 0.4956 - mape: 125.5924 - val_loss: 0.1937 - val_mae: 0.3728 - val_mape: 168.9713\n",
            "Epoch 104/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.2920 - mae: 0.4762 - mape: 111.4308 - val_loss: 0.1937 - val_mae: 0.3734 - val_mape: 169.8361\n",
            "Epoch 105/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.2766 - mae: 0.4733 - mape: 124.1470 - val_loss: 0.1940 - val_mae: 0.3744 - val_mape: 171.0203\n",
            "Epoch 106/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.2735 - mae: 0.4785 - mape: 127.3176 - val_loss: 0.1942 - val_mae: 0.3754 - val_mape: 172.2570\n",
            "Epoch 107/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.2188 - mae: 0.4025 - mape: 88.5159 - val_loss: 0.1943 - val_mae: 0.3763 - val_mape: 173.4729\n",
            "Epoch 108/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.2686 - mae: 0.4555 - mape: 107.1754 - val_loss: 0.1944 - val_mae: 0.3772 - val_mape: 174.8320\n",
            "Epoch 109/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.2532 - mae: 0.4273 - mape: 104.5875 - val_loss: 0.1943 - val_mae: 0.3780 - val_mape: 176.2188\n",
            "Epoch 110/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.2615 - mae: 0.4736 - mape: 156.6888 - val_loss: 0.1943 - val_mae: 0.3787 - val_mape: 177.6614\n",
            "Epoch 111/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.3078 - mae: 0.4764 - mape: 120.9436 - val_loss: 0.1944 - val_mae: 0.3795 - val_mape: 179.2014\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Vorhersagen (zuerst im skalierten Raum, dann zurück in echte Einheiten)\n",
        "y_hat_train_s = model.predict(X_train_z, verbose=1)\n",
        "y_hat_val_s   = model.predict(X_val_z,   verbose=1)\n",
        "y_hat_test_s  = model.predict(X_test_z,  verbose=1)\n",
        "\n",
        "y_hat_train = inv_y(y_hat_train_s)\n",
        "y_hat_val   = inv_y(y_hat_val_s)\n",
        "y_hat_test  = inv_y(y_hat_test_s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLV4VDdDjLmG",
        "outputId": "e06804a3-2b4d-4bc0-ad9d-206f2ab4cdb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error\n",
        "\n",
        "def report_2out(name, yt, yp, labels=(\"Mn\", \"Mw\")):\n",
        "    # yt و yp باید (n,2) باشن\n",
        "    for i, label in enumerate(labels):\n",
        "        y_true = yt[:, i].reshape(-1)\n",
        "        y_pred = yp[:, i].reshape(-1)\n",
        "\n",
        "        mae  = mean_absolute_error(y_true, y_pred)\n",
        "        mse  = mean_squared_error(y_true, y_pred)\n",
        "        r2   = r2_score(y_true, y_pred)\n",
        "        mape = mean_absolute_percentage_error(y_true, y_pred)\n",
        "\n",
        "        print(f\"[{name}] {label}: MAE={mae:.6f}  MSE={mse:.6f}  R²={r2:.4f}  MAPE={mape:.6f}\")"
      ],
      "metadata": {
        "id": "xeWwgdE0jLkG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "report_2out(\"Train\", y_train, y_hat_train)\n",
        "report_2out(\"Val  \", y_val,   y_hat_val)\n",
        "report_2out(\"Test \", y_test,  y_hat_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptHevHX-jLh_",
        "outputId": "ca2a17b0-6b4b-4e41-8e90-50bde0ab8b5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train] Mn: MAE=0.052544  MSE=0.003653  R²=0.3875  MAPE=0.000047\n",
            "[Train] Mw: MAE=0.057105  MSE=0.004172  R²=0.3004  MAPE=0.000043\n",
            "[Val  ] Mn: MAE=0.043195  MSE=0.002584  R²=0.2043  MAPE=0.000038\n",
            "[Val  ] Mw: MAE=0.042372  MSE=0.002449  R²=0.2458  MAPE=0.000032\n",
            "[Test ] Mn: MAE=0.067030  MSE=0.006081  R²=-0.5479  MAPE=0.000059\n",
            "[Test ] Mw: MAE=0.063862  MSE=0.005377  R²=-0.3688  MAPE=0.000048\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install matplotlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGS2LHAAjLfx",
        "outputId": "c5ef78f4-c870-4658-9a4c-388ffdd530b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.59.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "ZovIuGAXjLd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np, pandas as pd\n",
        "\n",
        "def make_table_multi(split, y_true, y_pred, target_names=(\"Mn\",\"Mw\"), n=None):\n",
        "    \"\"\"\n",
        "    Baut eine Tabelle für 2 (oder mehr) Outputs.\n",
        "    y_true, y_pred: Form (n, k)  -> k = Anzahl Outputs (hier 2: Mn, Mw)\n",
        "    pct_error in Prozent (0–100). Für Anteil (0–1) unten scale=1 nutzen.\n",
        "    \"\"\"\n",
        "    y_true = np.asarray(y_true)\n",
        "    y_pred = np.asarray(y_pred)\n",
        "    assert y_true.shape == y_pred.shape and y_true.ndim == 2, \"y muss (n,k) sein\"\n",
        "    k = y_true.shape[1]\n",
        "    assert k == len(target_names), \"target_names-Länge passt nicht zu y.shape[1]\"\n",
        "\n",
        "    parts = []\n",
        "    for j, name in enumerate(target_names):\n",
        "        df = pd.DataFrame({\n",
        "            \"split\":     split,\n",
        "            \"target\":    name,\n",
        "            \"actual\":    y_true[:, j],\n",
        "            \"predicted\": y_pred[:, j],\n",
        "        })\n",
        "        df[\"residual\"]  = df[\"actual\"] - df[\"predicted\"]\n",
        "        df[\"abs_error\"] = df[\"residual\"].abs()\n",
        "        # Prozent-Fehler (×100). Wenn du Bruchteil willst, ersetze 100 durch 1.\n",
        "        df[\"pct_error\"] = 100 * df[\"abs_error\"] / df[\"actual\"].abs().clip(lower=1e-8)\n",
        "        parts.append(df if n is None else df.head(n))\n",
        "    return pd.concat(parts, ignore_index=True)\n",
        "\n",
        "# Beispiel-Nutzung (y_* und y_hat_* haben Form (n,2) = [Mn, Mw]):\n",
        "tbl_train = make_table_multi(\"Train\", y_train, y_hat_train, target_names=(\"Mn\",\"Mw\"))\n",
        "tbl_val   = make_table_multi(\"Val\",   y_val,   y_hat_val,   target_names=(\"Mn\",\"Mw\"))\n",
        "tbl_test  = make_table_multi(\"Test\",  y_test,  y_hat_test,  target_names=(\"Mn\",\"Mw\"))\n",
        "\n",
        "tbl_all = pd.concat([tbl_train, tbl_val, tbl_test], ignore_index=True)\n",
        "print(tbl_all.to_string(index=False))   # in Notebook: display(tbl_all)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-ZWVSsjjLby",
        "outputId": "224eda97-b2d7-4034-eb93-9c2c243abade"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "split target  actual   predicted  residual  abs_error  pct_error\n",
            "Train     Mn 1127.38 1127.354736  0.025264   0.025264   0.002241\n",
            "Train     Mn 1127.37 1127.343384  0.026616   0.026616   0.002361\n",
            "Train     Mn 1127.42 1127.344971  0.075029   0.075029   0.006655\n",
            "Train     Mn 1127.40 1127.354492  0.045508   0.045508   0.004037\n",
            "Train     Mn 1127.32 1127.338379 -0.018379   0.018379   0.001630\n",
            "Train     Mn 1127.43 1127.359131  0.070869   0.070869   0.006286\n",
            "Train     Mn 1127.22 1127.310547 -0.090547   0.090547   0.008033\n",
            "Train     Mn 1127.33 1127.312256  0.017744   0.017744   0.001574\n",
            "Train     Mn 1127.20 1127.305298 -0.105298   0.105298   0.009342\n",
            "Train     Mn 1127.27 1127.320190 -0.050190   0.050190   0.004452\n",
            "Train     Mw 1321.84 1321.799561  0.040439   0.040439   0.003059\n",
            "Train     Mw 1321.83 1321.795654  0.034346   0.034346   0.002598\n",
            "Train     Mw 1321.88 1321.797363  0.082637   0.082637   0.006251\n",
            "Train     Mw 1321.86 1321.802246  0.057754   0.057754   0.004369\n",
            "Train     Mw 1321.78 1321.794434 -0.014434   0.014434   0.001092\n",
            "Train     Mw 1321.89 1321.808838  0.081162   0.081162   0.006140\n",
            "Train     Mw 1321.68 1321.769165 -0.089165   0.089165   0.006746\n",
            "Train     Mw 1321.79 1321.770020  0.019980   0.019980   0.001512\n",
            "Train     Mw 1321.66 1321.768555 -0.108555   0.108555   0.008214\n",
            "Train     Mw 1321.73 1321.772583 -0.042583   0.042583   0.003222\n",
            "  Val     Mn 1127.35 1127.338379  0.011621   0.011621   0.001031\n",
            "  Val     Mn 1127.41 1127.337891  0.072109   0.072109   0.006396\n",
            "  Val     Mn 1127.24 1127.312256 -0.072256   0.072256   0.006410\n",
            "  Val     Mn 1127.26 1127.322632 -0.062632   0.062632   0.005556\n",
            "  Val     Mn 1127.34 1127.350220 -0.010220   0.010220   0.000907\n",
            "  Val     Mn 1127.31 1127.340332 -0.030332   0.030332   0.002691\n",
            "  Val     Mw 1321.81 1321.794434  0.015566   0.015566   0.001178\n",
            "  Val     Mw 1321.87 1321.797241  0.072759   0.072759   0.005504\n",
            "  Val     Mw 1321.70 1321.770020 -0.070020   0.070020   0.005298\n",
            "  Val     Mw 1321.72 1321.779175 -0.059175   0.059175   0.004477\n",
            "  Val     Mw 1321.80 1321.787964  0.012036   0.012036   0.000911\n",
            "  Val     Mw 1321.77 1321.794678 -0.024678   0.024678   0.001867\n",
            " Test     Mn 1127.25 1127.300171 -0.050171   0.050171   0.004451\n",
            " Test     Mn 1127.23 1127.344971 -0.114971   0.114971   0.010199\n",
            " Test     Mn 1127.30 1127.331665 -0.031665   0.031665   0.002809\n",
            " Test     Mn 1127.28 1127.354492 -0.074492   0.074492   0.006608\n",
            " Test     Mn 1127.21 1127.350220 -0.140220   0.140220   0.012440\n",
            " Test     Mn 1127.36 1127.324097  0.035903   0.035903   0.003185\n",
            " Test     Mn 1127.19 1127.282227 -0.092227   0.092227   0.008182\n",
            " Test     Mn 1127.29 1127.299927 -0.009927   0.009927   0.000881\n",
            " Test     Mn 1127.39 1127.336304  0.053696   0.053696   0.004763\n",
            " Test     Mw 1321.71 1321.770386 -0.060386   0.060386   0.004569\n",
            " Test     Mw 1321.69 1321.797363 -0.107363   0.107363   0.008123\n",
            " Test     Mw 1321.76 1321.784668 -0.024668   0.024668   0.001866\n",
            " Test     Mw 1321.74 1321.802246 -0.062246   0.062246   0.004709\n",
            " Test     Mw 1321.67 1321.787964 -0.117964   0.117964   0.008925\n",
            " Test     Mw 1321.82 1321.782349  0.037651   0.037651   0.002848\n",
            " Test     Mw 1321.65 1321.750000 -0.100000   0.100000   0.007566\n",
            " Test     Mw 1321.75 1321.756470 -0.006470   0.006470   0.000489\n",
            " Test     Mw 1321.85 1321.791992  0.058008   0.058008   0.004388\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- 0) Reproducibility / Determinism ----\n",
        "import os, random, numpy as np, tensorflow as tf\n",
        "\n",
        "SEED = 42\n",
        "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
        "os.environ[\"TF_DETERMINISTIC_OPS\"] = \"1\"\n",
        "\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "try:\n",
        "    tf.keras.utils.set_random_seed(SEED)\n",
        "    tf.config.experimental.enable_op_determinism(True)\n",
        "except Exception:\n",
        "    pass"
      ],
      "metadata": {
        "id": "WqltLwhLjLZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- 5) Activation (Transfer Function) sweep on hidden layers ----\n",
        "import random, numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, optimizers\n",
        "\n",
        "activations = ['relu', 'tanh', 'sigmoid', 'softplus']\n",
        "labels      = ['ReLU', 'Tanh', 'Sigmoid', 'Softplus']\n",
        "\n",
        "val_mse_real  = []\n",
        "test_mse_real = []"
      ],
      "metadata": {
        "id": "t9miTBP8jLXi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for act in activations:\n",
        "\n",
        "    tf.keras.backend.clear_session()\n",
        "    np.random.seed(SEED); random.seed(SEED); tf.random.set_seed(SEED)\n",
        "\n",
        "    model = tf.keras.Sequential([\n",
        "        layers.Input(shape=(X_train_z.shape[1],)),\n",
        "        layers.Dense(16, activation=act),\n",
        "        layers.Dense(2,  activation='tanh')     # ⬅️ zwei Ausgänge: [Mn, Mw]\n",
        "    ])\n",
        "    model.compile(optimizer=optimizers.Adam(learning_rate=1e-3),\n",
        "                  loss='mse', metrics=['mae'])\n",
        "\n",
        "    history = model.fit(\n",
        "        X_train_z, y_train_s,                    # y_train_s: (n,2)\n",
        "        validation_data=(X_val_z, y_val_s),\n",
        "        epochs=200, batch_size=16, shuffle=True, verbose=1,\n",
        "        callbacks=[]\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJDODufEBSbC",
        "outputId": "cfa4e88f-ea10-4467-fde0-b49ff2fbd8ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - loss: 0.9160 - mae: 0.8158 - val_loss: 0.2898 - val_mae: 0.4254\n",
            "Epoch 2/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421ms/step - loss: 0.9092 - mae: 0.8133 - val_loss: 0.2897 - val_mae: 0.4243\n",
            "Epoch 3/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 309ms/step - loss: 0.9025 - mae: 0.8107 - val_loss: 0.2897 - val_mae: 0.4233\n",
            "Epoch 4/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 315ms/step - loss: 0.8957 - mae: 0.8080 - val_loss: 0.2897 - val_mae: 0.4222\n",
            "Epoch 5/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250ms/step - loss: 0.8889 - mae: 0.8054 - val_loss: 0.2897 - val_mae: 0.4210\n",
            "Epoch 6/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293ms/step - loss: 0.8822 - mae: 0.8027 - val_loss: 0.2897 - val_mae: 0.4199\n",
            "Epoch 7/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step - loss: 0.8754 - mae: 0.8001 - val_loss: 0.2898 - val_mae: 0.4188\n",
            "Epoch 8/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.8686 - mae: 0.7974 - val_loss: 0.2899 - val_mae: 0.4185\n",
            "Epoch 9/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.8618 - mae: 0.7946 - val_loss: 0.2900 - val_mae: 0.4186\n",
            "Epoch 10/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.8551 - mae: 0.7919 - val_loss: 0.2901 - val_mae: 0.4186\n",
            "Epoch 11/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 0.8483 - mae: 0.7892 - val_loss: 0.2902 - val_mae: 0.4187\n",
            "Epoch 12/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.8418 - mae: 0.7865 - val_loss: 0.2904 - val_mae: 0.4187\n",
            "Epoch 13/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 0.8352 - mae: 0.7837 - val_loss: 0.2906 - val_mae: 0.4187\n",
            "Epoch 14/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.8287 - mae: 0.7810 - val_loss: 0.2908 - val_mae: 0.4188\n",
            "Epoch 15/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.8221 - mae: 0.7783 - val_loss: 0.2911 - val_mae: 0.4188\n",
            "Epoch 16/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 0.8156 - mae: 0.7755 - val_loss: 0.2913 - val_mae: 0.4188\n",
            "Epoch 17/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.8091 - mae: 0.7728 - val_loss: 0.2917 - val_mae: 0.4189\n",
            "Epoch 18/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.8026 - mae: 0.7700 - val_loss: 0.2920 - val_mae: 0.4189\n",
            "Epoch 19/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.7961 - mae: 0.7673 - val_loss: 0.2924 - val_mae: 0.4190\n",
            "Epoch 20/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.7897 - mae: 0.7645 - val_loss: 0.2928 - val_mae: 0.4191\n",
            "Epoch 21/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.7833 - mae: 0.7618 - val_loss: 0.2933 - val_mae: 0.4192\n",
            "Epoch 22/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.7768 - mae: 0.7590 - val_loss: 0.2938 - val_mae: 0.4193\n",
            "Epoch 23/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.7704 - mae: 0.7562 - val_loss: 0.2943 - val_mae: 0.4194\n",
            "Epoch 24/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.7641 - mae: 0.7534 - val_loss: 0.2948 - val_mae: 0.4196\n",
            "Epoch 25/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.7577 - mae: 0.7506 - val_loss: 0.2955 - val_mae: 0.4198\n",
            "Epoch 26/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.7514 - mae: 0.7477 - val_loss: 0.2961 - val_mae: 0.4200\n",
            "Epoch 27/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.7451 - mae: 0.7449 - val_loss: 0.2968 - val_mae: 0.4203\n",
            "Epoch 28/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.7388 - mae: 0.7420 - val_loss: 0.2976 - val_mae: 0.4205\n",
            "Epoch 29/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.7325 - mae: 0.7391 - val_loss: 0.2984 - val_mae: 0.4209\n",
            "Epoch 30/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 0.7261 - mae: 0.7362 - val_loss: 0.2992 - val_mae: 0.4212\n",
            "Epoch 31/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.7198 - mae: 0.7333 - val_loss: 0.3001 - val_mae: 0.4216\n",
            "Epoch 32/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.7135 - mae: 0.7303 - val_loss: 0.3010 - val_mae: 0.4220\n",
            "Epoch 33/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.7072 - mae: 0.7273 - val_loss: 0.3020 - val_mae: 0.4225\n",
            "Epoch 34/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 0.7010 - mae: 0.7244 - val_loss: 0.3030 - val_mae: 0.4230\n",
            "Epoch 35/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - loss: 0.6947 - mae: 0.7214 - val_loss: 0.3041 - val_mae: 0.4235\n",
            "Epoch 36/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306ms/step - loss: 0.6885 - mae: 0.7184 - val_loss: 0.3052 - val_mae: 0.4241\n",
            "Epoch 37/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237ms/step - loss: 0.6823 - mae: 0.7154 - val_loss: 0.3063 - val_mae: 0.4248\n",
            "Epoch 38/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.6761 - mae: 0.7124 - val_loss: 0.3074 - val_mae: 0.4260\n",
            "Epoch 39/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 0.6699 - mae: 0.7093 - val_loss: 0.3086 - val_mae: 0.4272\n",
            "Epoch 40/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325ms/step - loss: 0.6637 - mae: 0.7063 - val_loss: 0.3098 - val_mae: 0.4284\n",
            "Epoch 41/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step - loss: 0.6576 - mae: 0.7033 - val_loss: 0.3110 - val_mae: 0.4296\n",
            "Epoch 42/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340ms/step - loss: 0.6515 - mae: 0.7002 - val_loss: 0.3123 - val_mae: 0.4308\n",
            "Epoch 43/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296ms/step - loss: 0.6454 - mae: 0.6972 - val_loss: 0.3135 - val_mae: 0.4320\n",
            "Epoch 44/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step - loss: 0.6394 - mae: 0.6941 - val_loss: 0.3148 - val_mae: 0.4332\n",
            "Epoch 45/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 327ms/step - loss: 0.6333 - mae: 0.6911 - val_loss: 0.3161 - val_mae: 0.4344\n",
            "Epoch 46/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step - loss: 0.6273 - mae: 0.6880 - val_loss: 0.3174 - val_mae: 0.4355\n",
            "Epoch 47/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.6214 - mae: 0.6849 - val_loss: 0.3187 - val_mae: 0.4367\n",
            "Epoch 48/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 0.6154 - mae: 0.6819 - val_loss: 0.3201 - val_mae: 0.4378\n",
            "Epoch 49/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.6095 - mae: 0.6788 - val_loss: 0.3215 - val_mae: 0.4390\n",
            "Epoch 50/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.6037 - mae: 0.6757 - val_loss: 0.3229 - val_mae: 0.4401\n",
            "Epoch 51/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.5978 - mae: 0.6727 - val_loss: 0.3243 - val_mae: 0.4412\n",
            "Epoch 52/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.5920 - mae: 0.6696 - val_loss: 0.3257 - val_mae: 0.4423\n",
            "Epoch 53/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 0.5863 - mae: 0.6665 - val_loss: 0.3272 - val_mae: 0.4435\n",
            "Epoch 54/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 0.5805 - mae: 0.6634 - val_loss: 0.3287 - val_mae: 0.4446\n",
            "Epoch 55/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 0.5746 - mae: 0.6602 - val_loss: 0.3302 - val_mae: 0.4458\n",
            "Epoch 56/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.5688 - mae: 0.6570 - val_loss: 0.3317 - val_mae: 0.4470\n",
            "Epoch 57/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.5629 - mae: 0.6538 - val_loss: 0.3333 - val_mae: 0.4482\n",
            "Epoch 58/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - loss: 0.5570 - mae: 0.6505 - val_loss: 0.3349 - val_mae: 0.4494\n",
            "Epoch 59/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.5512 - mae: 0.6472 - val_loss: 0.3365 - val_mae: 0.4506\n",
            "Epoch 60/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 0.5454 - mae: 0.6440 - val_loss: 0.3382 - val_mae: 0.4518\n",
            "Epoch 61/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.5396 - mae: 0.6407 - val_loss: 0.3399 - val_mae: 0.4531\n",
            "Epoch 62/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.5338 - mae: 0.6373 - val_loss: 0.3416 - val_mae: 0.4543\n",
            "Epoch 63/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.5281 - mae: 0.6340 - val_loss: 0.3433 - val_mae: 0.4555\n",
            "Epoch 64/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.5225 - mae: 0.6307 - val_loss: 0.3450 - val_mae: 0.4567\n",
            "Epoch 65/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - loss: 0.5169 - mae: 0.6274 - val_loss: 0.3467 - val_mae: 0.4580\n",
            "Epoch 66/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.5113 - mae: 0.6241 - val_loss: 0.3485 - val_mae: 0.4592\n",
            "Epoch 67/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.5058 - mae: 0.6208 - val_loss: 0.3502 - val_mae: 0.4605\n",
            "Epoch 68/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - loss: 0.5003 - mae: 0.6174 - val_loss: 0.3520 - val_mae: 0.4617\n",
            "Epoch 69/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.4949 - mae: 0.6141 - val_loss: 0.3537 - val_mae: 0.4629\n",
            "Epoch 70/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.4896 - mae: 0.6108 - val_loss: 0.3554 - val_mae: 0.4640\n",
            "Epoch 71/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.4843 - mae: 0.6075 - val_loss: 0.3572 - val_mae: 0.4652\n",
            "Epoch 72/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 0.4791 - mae: 0.6042 - val_loss: 0.3590 - val_mae: 0.4663\n",
            "Epoch 73/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - loss: 0.4739 - mae: 0.6009 - val_loss: 0.3607 - val_mae: 0.4674\n",
            "Epoch 74/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.4688 - mae: 0.5976 - val_loss: 0.3625 - val_mae: 0.4685\n",
            "Epoch 75/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.4638 - mae: 0.5943 - val_loss: 0.3643 - val_mae: 0.4702\n",
            "Epoch 76/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.4588 - mae: 0.5911 - val_loss: 0.3660 - val_mae: 0.4719\n",
            "Epoch 77/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.4539 - mae: 0.5879 - val_loss: 0.3678 - val_mae: 0.4736\n",
            "Epoch 78/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.4490 - mae: 0.5847 - val_loss: 0.3696 - val_mae: 0.4753\n",
            "Epoch 79/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.4442 - mae: 0.5815 - val_loss: 0.3715 - val_mae: 0.4770\n",
            "Epoch 80/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.4395 - mae: 0.5783 - val_loss: 0.3733 - val_mae: 0.4787\n",
            "Epoch 81/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.4350 - mae: 0.5753 - val_loss: 0.3752 - val_mae: 0.4804\n",
            "Epoch 82/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.4306 - mae: 0.5723 - val_loss: 0.3771 - val_mae: 0.4820\n",
            "Epoch 83/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.4262 - mae: 0.5693 - val_loss: 0.3790 - val_mae: 0.4837\n",
            "Epoch 84/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.4219 - mae: 0.5663 - val_loss: 0.3810 - val_mae: 0.4854\n",
            "Epoch 85/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 0.4176 - mae: 0.5633 - val_loss: 0.3829 - val_mae: 0.4871\n",
            "Epoch 86/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.4134 - mae: 0.5603 - val_loss: 0.3849 - val_mae: 0.4888\n",
            "Epoch 87/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.4092 - mae: 0.5573 - val_loss: 0.3869 - val_mae: 0.4905\n",
            "Epoch 88/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.4050 - mae: 0.5543 - val_loss: 0.3889 - val_mae: 0.4922\n",
            "Epoch 89/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.4008 - mae: 0.5513 - val_loss: 0.3909 - val_mae: 0.4939\n",
            "Epoch 90/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 0.3967 - mae: 0.5483 - val_loss: 0.3929 - val_mae: 0.4956\n",
            "Epoch 91/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 0.3927 - mae: 0.5454 - val_loss: 0.3950 - val_mae: 0.4973\n",
            "Epoch 92/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.3887 - mae: 0.5425 - val_loss: 0.3970 - val_mae: 0.4989\n",
            "Epoch 93/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.3847 - mae: 0.5395 - val_loss: 0.3990 - val_mae: 0.5006\n",
            "Epoch 94/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.3807 - mae: 0.5366 - val_loss: 0.4011 - val_mae: 0.5022\n",
            "Epoch 95/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.3768 - mae: 0.5337 - val_loss: 0.4031 - val_mae: 0.5039\n",
            "Epoch 96/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.3730 - mae: 0.5308 - val_loss: 0.4051 - val_mae: 0.5055\n",
            "Epoch 97/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.3691 - mae: 0.5280 - val_loss: 0.4072 - val_mae: 0.5071\n",
            "Epoch 98/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.3653 - mae: 0.5251 - val_loss: 0.4092 - val_mae: 0.5088\n",
            "Epoch 99/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.3616 - mae: 0.5223 - val_loss: 0.4113 - val_mae: 0.5104\n",
            "Epoch 100/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.3579 - mae: 0.5194 - val_loss: 0.4133 - val_mae: 0.5120\n",
            "Epoch 101/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 0.3542 - mae: 0.5166 - val_loss: 0.4153 - val_mae: 0.5136\n",
            "Epoch 102/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.3506 - mae: 0.5138 - val_loss: 0.4173 - val_mae: 0.5152\n",
            "Epoch 103/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.3470 - mae: 0.5110 - val_loss: 0.4192 - val_mae: 0.5167\n",
            "Epoch 104/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.3434 - mae: 0.5082 - val_loss: 0.4213 - val_mae: 0.5184\n",
            "Epoch 105/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.3399 - mae: 0.5054 - val_loss: 0.4234 - val_mae: 0.5201\n",
            "Epoch 106/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.3364 - mae: 0.5027 - val_loss: 0.4255 - val_mae: 0.5219\n",
            "Epoch 107/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.3330 - mae: 0.4999 - val_loss: 0.4276 - val_mae: 0.5236\n",
            "Epoch 108/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.3296 - mae: 0.4972 - val_loss: 0.4298 - val_mae: 0.5255\n",
            "Epoch 109/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.3262 - mae: 0.4945 - val_loss: 0.4320 - val_mae: 0.5273\n",
            "Epoch 110/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.3229 - mae: 0.4918 - val_loss: 0.4342 - val_mae: 0.5291\n",
            "Epoch 111/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.3196 - mae: 0.4890 - val_loss: 0.4364 - val_mae: 0.5310\n",
            "Epoch 112/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.3162 - mae: 0.4862 - val_loss: 0.4387 - val_mae: 0.5329\n",
            "Epoch 113/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 0.3129 - mae: 0.4834 - val_loss: 0.4409 - val_mae: 0.5351\n",
            "Epoch 114/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.3096 - mae: 0.4806 - val_loss: 0.4431 - val_mae: 0.5375\n",
            "Epoch 115/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.3064 - mae: 0.4778 - val_loss: 0.4454 - val_mae: 0.5400\n",
            "Epoch 116/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.3032 - mae: 0.4750 - val_loss: 0.4476 - val_mae: 0.5425\n",
            "Epoch 117/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 0.3000 - mae: 0.4722 - val_loss: 0.4498 - val_mae: 0.5450\n",
            "Epoch 118/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.2969 - mae: 0.4695 - val_loss: 0.4521 - val_mae: 0.5474\n",
            "Epoch 119/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.2938 - mae: 0.4668 - val_loss: 0.4543 - val_mae: 0.5498\n",
            "Epoch 120/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.2907 - mae: 0.4641 - val_loss: 0.4565 - val_mae: 0.5523\n",
            "Epoch 121/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.2877 - mae: 0.4614 - val_loss: 0.4587 - val_mae: 0.5547\n",
            "Epoch 122/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.2847 - mae: 0.4588 - val_loss: 0.4609 - val_mae: 0.5571\n",
            "Epoch 123/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.2817 - mae: 0.4562 - val_loss: 0.4631 - val_mae: 0.5595\n",
            "Epoch 124/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.2788 - mae: 0.4536 - val_loss: 0.4653 - val_mae: 0.5618\n",
            "Epoch 125/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296ms/step - loss: 0.2760 - mae: 0.4510 - val_loss: 0.4674 - val_mae: 0.5641\n",
            "Epoch 126/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 0.2731 - mae: 0.4484 - val_loss: 0.4695 - val_mae: 0.5664\n",
            "Epoch 127/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 0.2703 - mae: 0.4458 - val_loss: 0.4716 - val_mae: 0.5686\n",
            "Epoch 128/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 0.2675 - mae: 0.4433 - val_loss: 0.4737 - val_mae: 0.5709\n",
            "Epoch 129/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - loss: 0.2648 - mae: 0.4407 - val_loss: 0.4758 - val_mae: 0.5731\n",
            "Epoch 130/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - loss: 0.2620 - mae: 0.4382 - val_loss: 0.4779 - val_mae: 0.5753\n",
            "Epoch 131/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step - loss: 0.2594 - mae: 0.4357 - val_loss: 0.4800 - val_mae: 0.5775\n",
            "Epoch 132/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324ms/step - loss: 0.2567 - mae: 0.4333 - val_loss: 0.4820 - val_mae: 0.5797\n",
            "Epoch 133/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 0.2541 - mae: 0.4308 - val_loss: 0.4841 - val_mae: 0.5818\n",
            "Epoch 134/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - loss: 0.2515 - mae: 0.4284 - val_loss: 0.4861 - val_mae: 0.5839\n",
            "Epoch 135/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.2489 - mae: 0.4260 - val_loss: 0.4883 - val_mae: 0.5862\n",
            "Epoch 136/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.2464 - mae: 0.4236 - val_loss: 0.4905 - val_mae: 0.5885\n",
            "Epoch 137/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.2439 - mae: 0.4213 - val_loss: 0.4927 - val_mae: 0.5907\n",
            "Epoch 138/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.2415 - mae: 0.4189 - val_loss: 0.4949 - val_mae: 0.5930\n",
            "Epoch 139/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.2390 - mae: 0.4169 - val_loss: 0.4970 - val_mae: 0.5952\n",
            "Epoch 140/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 0.2366 - mae: 0.4150 - val_loss: 0.4992 - val_mae: 0.5974\n",
            "Epoch 141/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 0.2342 - mae: 0.4130 - val_loss: 0.5015 - val_mae: 0.5997\n",
            "Epoch 142/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 0.2319 - mae: 0.4110 - val_loss: 0.5040 - val_mae: 0.6020\n",
            "Epoch 143/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.2296 - mae: 0.4091 - val_loss: 0.5065 - val_mae: 0.6044\n",
            "Epoch 144/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.2273 - mae: 0.4071 - val_loss: 0.5089 - val_mae: 0.6066\n",
            "Epoch 145/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.2251 - mae: 0.4053 - val_loss: 0.5113 - val_mae: 0.6088\n",
            "Epoch 146/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.2229 - mae: 0.4036 - val_loss: 0.5137 - val_mae: 0.6110\n",
            "Epoch 147/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.2207 - mae: 0.4019 - val_loss: 0.5160 - val_mae: 0.6132\n",
            "Epoch 148/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 0.2185 - mae: 0.4002 - val_loss: 0.5183 - val_mae: 0.6153\n",
            "Epoch 149/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 0.2164 - mae: 0.3985 - val_loss: 0.5206 - val_mae: 0.6174\n",
            "Epoch 150/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.2143 - mae: 0.3968 - val_loss: 0.5229 - val_mae: 0.6195\n",
            "Epoch 151/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.2122 - mae: 0.3951 - val_loss: 0.5251 - val_mae: 0.6215\n",
            "Epoch 152/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.2101 - mae: 0.3934 - val_loss: 0.5273 - val_mae: 0.6236\n",
            "Epoch 153/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.2081 - mae: 0.3917 - val_loss: 0.5295 - val_mae: 0.6255\n",
            "Epoch 154/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.2061 - mae: 0.3901 - val_loss: 0.5316 - val_mae: 0.6275\n",
            "Epoch 155/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.2041 - mae: 0.3884 - val_loss: 0.5338 - val_mae: 0.6294\n",
            "Epoch 156/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.2021 - mae: 0.3867 - val_loss: 0.5359 - val_mae: 0.6313\n",
            "Epoch 157/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.2002 - mae: 0.3851 - val_loss: 0.5380 - val_mae: 0.6332\n",
            "Epoch 158/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.1983 - mae: 0.3834 - val_loss: 0.5400 - val_mae: 0.6350\n",
            "Epoch 159/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step - loss: 0.1964 - mae: 0.3818 - val_loss: 0.5421 - val_mae: 0.6369\n",
            "Epoch 160/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.1945 - mae: 0.3801 - val_loss: 0.5442 - val_mae: 0.6388\n",
            "Epoch 161/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.1926 - mae: 0.3784 - val_loss: 0.5463 - val_mae: 0.6406\n",
            "Epoch 162/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.1908 - mae: 0.3768 - val_loss: 0.5484 - val_mae: 0.6424\n",
            "Epoch 163/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.1889 - mae: 0.3752 - val_loss: 0.5504 - val_mae: 0.6442\n",
            "Epoch 164/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.1871 - mae: 0.3735 - val_loss: 0.5524 - val_mae: 0.6460\n",
            "Epoch 165/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.1853 - mae: 0.3719 - val_loss: 0.5544 - val_mae: 0.6477\n",
            "Epoch 166/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.1836 - mae: 0.3703 - val_loss: 0.5564 - val_mae: 0.6494\n",
            "Epoch 167/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.1818 - mae: 0.3687 - val_loss: 0.5583 - val_mae: 0.6512\n",
            "Epoch 168/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.1801 - mae: 0.3671 - val_loss: 0.5603 - val_mae: 0.6529\n",
            "Epoch 169/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.1784 - mae: 0.3655 - val_loss: 0.5623 - val_mae: 0.6545\n",
            "Epoch 170/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.1767 - mae: 0.3639 - val_loss: 0.5642 - val_mae: 0.6562\n",
            "Epoch 171/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 0.1750 - mae: 0.3623 - val_loss: 0.5661 - val_mae: 0.6579\n",
            "Epoch 172/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.1734 - mae: 0.3607 - val_loss: 0.5680 - val_mae: 0.6595\n",
            "Epoch 173/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.1719 - mae: 0.3592 - val_loss: 0.5699 - val_mae: 0.6611\n",
            "Epoch 174/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.1704 - mae: 0.3577 - val_loss: 0.5718 - val_mae: 0.6627\n",
            "Epoch 175/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.1688 - mae: 0.3562 - val_loss: 0.5737 - val_mae: 0.6643\n",
            "Epoch 176/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.1673 - mae: 0.3547 - val_loss: 0.5756 - val_mae: 0.6658\n",
            "Epoch 177/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.1658 - mae: 0.3532 - val_loss: 0.5774 - val_mae: 0.6674\n",
            "Epoch 178/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.1643 - mae: 0.3517 - val_loss: 0.5793 - val_mae: 0.6690\n",
            "Epoch 179/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 0.1628 - mae: 0.3502 - val_loss: 0.5812 - val_mae: 0.6705\n",
            "Epoch 180/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.1614 - mae: 0.3487 - val_loss: 0.5830 - val_mae: 0.6721\n",
            "Epoch 181/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 0.1599 - mae: 0.3472 - val_loss: 0.5849 - val_mae: 0.6736\n",
            "Epoch 182/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.1585 - mae: 0.3458 - val_loss: 0.5867 - val_mae: 0.6751\n",
            "Epoch 183/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.1570 - mae: 0.3443 - val_loss: 0.5885 - val_mae: 0.6765\n",
            "Epoch 184/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 0.1556 - mae: 0.3428 - val_loss: 0.5903 - val_mae: 0.6780\n",
            "Epoch 185/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.1542 - mae: 0.3414 - val_loss: 0.5921 - val_mae: 0.6795\n",
            "Epoch 186/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.1528 - mae: 0.3399 - val_loss: 0.5939 - val_mae: 0.6809\n",
            "Epoch 187/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.1515 - mae: 0.3384 - val_loss: 0.5957 - val_mae: 0.6824\n",
            "Epoch 188/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.1501 - mae: 0.3370 - val_loss: 0.5975 - val_mae: 0.6838\n",
            "Epoch 189/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.1487 - mae: 0.3355 - val_loss: 0.5993 - val_mae: 0.6852\n",
            "Epoch 190/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.1474 - mae: 0.3341 - val_loss: 0.6010 - val_mae: 0.6867\n",
            "Epoch 191/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 0.1461 - mae: 0.3326 - val_loss: 0.6028 - val_mae: 0.6880\n",
            "Epoch 192/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.1448 - mae: 0.3312 - val_loss: 0.6046 - val_mae: 0.6894\n",
            "Epoch 193/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.1435 - mae: 0.3297 - val_loss: 0.6063 - val_mae: 0.6907\n",
            "Epoch 194/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.1422 - mae: 0.3283 - val_loss: 0.6080 - val_mae: 0.6921\n",
            "Epoch 195/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.1409 - mae: 0.3269 - val_loss: 0.6097 - val_mae: 0.6934\n",
            "Epoch 196/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.1397 - mae: 0.3255 - val_loss: 0.6115 - val_mae: 0.6947\n",
            "Epoch 197/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 0.1385 - mae: 0.3240 - val_loss: 0.6132 - val_mae: 0.6960\n",
            "Epoch 198/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 0.1372 - mae: 0.3226 - val_loss: 0.6149 - val_mae: 0.6973\n",
            "Epoch 199/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.1360 - mae: 0.3212 - val_loss: 0.6166 - val_mae: 0.6986\n",
            "Epoch 200/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.1348 - mae: 0.3198 - val_loss: 0.6183 - val_mae: 0.6999\n",
            "Epoch 1/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.9828 - mae: 0.8387 - val_loss: 0.2556 - val_mae: 0.3503\n",
            "Epoch 2/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 357ms/step - loss: 0.9747 - mae: 0.8353 - val_loss: 0.2544 - val_mae: 0.3489\n",
            "Epoch 3/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 323ms/step - loss: 0.9666 - mae: 0.8320 - val_loss: 0.2532 - val_mae: 0.3476\n",
            "Epoch 4/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - loss: 0.9585 - mae: 0.8285 - val_loss: 0.2521 - val_mae: 0.3462\n",
            "Epoch 5/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324ms/step - loss: 0.9504 - mae: 0.8251 - val_loss: 0.2511 - val_mae: 0.3452\n",
            "Epoch 6/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274ms/step - loss: 0.9422 - mae: 0.8216 - val_loss: 0.2501 - val_mae: 0.3449\n",
            "Epoch 7/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 0.9341 - mae: 0.8181 - val_loss: 0.2492 - val_mae: 0.3458\n",
            "Epoch 8/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240ms/step - loss: 0.9259 - mae: 0.8146 - val_loss: 0.2484 - val_mae: 0.3468\n",
            "Epoch 9/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.9177 - mae: 0.8111 - val_loss: 0.2477 - val_mae: 0.3477\n",
            "Epoch 10/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.9095 - mae: 0.8075 - val_loss: 0.2470 - val_mae: 0.3486\n",
            "Epoch 11/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.9013 - mae: 0.8039 - val_loss: 0.2464 - val_mae: 0.3494\n",
            "Epoch 12/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.8931 - mae: 0.8003 - val_loss: 0.2459 - val_mae: 0.3501\n",
            "Epoch 13/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.8849 - mae: 0.7967 - val_loss: 0.2455 - val_mae: 0.3508\n",
            "Epoch 14/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.8767 - mae: 0.7930 - val_loss: 0.2452 - val_mae: 0.3514\n",
            "Epoch 15/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.8685 - mae: 0.7894 - val_loss: 0.2449 - val_mae: 0.3520\n",
            "Epoch 16/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.8603 - mae: 0.7857 - val_loss: 0.2447 - val_mae: 0.3525\n",
            "Epoch 17/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 0.8520 - mae: 0.7821 - val_loss: 0.2446 - val_mae: 0.3529\n",
            "Epoch 18/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.8438 - mae: 0.7787 - val_loss: 0.2446 - val_mae: 0.3533\n",
            "Epoch 19/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.8356 - mae: 0.7752 - val_loss: 0.2447 - val_mae: 0.3548\n",
            "Epoch 20/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.8274 - mae: 0.7717 - val_loss: 0.2449 - val_mae: 0.3563\n",
            "Epoch 21/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 0.8191 - mae: 0.7682 - val_loss: 0.2452 - val_mae: 0.3577\n",
            "Epoch 22/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.8109 - mae: 0.7646 - val_loss: 0.2456 - val_mae: 0.3591\n",
            "Epoch 23/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 0.8027 - mae: 0.7610 - val_loss: 0.2460 - val_mae: 0.3604\n",
            "Epoch 24/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.7945 - mae: 0.7574 - val_loss: 0.2466 - val_mae: 0.3617\n",
            "Epoch 25/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.7863 - mae: 0.7537 - val_loss: 0.2473 - val_mae: 0.3629\n",
            "Epoch 26/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.7781 - mae: 0.7500 - val_loss: 0.2481 - val_mae: 0.3641\n",
            "Epoch 27/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.7700 - mae: 0.7463 - val_loss: 0.2490 - val_mae: 0.3668\n",
            "Epoch 28/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.7618 - mae: 0.7425 - val_loss: 0.2501 - val_mae: 0.3696\n",
            "Epoch 29/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - loss: 0.7537 - mae: 0.7388 - val_loss: 0.2512 - val_mae: 0.3724\n",
            "Epoch 30/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.7455 - mae: 0.7350 - val_loss: 0.2524 - val_mae: 0.3752\n",
            "Epoch 31/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.7374 - mae: 0.7311 - val_loss: 0.2538 - val_mae: 0.3780\n",
            "Epoch 32/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step - loss: 0.7294 - mae: 0.7273 - val_loss: 0.2552 - val_mae: 0.3808\n",
            "Epoch 33/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.7213 - mae: 0.7234 - val_loss: 0.2568 - val_mae: 0.3836\n",
            "Epoch 34/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.7133 - mae: 0.7195 - val_loss: 0.2584 - val_mae: 0.3864\n",
            "Epoch 35/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.7053 - mae: 0.7156 - val_loss: 0.2602 - val_mae: 0.3892\n",
            "Epoch 36/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.6974 - mae: 0.7116 - val_loss: 0.2620 - val_mae: 0.3920\n",
            "Epoch 37/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.6894 - mae: 0.7077 - val_loss: 0.2640 - val_mae: 0.3948\n",
            "Epoch 38/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.6815 - mae: 0.7037 - val_loss: 0.2660 - val_mae: 0.3976\n",
            "Epoch 39/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.6737 - mae: 0.6997 - val_loss: 0.2682 - val_mae: 0.4003\n",
            "Epoch 40/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.6659 - mae: 0.6957 - val_loss: 0.2704 - val_mae: 0.4031\n",
            "Epoch 41/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.6581 - mae: 0.6917 - val_loss: 0.2727 - val_mae: 0.4059\n",
            "Epoch 42/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.6504 - mae: 0.6877 - val_loss: 0.2751 - val_mae: 0.4086\n",
            "Epoch 43/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.6427 - mae: 0.6836 - val_loss: 0.2776 - val_mae: 0.4113\n",
            "Epoch 44/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.6350 - mae: 0.6796 - val_loss: 0.2802 - val_mae: 0.4140\n",
            "Epoch 45/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.6274 - mae: 0.6755 - val_loss: 0.2829 - val_mae: 0.4167\n",
            "Epoch 46/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.6199 - mae: 0.6715 - val_loss: 0.2857 - val_mae: 0.4194\n",
            "Epoch 47/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - loss: 0.6124 - mae: 0.6674 - val_loss: 0.2885 - val_mae: 0.4220\n",
            "Epoch 48/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.6049 - mae: 0.6634 - val_loss: 0.2914 - val_mae: 0.4246\n",
            "Epoch 49/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.5975 - mae: 0.6593 - val_loss: 0.2944 - val_mae: 0.4272\n",
            "Epoch 50/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.5902 - mae: 0.6552 - val_loss: 0.2975 - val_mae: 0.4298\n",
            "Epoch 51/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.5829 - mae: 0.6512 - val_loss: 0.3007 - val_mae: 0.4324\n",
            "Epoch 52/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.5756 - mae: 0.6471 - val_loss: 0.3039 - val_mae: 0.4349\n",
            "Epoch 53/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.5684 - mae: 0.6431 - val_loss: 0.3072 - val_mae: 0.4374\n",
            "Epoch 54/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.5613 - mae: 0.6391 - val_loss: 0.3105 - val_mae: 0.4398\n",
            "Epoch 55/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.5542 - mae: 0.6350 - val_loss: 0.3140 - val_mae: 0.4426\n",
            "Epoch 56/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.5471 - mae: 0.6310 - val_loss: 0.3175 - val_mae: 0.4459\n",
            "Epoch 57/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.5402 - mae: 0.6270 - val_loss: 0.3210 - val_mae: 0.4492\n",
            "Epoch 58/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.5332 - mae: 0.6230 - val_loss: 0.3246 - val_mae: 0.4525\n",
            "Epoch 59/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.5263 - mae: 0.6190 - val_loss: 0.3283 - val_mae: 0.4558\n",
            "Epoch 60/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.5195 - mae: 0.6151 - val_loss: 0.3320 - val_mae: 0.4601\n",
            "Epoch 61/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 0.5128 - mae: 0.6111 - val_loss: 0.3357 - val_mae: 0.4643\n",
            "Epoch 62/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.5061 - mae: 0.6072 - val_loss: 0.3396 - val_mae: 0.4685\n",
            "Epoch 63/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.4994 - mae: 0.6032 - val_loss: 0.3434 - val_mae: 0.4727\n",
            "Epoch 64/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 0.4928 - mae: 0.5993 - val_loss: 0.3473 - val_mae: 0.4768\n",
            "Epoch 65/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.4863 - mae: 0.5954 - val_loss: 0.3513 - val_mae: 0.4809\n",
            "Epoch 66/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.4798 - mae: 0.5916 - val_loss: 0.3552 - val_mae: 0.4850\n",
            "Epoch 67/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.4734 - mae: 0.5877 - val_loss: 0.3592 - val_mae: 0.4890\n",
            "Epoch 68/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.4671 - mae: 0.5839 - val_loss: 0.3633 - val_mae: 0.4930\n",
            "Epoch 69/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.4608 - mae: 0.5801 - val_loss: 0.3674 - val_mae: 0.4970\n",
            "Epoch 70/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.4546 - mae: 0.5763 - val_loss: 0.3715 - val_mae: 0.5009\n",
            "Epoch 71/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.4484 - mae: 0.5725 - val_loss: 0.3756 - val_mae: 0.5048\n",
            "Epoch 72/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.4423 - mae: 0.5688 - val_loss: 0.3798 - val_mae: 0.5087\n",
            "Epoch 73/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 0.4363 - mae: 0.5651 - val_loss: 0.3840 - val_mae: 0.5125\n",
            "Epoch 74/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.4303 - mae: 0.5614 - val_loss: 0.3882 - val_mae: 0.5163\n",
            "Epoch 75/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 0.4244 - mae: 0.5577 - val_loss: 0.3925 - val_mae: 0.5201\n",
            "Epoch 76/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.4186 - mae: 0.5540 - val_loss: 0.3967 - val_mae: 0.5238\n",
            "Epoch 77/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 0.4128 - mae: 0.5504 - val_loss: 0.4010 - val_mae: 0.5275\n",
            "Epoch 78/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.4071 - mae: 0.5468 - val_loss: 0.4053 - val_mae: 0.5311\n",
            "Epoch 79/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 0.4015 - mae: 0.5432 - val_loss: 0.4096 - val_mae: 0.5348\n",
            "Epoch 80/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.3959 - mae: 0.5397 - val_loss: 0.4140 - val_mae: 0.5383\n",
            "Epoch 81/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.3904 - mae: 0.5361 - val_loss: 0.4183 - val_mae: 0.5419\n",
            "Epoch 82/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.3850 - mae: 0.5326 - val_loss: 0.4227 - val_mae: 0.5454\n",
            "Epoch 83/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.3797 - mae: 0.5291 - val_loss: 0.4271 - val_mae: 0.5489\n",
            "Epoch 84/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.3744 - mae: 0.5257 - val_loss: 0.4315 - val_mae: 0.5524\n",
            "Epoch 85/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 0.3692 - mae: 0.5222 - val_loss: 0.4359 - val_mae: 0.5558\n",
            "Epoch 86/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - loss: 0.3641 - mae: 0.5188 - val_loss: 0.4403 - val_mae: 0.5591\n",
            "Epoch 87/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 0.3590 - mae: 0.5154 - val_loss: 0.4447 - val_mae: 0.5625\n",
            "Epoch 88/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335ms/step - loss: 0.3540 - mae: 0.5121 - val_loss: 0.4491 - val_mae: 0.5658\n",
            "Epoch 89/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300ms/step - loss: 0.3491 - mae: 0.5087 - val_loss: 0.4535 - val_mae: 0.5691\n",
            "Epoch 90/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - loss: 0.3442 - mae: 0.5054 - val_loss: 0.4579 - val_mae: 0.5723\n",
            "Epoch 91/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.3395 - mae: 0.5021 - val_loss: 0.4624 - val_mae: 0.5755\n",
            "Epoch 92/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 0.3348 - mae: 0.4989 - val_loss: 0.4668 - val_mae: 0.5786\n",
            "Epoch 93/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324ms/step - loss: 0.3301 - mae: 0.4956 - val_loss: 0.4712 - val_mae: 0.5818\n",
            "Epoch 94/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 0.3256 - mae: 0.4924 - val_loss: 0.4757 - val_mae: 0.5849\n",
            "Epoch 95/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - loss: 0.3211 - mae: 0.4892 - val_loss: 0.4801 - val_mae: 0.5879\n",
            "Epoch 96/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - loss: 0.3167 - mae: 0.4861 - val_loss: 0.4845 - val_mae: 0.5909\n",
            "Epoch 97/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - loss: 0.3123 - mae: 0.4829 - val_loss: 0.4889 - val_mae: 0.5939\n",
            "Epoch 98/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.3081 - mae: 0.4798 - val_loss: 0.4933 - val_mae: 0.5969\n",
            "Epoch 99/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.3039 - mae: 0.4767 - val_loss: 0.4977 - val_mae: 0.5998\n",
            "Epoch 100/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.2997 - mae: 0.4737 - val_loss: 0.5021 - val_mae: 0.6026\n",
            "Epoch 101/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.2957 - mae: 0.4706 - val_loss: 0.5065 - val_mae: 0.6055\n",
            "Epoch 102/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.2917 - mae: 0.4676 - val_loss: 0.5109 - val_mae: 0.6083\n",
            "Epoch 103/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.2877 - mae: 0.4647 - val_loss: 0.5153 - val_mae: 0.6111\n",
            "Epoch 104/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.2839 - mae: 0.4617 - val_loss: 0.5196 - val_mae: 0.6138\n",
            "Epoch 105/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.2801 - mae: 0.4588 - val_loss: 0.5240 - val_mae: 0.6165\n",
            "Epoch 106/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 0.2764 - mae: 0.4559 - val_loss: 0.5283 - val_mae: 0.6192\n",
            "Epoch 107/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step - loss: 0.2727 - mae: 0.4530 - val_loss: 0.5326 - val_mae: 0.6218\n",
            "Epoch 108/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 0.2691 - mae: 0.4502 - val_loss: 0.5369 - val_mae: 0.6244\n",
            "Epoch 109/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - loss: 0.2656 - mae: 0.4474 - val_loss: 0.5411 - val_mae: 0.6270\n",
            "Epoch 110/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.2621 - mae: 0.4446 - val_loss: 0.5454 - val_mae: 0.6295\n",
            "Epoch 111/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.2587 - mae: 0.4421 - val_loss: 0.5496 - val_mae: 0.6320\n",
            "Epoch 112/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.2554 - mae: 0.4396 - val_loss: 0.5538 - val_mae: 0.6344\n",
            "Epoch 113/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.2521 - mae: 0.4372 - val_loss: 0.5580 - val_mae: 0.6369\n",
            "Epoch 114/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.2489 - mae: 0.4349 - val_loss: 0.5622 - val_mae: 0.6393\n",
            "Epoch 115/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.2457 - mae: 0.4325 - val_loss: 0.5663 - val_mae: 0.6416\n",
            "Epoch 116/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 0.2426 - mae: 0.4302 - val_loss: 0.5705 - val_mae: 0.6440\n",
            "Epoch 117/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.2396 - mae: 0.4279 - val_loss: 0.5745 - val_mae: 0.6463\n",
            "Epoch 118/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.2366 - mae: 0.4256 - val_loss: 0.5786 - val_mae: 0.6485\n",
            "Epoch 119/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.2337 - mae: 0.4233 - val_loss: 0.5827 - val_mae: 0.6516\n",
            "Epoch 120/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.2308 - mae: 0.4211 - val_loss: 0.5867 - val_mae: 0.6548\n",
            "Epoch 121/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.2280 - mae: 0.4188 - val_loss: 0.5907 - val_mae: 0.6579\n",
            "Epoch 122/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.2252 - mae: 0.4166 - val_loss: 0.5947 - val_mae: 0.6610\n",
            "Epoch 123/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - loss: 0.2225 - mae: 0.4145 - val_loss: 0.5986 - val_mae: 0.6641\n",
            "Epoch 124/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.2199 - mae: 0.4123 - val_loss: 0.6025 - val_mae: 0.6671\n",
            "Epoch 125/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.2172 - mae: 0.4101 - val_loss: 0.6064 - val_mae: 0.6701\n",
            "Epoch 126/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.2147 - mae: 0.4080 - val_loss: 0.6102 - val_mae: 0.6731\n",
            "Epoch 127/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.2122 - mae: 0.4059 - val_loss: 0.6141 - val_mae: 0.6760\n",
            "Epoch 128/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.2097 - mae: 0.4038 - val_loss: 0.6179 - val_mae: 0.6789\n",
            "Epoch 129/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.2073 - mae: 0.4018 - val_loss: 0.6216 - val_mae: 0.6817\n",
            "Epoch 130/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.2050 - mae: 0.3997 - val_loss: 0.6254 - val_mae: 0.6846\n",
            "Epoch 131/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 0.2027 - mae: 0.3977 - val_loss: 0.6291 - val_mae: 0.6873\n",
            "Epoch 132/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.2004 - mae: 0.3957 - val_loss: 0.6328 - val_mae: 0.6901\n",
            "Epoch 133/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.1982 - mae: 0.3937 - val_loss: 0.6364 - val_mae: 0.6928\n",
            "Epoch 134/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.1960 - mae: 0.3917 - val_loss: 0.6400 - val_mae: 0.6955\n",
            "Epoch 135/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.1939 - mae: 0.3898 - val_loss: 0.6436 - val_mae: 0.6981\n",
            "Epoch 136/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.1918 - mae: 0.3879 - val_loss: 0.6472 - val_mae: 0.7008\n",
            "Epoch 137/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.1898 - mae: 0.3860 - val_loss: 0.6507 - val_mae: 0.7034\n",
            "Epoch 138/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.1878 - mae: 0.3841 - val_loss: 0.6542 - val_mae: 0.7059\n",
            "Epoch 139/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.1858 - mae: 0.3822 - val_loss: 0.6577 - val_mae: 0.7084\n",
            "Epoch 140/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.1839 - mae: 0.3804 - val_loss: 0.6611 - val_mae: 0.7109\n",
            "Epoch 141/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.1820 - mae: 0.3785 - val_loss: 0.6645 - val_mae: 0.7134\n",
            "Epoch 142/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.1802 - mae: 0.3767 - val_loss: 0.6679 - val_mae: 0.7158\n",
            "Epoch 143/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 0.1784 - mae: 0.3750 - val_loss: 0.6713 - val_mae: 0.7182\n",
            "Epoch 144/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step - loss: 0.1766 - mae: 0.3732 - val_loss: 0.6746 - val_mae: 0.7206\n",
            "Epoch 145/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.1748 - mae: 0.3714 - val_loss: 0.6779 - val_mae: 0.7229\n",
            "Epoch 146/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.1731 - mae: 0.3697 - val_loss: 0.6811 - val_mae: 0.7252\n",
            "Epoch 147/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 0.1715 - mae: 0.3680 - val_loss: 0.6844 - val_mae: 0.7275\n",
            "Epoch 148/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 0.1698 - mae: 0.3663 - val_loss: 0.6876 - val_mae: 0.7298\n",
            "Epoch 149/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 0.1682 - mae: 0.3646 - val_loss: 0.6907 - val_mae: 0.7320\n",
            "Epoch 150/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.1667 - mae: 0.3629 - val_loss: 0.6939 - val_mae: 0.7342\n",
            "Epoch 151/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.1651 - mae: 0.3613 - val_loss: 0.6970 - val_mae: 0.7363\n",
            "Epoch 152/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 0.1636 - mae: 0.3597 - val_loss: 0.7000 - val_mae: 0.7385\n",
            "Epoch 153/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.1621 - mae: 0.3581 - val_loss: 0.7031 - val_mae: 0.7406\n",
            "Epoch 154/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.1607 - mae: 0.3565 - val_loss: 0.7061 - val_mae: 0.7427\n",
            "Epoch 155/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.1592 - mae: 0.3549 - val_loss: 0.7091 - val_mae: 0.7447\n",
            "Epoch 156/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.1578 - mae: 0.3533 - val_loss: 0.7120 - val_mae: 0.7468\n",
            "Epoch 157/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 0.1565 - mae: 0.3518 - val_loss: 0.7150 - val_mae: 0.7488\n",
            "Epoch 158/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.1551 - mae: 0.3502 - val_loss: 0.7179 - val_mae: 0.7507\n",
            "Epoch 159/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.1538 - mae: 0.3487 - val_loss: 0.7207 - val_mae: 0.7527\n",
            "Epoch 160/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.1525 - mae: 0.3472 - val_loss: 0.7236 - val_mae: 0.7546\n",
            "Epoch 161/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.1512 - mae: 0.3459 - val_loss: 0.7264 - val_mae: 0.7565\n",
            "Epoch 162/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.1500 - mae: 0.3446 - val_loss: 0.7291 - val_mae: 0.7584\n",
            "Epoch 163/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.1488 - mae: 0.3434 - val_loss: 0.7319 - val_mae: 0.7602\n",
            "Epoch 164/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.1475 - mae: 0.3421 - val_loss: 0.7346 - val_mae: 0.7621\n",
            "Epoch 165/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.1464 - mae: 0.3409 - val_loss: 0.7373 - val_mae: 0.7639\n",
            "Epoch 166/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.1452 - mae: 0.3397 - val_loss: 0.7400 - val_mae: 0.7657\n",
            "Epoch 167/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 0.1441 - mae: 0.3385 - val_loss: 0.7426 - val_mae: 0.7674\n",
            "Epoch 168/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.1429 - mae: 0.3373 - val_loss: 0.7452 - val_mae: 0.7691\n",
            "Epoch 169/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.1418 - mae: 0.3361 - val_loss: 0.7478 - val_mae: 0.7709\n",
            "Epoch 170/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.1408 - mae: 0.3349 - val_loss: 0.7503 - val_mae: 0.7725\n",
            "Epoch 171/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - loss: 0.1397 - mae: 0.3338 - val_loss: 0.7529 - val_mae: 0.7742\n",
            "Epoch 172/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - loss: 0.1386 - mae: 0.3326 - val_loss: 0.7553 - val_mae: 0.7758\n",
            "Epoch 173/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - loss: 0.1376 - mae: 0.3315 - val_loss: 0.7578 - val_mae: 0.7775\n",
            "Epoch 174/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 0.1366 - mae: 0.3304 - val_loss: 0.7603 - val_mae: 0.7791\n",
            "Epoch 175/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - loss: 0.1356 - mae: 0.3293 - val_loss: 0.7627 - val_mae: 0.7806\n",
            "Epoch 176/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 0.1346 - mae: 0.3282 - val_loss: 0.7650 - val_mae: 0.7822\n",
            "Epoch 177/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 0.1337 - mae: 0.3271 - val_loss: 0.7674 - val_mae: 0.7837\n",
            "Epoch 178/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - loss: 0.1327 - mae: 0.3260 - val_loss: 0.7697 - val_mae: 0.7852\n",
            "Epoch 179/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - loss: 0.1318 - mae: 0.3249 - val_loss: 0.7720 - val_mae: 0.7867\n",
            "Epoch 180/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303ms/step - loss: 0.1309 - mae: 0.3238 - val_loss: 0.7743 - val_mae: 0.7882\n",
            "Epoch 181/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - loss: 0.1300 - mae: 0.3228 - val_loss: 0.7766 - val_mae: 0.7897\n",
            "Epoch 182/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - loss: 0.1291 - mae: 0.3217 - val_loss: 0.7788 - val_mae: 0.7911\n",
            "Epoch 183/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - loss: 0.1282 - mae: 0.3207 - val_loss: 0.7810 - val_mae: 0.7925\n",
            "Epoch 184/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.1273 - mae: 0.3197 - val_loss: 0.7832 - val_mae: 0.7939\n",
            "Epoch 185/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.1265 - mae: 0.3187 - val_loss: 0.7853 - val_mae: 0.7953\n",
            "Epoch 186/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.1256 - mae: 0.3176 - val_loss: 0.7875 - val_mae: 0.7966\n",
            "Epoch 187/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.1248 - mae: 0.3166 - val_loss: 0.7896 - val_mae: 0.7979\n",
            "Epoch 188/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.1240 - mae: 0.3156 - val_loss: 0.7916 - val_mae: 0.7993\n",
            "Epoch 189/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 0.1232 - mae: 0.3147 - val_loss: 0.7937 - val_mae: 0.8006\n",
            "Epoch 190/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 0.1224 - mae: 0.3137 - val_loss: 0.7957 - val_mae: 0.8018\n",
            "Epoch 191/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.1216 - mae: 0.3127 - val_loss: 0.7977 - val_mae: 0.8031\n",
            "Epoch 192/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.1208 - mae: 0.3118 - val_loss: 0.7997 - val_mae: 0.8044\n",
            "Epoch 193/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.1200 - mae: 0.3108 - val_loss: 0.8016 - val_mae: 0.8056\n",
            "Epoch 194/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.1193 - mae: 0.3098 - val_loss: 0.8036 - val_mae: 0.8068\n",
            "Epoch 195/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.1185 - mae: 0.3089 - val_loss: 0.8055 - val_mae: 0.8080\n",
            "Epoch 196/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 0.1178 - mae: 0.3080 - val_loss: 0.8074 - val_mae: 0.8092\n",
            "Epoch 197/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.1171 - mae: 0.3070 - val_loss: 0.8092 - val_mae: 0.8103\n",
            "Epoch 198/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.1164 - mae: 0.3061 - val_loss: 0.8111 - val_mae: 0.8115\n",
            "Epoch 199/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.1157 - mae: 0.3052 - val_loss: 0.8129 - val_mae: 0.8126\n",
            "Epoch 200/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.1150 - mae: 0.3043 - val_loss: 0.8147 - val_mae: 0.8137\n",
            "Epoch 1/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.6324 - mae: 0.6266 - val_loss: 0.3603 - val_mae: 0.5015\n",
            "Epoch 2/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.6278 - mae: 0.6256 - val_loss: 0.3545 - val_mae: 0.4966\n",
            "Epoch 3/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.6233 - mae: 0.6248 - val_loss: 0.3488 - val_mae: 0.4917\n",
            "Epoch 4/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.6188 - mae: 0.6239 - val_loss: 0.3432 - val_mae: 0.4868\n",
            "Epoch 5/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.6143 - mae: 0.6236 - val_loss: 0.3376 - val_mae: 0.4819\n",
            "Epoch 6/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.6100 - mae: 0.6233 - val_loss: 0.3322 - val_mae: 0.4770\n",
            "Epoch 7/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.6057 - mae: 0.6230 - val_loss: 0.3268 - val_mae: 0.4725\n",
            "Epoch 8/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.6014 - mae: 0.6234 - val_loss: 0.3216 - val_mae: 0.4688\n",
            "Epoch 9/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.5973 - mae: 0.6240 - val_loss: 0.3165 - val_mae: 0.4651\n",
            "Epoch 10/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.5932 - mae: 0.6244 - val_loss: 0.3115 - val_mae: 0.4614\n",
            "Epoch 11/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.5892 - mae: 0.6249 - val_loss: 0.3067 - val_mae: 0.4577\n",
            "Epoch 12/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 0.5853 - mae: 0.6253 - val_loss: 0.3020 - val_mae: 0.4540\n",
            "Epoch 13/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.5815 - mae: 0.6258 - val_loss: 0.2974 - val_mae: 0.4503\n",
            "Epoch 14/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.5777 - mae: 0.6261 - val_loss: 0.2930 - val_mae: 0.4467\n",
            "Epoch 15/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 0.5741 - mae: 0.6265 - val_loss: 0.2888 - val_mae: 0.4430\n",
            "Epoch 16/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.5705 - mae: 0.6268 - val_loss: 0.2847 - val_mae: 0.4394\n",
            "Epoch 17/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 0.5671 - mae: 0.6271 - val_loss: 0.2809 - val_mae: 0.4358\n",
            "Epoch 18/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.5637 - mae: 0.6274 - val_loss: 0.2772 - val_mae: 0.4323\n",
            "Epoch 19/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.5605 - mae: 0.6276 - val_loss: 0.2736 - val_mae: 0.4288\n",
            "Epoch 20/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.5573 - mae: 0.6278 - val_loss: 0.2703 - val_mae: 0.4254\n",
            "Epoch 21/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.5543 - mae: 0.6280 - val_loss: 0.2671 - val_mae: 0.4234\n",
            "Epoch 22/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.5513 - mae: 0.6281 - val_loss: 0.2642 - val_mae: 0.4214\n",
            "Epoch 23/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.5484 - mae: 0.6282 - val_loss: 0.2614 - val_mae: 0.4195\n",
            "Epoch 24/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.5457 - mae: 0.6282 - val_loss: 0.2588 - val_mae: 0.4176\n",
            "Epoch 25/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.5430 - mae: 0.6282 - val_loss: 0.2564 - val_mae: 0.4158\n",
            "Epoch 26/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.5404 - mae: 0.6282 - val_loss: 0.2542 - val_mae: 0.4140\n",
            "Epoch 27/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.5379 - mae: 0.6281 - val_loss: 0.2521 - val_mae: 0.4123\n",
            "Epoch 28/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.5354 - mae: 0.6280 - val_loss: 0.2502 - val_mae: 0.4107\n",
            "Epoch 29/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.5331 - mae: 0.6278 - val_loss: 0.2485 - val_mae: 0.4091\n",
            "Epoch 30/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.5308 - mae: 0.6276 - val_loss: 0.2470 - val_mae: 0.4076\n",
            "Epoch 31/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.5286 - mae: 0.6273 - val_loss: 0.2456 - val_mae: 0.4062\n",
            "Epoch 32/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.5264 - mae: 0.6270 - val_loss: 0.2444 - val_mae: 0.4049\n",
            "Epoch 33/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.5243 - mae: 0.6266 - val_loss: 0.2434 - val_mae: 0.4036\n",
            "Epoch 34/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - loss: 0.5223 - mae: 0.6263 - val_loss: 0.2425 - val_mae: 0.4024\n",
            "Epoch 35/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.5203 - mae: 0.6258 - val_loss: 0.2417 - val_mae: 0.4014\n",
            "Epoch 36/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.5183 - mae: 0.6253 - val_loss: 0.2411 - val_mae: 0.4004\n",
            "Epoch 37/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.5164 - mae: 0.6248 - val_loss: 0.2405 - val_mae: 0.3994\n",
            "Epoch 38/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.5145 - mae: 0.6242 - val_loss: 0.2402 - val_mae: 0.3986\n",
            "Epoch 39/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.5127 - mae: 0.6236 - val_loss: 0.2399 - val_mae: 0.3979\n",
            "Epoch 40/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.5108 - mae: 0.6230 - val_loss: 0.2397 - val_mae: 0.3972\n",
            "Epoch 41/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.5090 - mae: 0.6223 - val_loss: 0.2396 - val_mae: 0.3966\n",
            "Epoch 42/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.5072 - mae: 0.6216 - val_loss: 0.2397 - val_mae: 0.3961\n",
            "Epoch 43/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.5055 - mae: 0.6208 - val_loss: 0.2398 - val_mae: 0.3958\n",
            "Epoch 44/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - loss: 0.5037 - mae: 0.6200 - val_loss: 0.2400 - val_mae: 0.3961\n",
            "Epoch 45/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.5019 - mae: 0.6192 - val_loss: 0.2402 - val_mae: 0.3964\n",
            "Epoch 46/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.5002 - mae: 0.6184 - val_loss: 0.2406 - val_mae: 0.3968\n",
            "Epoch 47/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 0.4985 - mae: 0.6175 - val_loss: 0.2410 - val_mae: 0.3972\n",
            "Epoch 48/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - loss: 0.4967 - mae: 0.6166 - val_loss: 0.2415 - val_mae: 0.3976\n",
            "Epoch 49/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - loss: 0.4950 - mae: 0.6156 - val_loss: 0.2420 - val_mae: 0.3981\n",
            "Epoch 50/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247ms/step - loss: 0.4933 - mae: 0.6147 - val_loss: 0.2425 - val_mae: 0.3985\n",
            "Epoch 51/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322ms/step - loss: 0.4916 - mae: 0.6137 - val_loss: 0.2432 - val_mae: 0.3990\n",
            "Epoch 52/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300ms/step - loss: 0.4899 - mae: 0.6127 - val_loss: 0.2438 - val_mae: 0.3996\n",
            "Epoch 53/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - loss: 0.4882 - mae: 0.6117 - val_loss: 0.2445 - val_mae: 0.4001\n",
            "Epoch 54/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303ms/step - loss: 0.4865 - mae: 0.6107 - val_loss: 0.2453 - val_mae: 0.4007\n",
            "Epoch 55/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 316ms/step - loss: 0.4848 - mae: 0.6097 - val_loss: 0.2460 - val_mae: 0.4013\n",
            "Epoch 56/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - loss: 0.4831 - mae: 0.6086 - val_loss: 0.2468 - val_mae: 0.4019\n",
            "Epoch 57/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 0.4815 - mae: 0.6075 - val_loss: 0.2477 - val_mae: 0.4025\n",
            "Epoch 58/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.4798 - mae: 0.6065 - val_loss: 0.2485 - val_mae: 0.4031\n",
            "Epoch 59/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.4781 - mae: 0.6054 - val_loss: 0.2494 - val_mae: 0.4037\n",
            "Epoch 60/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.4765 - mae: 0.6043 - val_loss: 0.2503 - val_mae: 0.4044\n",
            "Epoch 61/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.4748 - mae: 0.6032 - val_loss: 0.2512 - val_mae: 0.4050\n",
            "Epoch 62/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 0.4732 - mae: 0.6021 - val_loss: 0.2521 - val_mae: 0.4057\n",
            "Epoch 63/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.4715 - mae: 0.6010 - val_loss: 0.2530 - val_mae: 0.4064\n",
            "Epoch 64/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.4699 - mae: 0.5999 - val_loss: 0.2540 - val_mae: 0.4070\n",
            "Epoch 65/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 0.4683 - mae: 0.5988 - val_loss: 0.2549 - val_mae: 0.4077\n",
            "Epoch 66/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.4666 - mae: 0.5977 - val_loss: 0.2559 - val_mae: 0.4084\n",
            "Epoch 67/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.4650 - mae: 0.5966 - val_loss: 0.2568 - val_mae: 0.4091\n",
            "Epoch 68/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.4634 - mae: 0.5955 - val_loss: 0.2578 - val_mae: 0.4097\n",
            "Epoch 69/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.4618 - mae: 0.5944 - val_loss: 0.2587 - val_mae: 0.4104\n",
            "Epoch 70/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - loss: 0.4603 - mae: 0.5933 - val_loss: 0.2597 - val_mae: 0.4111\n",
            "Epoch 71/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - loss: 0.4587 - mae: 0.5922 - val_loss: 0.2607 - val_mae: 0.4117\n",
            "Epoch 72/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.4571 - mae: 0.5912 - val_loss: 0.2616 - val_mae: 0.4124\n",
            "Epoch 73/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.4555 - mae: 0.5901 - val_loss: 0.2626 - val_mae: 0.4131\n",
            "Epoch 74/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.4540 - mae: 0.5890 - val_loss: 0.2636 - val_mae: 0.4137\n",
            "Epoch 75/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.4524 - mae: 0.5879 - val_loss: 0.2645 - val_mae: 0.4144\n",
            "Epoch 76/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.4509 - mae: 0.5869 - val_loss: 0.2655 - val_mae: 0.4150\n",
            "Epoch 77/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.4494 - mae: 0.5858 - val_loss: 0.2665 - val_mae: 0.4157\n",
            "Epoch 78/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.4478 - mae: 0.5848 - val_loss: 0.2674 - val_mae: 0.4163\n",
            "Epoch 79/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.4463 - mae: 0.5837 - val_loss: 0.2684 - val_mae: 0.4169\n",
            "Epoch 80/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.4448 - mae: 0.5827 - val_loss: 0.2693 - val_mae: 0.4176\n",
            "Epoch 81/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.4433 - mae: 0.5816 - val_loss: 0.2703 - val_mae: 0.4182\n",
            "Epoch 82/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 0.4417 - mae: 0.5806 - val_loss: 0.2712 - val_mae: 0.4188\n",
            "Epoch 83/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.4402 - mae: 0.5796 - val_loss: 0.2722 - val_mae: 0.4194\n",
            "Epoch 84/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 0.4387 - mae: 0.5786 - val_loss: 0.2731 - val_mae: 0.4200\n",
            "Epoch 85/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 0.4373 - mae: 0.5775 - val_loss: 0.2741 - val_mae: 0.4206\n",
            "Epoch 86/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278ms/step - loss: 0.4358 - mae: 0.5765 - val_loss: 0.2750 - val_mae: 0.4212\n",
            "Epoch 87/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.4343 - mae: 0.5755 - val_loss: 0.2760 - val_mae: 0.4218\n",
            "Epoch 88/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.4328 - mae: 0.5745 - val_loss: 0.2769 - val_mae: 0.4224\n",
            "Epoch 89/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 0.4313 - mae: 0.5735 - val_loss: 0.2779 - val_mae: 0.4230\n",
            "Epoch 90/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.4299 - mae: 0.5725 - val_loss: 0.2789 - val_mae: 0.4235\n",
            "Epoch 91/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.4284 - mae: 0.5716 - val_loss: 0.2798 - val_mae: 0.4241\n",
            "Epoch 92/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.4269 - mae: 0.5706 - val_loss: 0.2808 - val_mae: 0.4247\n",
            "Epoch 93/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.4255 - mae: 0.5696 - val_loss: 0.2818 - val_mae: 0.4252\n",
            "Epoch 94/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.4240 - mae: 0.5686 - val_loss: 0.2827 - val_mae: 0.4258\n",
            "Epoch 95/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.4226 - mae: 0.5676 - val_loss: 0.2837 - val_mae: 0.4264\n",
            "Epoch 96/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.4212 - mae: 0.5667 - val_loss: 0.2847 - val_mae: 0.4269\n",
            "Epoch 97/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - loss: 0.4197 - mae: 0.5657 - val_loss: 0.2857 - val_mae: 0.4275\n",
            "Epoch 98/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.4183 - mae: 0.5647 - val_loss: 0.2867 - val_mae: 0.4280\n",
            "Epoch 99/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 0.4169 - mae: 0.5638 - val_loss: 0.2877 - val_mae: 0.4286\n",
            "Epoch 100/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.4154 - mae: 0.5628 - val_loss: 0.2887 - val_mae: 0.4292\n",
            "Epoch 101/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.4140 - mae: 0.5618 - val_loss: 0.2898 - val_mae: 0.4297\n",
            "Epoch 102/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 0.4126 - mae: 0.5609 - val_loss: 0.2908 - val_mae: 0.4303\n",
            "Epoch 103/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.4112 - mae: 0.5599 - val_loss: 0.2919 - val_mae: 0.4308\n",
            "Epoch 104/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.4098 - mae: 0.5589 - val_loss: 0.2929 - val_mae: 0.4314\n",
            "Epoch 105/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.4084 - mae: 0.5580 - val_loss: 0.2940 - val_mae: 0.4319\n",
            "Epoch 106/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 0.4070 - mae: 0.5570 - val_loss: 0.2950 - val_mae: 0.4325\n",
            "Epoch 107/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 0.4056 - mae: 0.5560 - val_loss: 0.2961 - val_mae: 0.4330\n",
            "Epoch 108/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.4042 - mae: 0.5551 - val_loss: 0.2972 - val_mae: 0.4336\n",
            "Epoch 109/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - loss: 0.4029 - mae: 0.5541 - val_loss: 0.2983 - val_mae: 0.4341\n",
            "Epoch 110/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.4015 - mae: 0.5531 - val_loss: 0.2994 - val_mae: 0.4347\n",
            "Epoch 111/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.4001 - mae: 0.5522 - val_loss: 0.3005 - val_mae: 0.4353\n",
            "Epoch 112/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.3987 - mae: 0.5512 - val_loss: 0.3016 - val_mae: 0.4358\n",
            "Epoch 113/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 0.3974 - mae: 0.5503 - val_loss: 0.3028 - val_mae: 0.4364\n",
            "Epoch 114/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.3960 - mae: 0.5493 - val_loss: 0.3039 - val_mae: 0.4370\n",
            "Epoch 115/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.3947 - mae: 0.5483 - val_loss: 0.3051 - val_mae: 0.4375\n",
            "Epoch 116/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.3933 - mae: 0.5474 - val_loss: 0.3062 - val_mae: 0.4381\n",
            "Epoch 117/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.3920 - mae: 0.5464 - val_loss: 0.3074 - val_mae: 0.4386\n",
            "Epoch 118/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.3906 - mae: 0.5454 - val_loss: 0.3086 - val_mae: 0.4392\n",
            "Epoch 119/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 0.3893 - mae: 0.5445 - val_loss: 0.3097 - val_mae: 0.4398\n",
            "Epoch 120/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.3879 - mae: 0.5435 - val_loss: 0.3109 - val_mae: 0.4404\n",
            "Epoch 121/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.3866 - mae: 0.5425 - val_loss: 0.3121 - val_mae: 0.4409\n",
            "Epoch 122/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.3853 - mae: 0.5415 - val_loss: 0.3133 - val_mae: 0.4415\n",
            "Epoch 123/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.3839 - mae: 0.5406 - val_loss: 0.3145 - val_mae: 0.4421\n",
            "Epoch 124/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.3826 - mae: 0.5396 - val_loss: 0.3158 - val_mae: 0.4426\n",
            "Epoch 125/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.3813 - mae: 0.5386 - val_loss: 0.3170 - val_mae: 0.4432\n",
            "Epoch 126/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.3800 - mae: 0.5377 - val_loss: 0.3182 - val_mae: 0.4438\n",
            "Epoch 127/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.3787 - mae: 0.5367 - val_loss: 0.3195 - val_mae: 0.4444\n",
            "Epoch 128/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.3774 - mae: 0.5357 - val_loss: 0.3207 - val_mae: 0.4449\n",
            "Epoch 129/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.3761 - mae: 0.5348 - val_loss: 0.3220 - val_mae: 0.4455\n",
            "Epoch 130/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - loss: 0.3748 - mae: 0.5338 - val_loss: 0.3232 - val_mae: 0.4461\n",
            "Epoch 131/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step - loss: 0.3735 - mae: 0.5328 - val_loss: 0.3245 - val_mae: 0.4470\n",
            "Epoch 132/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250ms/step - loss: 0.3722 - mae: 0.5319 - val_loss: 0.3258 - val_mae: 0.4479\n",
            "Epoch 133/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - loss: 0.3709 - mae: 0.5309 - val_loss: 0.3270 - val_mae: 0.4489\n",
            "Epoch 134/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - loss: 0.3696 - mae: 0.5299 - val_loss: 0.3283 - val_mae: 0.4498\n",
            "Epoch 135/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 313ms/step - loss: 0.3683 - mae: 0.5290 - val_loss: 0.3296 - val_mae: 0.4507\n",
            "Epoch 136/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295ms/step - loss: 0.3670 - mae: 0.5280 - val_loss: 0.3309 - val_mae: 0.4516\n",
            "Epoch 137/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 307ms/step - loss: 0.3658 - mae: 0.5270 - val_loss: 0.3322 - val_mae: 0.4526\n",
            "Epoch 138/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 815ms/step - loss: 0.3645 - mae: 0.5261 - val_loss: 0.3336 - val_mae: 0.4535\n",
            "Epoch 139/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 761ms/step - loss: 0.3632 - mae: 0.5251 - val_loss: 0.3349 - val_mae: 0.4544\n",
            "Epoch 140/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 815ms/step - loss: 0.3620 - mae: 0.5241 - val_loss: 0.3362 - val_mae: 0.4553\n",
            "Epoch 141/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 690ms/step - loss: 0.3607 - mae: 0.5232 - val_loss: 0.3375 - val_mae: 0.4563\n",
            "Epoch 142/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340ms/step - loss: 0.3594 - mae: 0.5222 - val_loss: 0.3389 - val_mae: 0.4572\n",
            "Epoch 143/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 431ms/step - loss: 0.3582 - mae: 0.5212 - val_loss: 0.3402 - val_mae: 0.4581\n",
            "Epoch 144/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - loss: 0.3569 - mae: 0.5203 - val_loss: 0.3416 - val_mae: 0.4590\n",
            "Epoch 145/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.3557 - mae: 0.5193 - val_loss: 0.3429 - val_mae: 0.4600\n",
            "Epoch 146/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.3545 - mae: 0.5183 - val_loss: 0.3443 - val_mae: 0.4612\n",
            "Epoch 147/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.3532 - mae: 0.5174 - val_loss: 0.3457 - val_mae: 0.4625\n",
            "Epoch 148/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.3520 - mae: 0.5164 - val_loss: 0.3471 - val_mae: 0.4637\n",
            "Epoch 149/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - loss: 0.3507 - mae: 0.5155 - val_loss: 0.3485 - val_mae: 0.4650\n",
            "Epoch 150/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - loss: 0.3495 - mae: 0.5146 - val_loss: 0.3499 - val_mae: 0.4662\n",
            "Epoch 151/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.3483 - mae: 0.5137 - val_loss: 0.3513 - val_mae: 0.4675\n",
            "Epoch 152/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 0.3471 - mae: 0.5128 - val_loss: 0.3527 - val_mae: 0.4687\n",
            "Epoch 153/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.3459 - mae: 0.5120 - val_loss: 0.3541 - val_mae: 0.4702\n",
            "Epoch 154/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.3446 - mae: 0.5111 - val_loss: 0.3555 - val_mae: 0.4718\n",
            "Epoch 155/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.3434 - mae: 0.5103 - val_loss: 0.3569 - val_mae: 0.4734\n",
            "Epoch 156/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.3422 - mae: 0.5094 - val_loss: 0.3584 - val_mae: 0.4749\n",
            "Epoch 157/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 0.3410 - mae: 0.5085 - val_loss: 0.3598 - val_mae: 0.4765\n",
            "Epoch 158/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.3398 - mae: 0.5077 - val_loss: 0.3613 - val_mae: 0.4781\n",
            "Epoch 159/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.3386 - mae: 0.5068 - val_loss: 0.3627 - val_mae: 0.4797\n",
            "Epoch 160/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.3374 - mae: 0.5059 - val_loss: 0.3642 - val_mae: 0.4812\n",
            "Epoch 161/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.3362 - mae: 0.5051 - val_loss: 0.3656 - val_mae: 0.4828\n",
            "Epoch 162/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.3350 - mae: 0.5042 - val_loss: 0.3671 - val_mae: 0.4844\n",
            "Epoch 163/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.3339 - mae: 0.5033 - val_loss: 0.3686 - val_mae: 0.4860\n",
            "Epoch 164/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.3327 - mae: 0.5025 - val_loss: 0.3701 - val_mae: 0.4875\n",
            "Epoch 165/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.3315 - mae: 0.5016 - val_loss: 0.3716 - val_mae: 0.4891\n",
            "Epoch 166/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.3303 - mae: 0.5007 - val_loss: 0.3731 - val_mae: 0.4907\n",
            "Epoch 167/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 0.3292 - mae: 0.4999 - val_loss: 0.3746 - val_mae: 0.4922\n",
            "Epoch 168/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.3280 - mae: 0.4990 - val_loss: 0.3761 - val_mae: 0.4938\n",
            "Epoch 169/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.3268 - mae: 0.4981 - val_loss: 0.3776 - val_mae: 0.4954\n",
            "Epoch 170/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.3257 - mae: 0.4973 - val_loss: 0.3791 - val_mae: 0.4969\n",
            "Epoch 171/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.3245 - mae: 0.4964 - val_loss: 0.3807 - val_mae: 0.4985\n",
            "Epoch 172/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.3234 - mae: 0.4955 - val_loss: 0.3822 - val_mae: 0.5001\n",
            "Epoch 173/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.3222 - mae: 0.4947 - val_loss: 0.3838 - val_mae: 0.5016\n",
            "Epoch 174/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.3211 - mae: 0.4938 - val_loss: 0.3853 - val_mae: 0.5032\n",
            "Epoch 175/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.3200 - mae: 0.4930 - val_loss: 0.3869 - val_mae: 0.5047\n",
            "Epoch 176/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.3188 - mae: 0.4921 - val_loss: 0.3884 - val_mae: 0.5063\n",
            "Epoch 177/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.3177 - mae: 0.4912 - val_loss: 0.3900 - val_mae: 0.5079\n",
            "Epoch 178/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.3166 - mae: 0.4904 - val_loss: 0.3916 - val_mae: 0.5094\n",
            "Epoch 179/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.3154 - mae: 0.4895 - val_loss: 0.3932 - val_mae: 0.5110\n",
            "Epoch 180/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.3143 - mae: 0.4886 - val_loss: 0.3948 - val_mae: 0.5125\n",
            "Epoch 181/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.3132 - mae: 0.4878 - val_loss: 0.3963 - val_mae: 0.5141\n",
            "Epoch 182/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.3121 - mae: 0.4869 - val_loss: 0.3979 - val_mae: 0.5156\n",
            "Epoch 183/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 0.3110 - mae: 0.4860 - val_loss: 0.3995 - val_mae: 0.5172\n",
            "Epoch 184/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.3099 - mae: 0.4852 - val_loss: 0.4012 - val_mae: 0.5188\n",
            "Epoch 185/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.3088 - mae: 0.4843 - val_loss: 0.4028 - val_mae: 0.5203\n",
            "Epoch 186/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.3077 - mae: 0.4834 - val_loss: 0.4044 - val_mae: 0.5219\n",
            "Epoch 187/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.3066 - mae: 0.4826 - val_loss: 0.4060 - val_mae: 0.5234\n",
            "Epoch 188/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.3055 - mae: 0.4817 - val_loss: 0.4077 - val_mae: 0.5250\n",
            "Epoch 189/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 0.3044 - mae: 0.4809 - val_loss: 0.4093 - val_mae: 0.5265\n",
            "Epoch 190/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.3033 - mae: 0.4800 - val_loss: 0.4109 - val_mae: 0.5280\n",
            "Epoch 191/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.3023 - mae: 0.4791 - val_loss: 0.4126 - val_mae: 0.5296\n",
            "Epoch 192/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.3012 - mae: 0.4783 - val_loss: 0.4142 - val_mae: 0.5311\n",
            "Epoch 193/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.3001 - mae: 0.4774 - val_loss: 0.4159 - val_mae: 0.5327\n",
            "Epoch 194/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - loss: 0.2991 - mae: 0.4766 - val_loss: 0.4176 - val_mae: 0.5342\n",
            "Epoch 195/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 0.2980 - mae: 0.4757 - val_loss: 0.4192 - val_mae: 0.5357\n",
            "Epoch 196/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340ms/step - loss: 0.2969 - mae: 0.4748 - val_loss: 0.4209 - val_mae: 0.5373\n",
            "Epoch 197/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299ms/step - loss: 0.2959 - mae: 0.4740 - val_loss: 0.4226 - val_mae: 0.5388\n",
            "Epoch 198/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 0.2948 - mae: 0.4731 - val_loss: 0.4243 - val_mae: 0.5404\n",
            "Epoch 199/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295ms/step - loss: 0.2938 - mae: 0.4723 - val_loss: 0.4259 - val_mae: 0.5419\n",
            "Epoch 200/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 0.2928 - mae: 0.4714 - val_loss: 0.4276 - val_mae: 0.5434\n",
            "Epoch 1/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.8770 - mae: 0.7439 - val_loss: 0.4881 - val_mae: 0.5964\n",
            "Epoch 2/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.8713 - mae: 0.7408 - val_loss: 0.4814 - val_mae: 0.5917\n",
            "Epoch 3/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.8655 - mae: 0.7378 - val_loss: 0.4746 - val_mae: 0.5869\n",
            "Epoch 4/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.8597 - mae: 0.7347 - val_loss: 0.4679 - val_mae: 0.5825\n",
            "Epoch 5/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.8539 - mae: 0.7334 - val_loss: 0.4612 - val_mae: 0.5784\n",
            "Epoch 6/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.8480 - mae: 0.7321 - val_loss: 0.4545 - val_mae: 0.5743\n",
            "Epoch 7/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 0.8420 - mae: 0.7308 - val_loss: 0.4478 - val_mae: 0.5700\n",
            "Epoch 8/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.8360 - mae: 0.7295 - val_loss: 0.4412 - val_mae: 0.5657\n",
            "Epoch 9/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.8299 - mae: 0.7281 - val_loss: 0.4346 - val_mae: 0.5614\n",
            "Epoch 10/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.8237 - mae: 0.7268 - val_loss: 0.4280 - val_mae: 0.5569\n",
            "Epoch 11/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 0.8176 - mae: 0.7258 - val_loss: 0.4214 - val_mae: 0.5524\n",
            "Epoch 12/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 0.8113 - mae: 0.7248 - val_loss: 0.4149 - val_mae: 0.5478\n",
            "Epoch 13/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.8051 - mae: 0.7237 - val_loss: 0.4084 - val_mae: 0.5431\n",
            "Epoch 14/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 0.7987 - mae: 0.7226 - val_loss: 0.4019 - val_mae: 0.5383\n",
            "Epoch 15/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.7924 - mae: 0.7215 - val_loss: 0.3956 - val_mae: 0.5335\n",
            "Epoch 16/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.7860 - mae: 0.7202 - val_loss: 0.3893 - val_mae: 0.5285\n",
            "Epoch 17/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.7796 - mae: 0.7190 - val_loss: 0.3830 - val_mae: 0.5236\n",
            "Epoch 18/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.7732 - mae: 0.7176 - val_loss: 0.3769 - val_mae: 0.5185\n",
            "Epoch 19/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.7667 - mae: 0.7162 - val_loss: 0.3709 - val_mae: 0.5134\n",
            "Epoch 20/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.7602 - mae: 0.7148 - val_loss: 0.3650 - val_mae: 0.5082\n",
            "Epoch 21/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.7538 - mae: 0.7132 - val_loss: 0.3592 - val_mae: 0.5030\n",
            "Epoch 22/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 0.7473 - mae: 0.7116 - val_loss: 0.3536 - val_mae: 0.4977\n",
            "Epoch 23/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.7408 - mae: 0.7100 - val_loss: 0.3482 - val_mae: 0.4924\n",
            "Epoch 24/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.7344 - mae: 0.7082 - val_loss: 0.3429 - val_mae: 0.4871\n",
            "Epoch 25/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.7279 - mae: 0.7064 - val_loss: 0.3378 - val_mae: 0.4818\n",
            "Epoch 26/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.7215 - mae: 0.7045 - val_loss: 0.3329 - val_mae: 0.4765\n",
            "Epoch 27/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.7152 - mae: 0.7026 - val_loss: 0.3283 - val_mae: 0.4712\n",
            "Epoch 28/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 0.7088 - mae: 0.7005 - val_loss: 0.3239 - val_mae: 0.4659\n",
            "Epoch 29/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.7025 - mae: 0.6985 - val_loss: 0.3197 - val_mae: 0.4607\n",
            "Epoch 30/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 0.6963 - mae: 0.6972 - val_loss: 0.3158 - val_mae: 0.4556\n",
            "Epoch 31/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.6901 - mae: 0.6958 - val_loss: 0.3121 - val_mae: 0.4505\n",
            "Epoch 32/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.6839 - mae: 0.6943 - val_loss: 0.3087 - val_mae: 0.4455\n",
            "Epoch 33/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.6779 - mae: 0.6927 - val_loss: 0.3056 - val_mae: 0.4406\n",
            "Epoch 34/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.6719 - mae: 0.6911 - val_loss: 0.3028 - val_mae: 0.4359\n",
            "Epoch 35/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.6659 - mae: 0.6894 - val_loss: 0.3003 - val_mae: 0.4313\n",
            "Epoch 36/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.6601 - mae: 0.6876 - val_loss: 0.2981 - val_mae: 0.4268\n",
            "Epoch 37/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.6543 - mae: 0.6858 - val_loss: 0.2961 - val_mae: 0.4225\n",
            "Epoch 38/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.6486 - mae: 0.6839 - val_loss: 0.2945 - val_mae: 0.4184\n",
            "Epoch 39/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.6429 - mae: 0.6819 - val_loss: 0.2931 - val_mae: 0.4144\n",
            "Epoch 40/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.6373 - mae: 0.6798 - val_loss: 0.2919 - val_mae: 0.4107\n",
            "Epoch 41/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.6318 - mae: 0.6777 - val_loss: 0.2911 - val_mae: 0.4071\n",
            "Epoch 42/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.6264 - mae: 0.6758 - val_loss: 0.2904 - val_mae: 0.4037\n",
            "Epoch 43/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 0.6211 - mae: 0.6741 - val_loss: 0.2900 - val_mae: 0.4017\n",
            "Epoch 44/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.6158 - mae: 0.6722 - val_loss: 0.2898 - val_mae: 0.4002\n",
            "Epoch 45/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.6106 - mae: 0.6703 - val_loss: 0.2899 - val_mae: 0.3989\n",
            "Epoch 46/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.6054 - mae: 0.6683 - val_loss: 0.2901 - val_mae: 0.3977\n",
            "Epoch 47/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.6003 - mae: 0.6662 - val_loss: 0.2905 - val_mae: 0.3969\n",
            "Epoch 48/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.5953 - mae: 0.6641 - val_loss: 0.2910 - val_mae: 0.3961\n",
            "Epoch 49/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.5903 - mae: 0.6620 - val_loss: 0.2918 - val_mae: 0.3955\n",
            "Epoch 50/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.5854 - mae: 0.6598 - val_loss: 0.2926 - val_mae: 0.3961\n",
            "Epoch 51/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.5806 - mae: 0.6575 - val_loss: 0.2936 - val_mae: 0.3970\n",
            "Epoch 52/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.5758 - mae: 0.6552 - val_loss: 0.2948 - val_mae: 0.3980\n",
            "Epoch 53/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.5711 - mae: 0.6529 - val_loss: 0.2960 - val_mae: 0.4001\n",
            "Epoch 54/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.5664 - mae: 0.6505 - val_loss: 0.2974 - val_mae: 0.4027\n",
            "Epoch 55/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.5618 - mae: 0.6481 - val_loss: 0.2989 - val_mae: 0.4051\n",
            "Epoch 56/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.5572 - mae: 0.6457 - val_loss: 0.3004 - val_mae: 0.4076\n",
            "Epoch 57/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.5526 - mae: 0.6433 - val_loss: 0.3021 - val_mae: 0.4103\n",
            "Epoch 58/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.5482 - mae: 0.6408 - val_loss: 0.3038 - val_mae: 0.4129\n",
            "Epoch 59/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.5437 - mae: 0.6383 - val_loss: 0.3056 - val_mae: 0.4156\n",
            "Epoch 60/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.5393 - mae: 0.6358 - val_loss: 0.3075 - val_mae: 0.4183\n",
            "Epoch 61/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.5350 - mae: 0.6333 - val_loss: 0.3094 - val_mae: 0.4210\n",
            "Epoch 62/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 0.5307 - mae: 0.6308 - val_loss: 0.3114 - val_mae: 0.4236\n",
            "Epoch 63/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.5264 - mae: 0.6283 - val_loss: 0.3134 - val_mae: 0.4263\n",
            "Epoch 64/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.5222 - mae: 0.6258 - val_loss: 0.3155 - val_mae: 0.4290\n",
            "Epoch 65/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.5180 - mae: 0.6232 - val_loss: 0.3176 - val_mae: 0.4316\n",
            "Epoch 66/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.5139 - mae: 0.6207 - val_loss: 0.3198 - val_mae: 0.4343\n",
            "Epoch 67/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.5098 - mae: 0.6182 - val_loss: 0.3220 - val_mae: 0.4369\n",
            "Epoch 68/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 0.5058 - mae: 0.6157 - val_loss: 0.3242 - val_mae: 0.4396\n",
            "Epoch 69/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 0.5018 - mae: 0.6132 - val_loss: 0.3264 - val_mae: 0.4422\n",
            "Epoch 70/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - loss: 0.4979 - mae: 0.6106 - val_loss: 0.3287 - val_mae: 0.4448\n",
            "Epoch 71/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338ms/step - loss: 0.4940 - mae: 0.6082 - val_loss: 0.3310 - val_mae: 0.4474\n",
            "Epoch 72/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: 0.4901 - mae: 0.6057 - val_loss: 0.3334 - val_mae: 0.4500\n",
            "Epoch 73/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step - loss: 0.4863 - mae: 0.6032 - val_loss: 0.3357 - val_mae: 0.4525\n",
            "Epoch 74/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302ms/step - loss: 0.4825 - mae: 0.6007 - val_loss: 0.3381 - val_mae: 0.4550\n",
            "Epoch 75/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 311ms/step - loss: 0.4787 - mae: 0.5983 - val_loss: 0.3404 - val_mae: 0.4576\n",
            "Epoch 76/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276ms/step - loss: 0.4750 - mae: 0.5959 - val_loss: 0.3428 - val_mae: 0.4601\n",
            "Epoch 77/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - loss: 0.4714 - mae: 0.5935 - val_loss: 0.3452 - val_mae: 0.4626\n",
            "Epoch 78/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - loss: 0.4677 - mae: 0.5911 - val_loss: 0.3476 - val_mae: 0.4650\n",
            "Epoch 79/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.4641 - mae: 0.5887 - val_loss: 0.3500 - val_mae: 0.4675\n",
            "Epoch 80/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.4606 - mae: 0.5863 - val_loss: 0.3525 - val_mae: 0.4699\n",
            "Epoch 81/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.4571 - mae: 0.5840 - val_loss: 0.3549 - val_mae: 0.4723\n",
            "Epoch 82/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.4536 - mae: 0.5817 - val_loss: 0.3574 - val_mae: 0.4747\n",
            "Epoch 83/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.4501 - mae: 0.5793 - val_loss: 0.3598 - val_mae: 0.4771\n",
            "Epoch 84/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - loss: 0.4467 - mae: 0.5771 - val_loss: 0.3623 - val_mae: 0.4795\n",
            "Epoch 85/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.4434 - mae: 0.5748 - val_loss: 0.3647 - val_mae: 0.4818\n",
            "Epoch 86/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 0.4400 - mae: 0.5725 - val_loss: 0.3672 - val_mae: 0.4841\n",
            "Epoch 87/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.4367 - mae: 0.5703 - val_loss: 0.3697 - val_mae: 0.4864\n",
            "Epoch 88/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 0.4334 - mae: 0.5681 - val_loss: 0.3722 - val_mae: 0.4887\n",
            "Epoch 89/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.4302 - mae: 0.5659 - val_loss: 0.3747 - val_mae: 0.4914\n",
            "Epoch 90/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - loss: 0.4270 - mae: 0.5637 - val_loss: 0.3772 - val_mae: 0.4944\n",
            "Epoch 91/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.4238 - mae: 0.5615 - val_loss: 0.3797 - val_mae: 0.4975\n",
            "Epoch 92/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.4207 - mae: 0.5593 - val_loss: 0.3822 - val_mae: 0.5005\n",
            "Epoch 93/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.4176 - mae: 0.5572 - val_loss: 0.3847 - val_mae: 0.5035\n",
            "Epoch 94/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.4145 - mae: 0.5550 - val_loss: 0.3873 - val_mae: 0.5065\n",
            "Epoch 95/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 0.4114 - mae: 0.5529 - val_loss: 0.3898 - val_mae: 0.5094\n",
            "Epoch 96/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 0.4084 - mae: 0.5508 - val_loss: 0.3924 - val_mae: 0.5124\n",
            "Epoch 97/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.4054 - mae: 0.5487 - val_loss: 0.3949 - val_mae: 0.5153\n",
            "Epoch 98/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.4025 - mae: 0.5467 - val_loss: 0.3975 - val_mae: 0.5182\n",
            "Epoch 99/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 0.3995 - mae: 0.5449 - val_loss: 0.4000 - val_mae: 0.5211\n",
            "Epoch 100/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - loss: 0.3966 - mae: 0.5431 - val_loss: 0.4026 - val_mae: 0.5239\n",
            "Epoch 101/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step - loss: 0.3938 - mae: 0.5413 - val_loss: 0.4052 - val_mae: 0.5268\n",
            "Epoch 102/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.3909 - mae: 0.5395 - val_loss: 0.4078 - val_mae: 0.5296\n",
            "Epoch 103/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.3881 - mae: 0.5377 - val_loss: 0.4104 - val_mae: 0.5324\n",
            "Epoch 104/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270ms/step - loss: 0.3853 - mae: 0.5359 - val_loss: 0.4131 - val_mae: 0.5352\n",
            "Epoch 105/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.3825 - mae: 0.5341 - val_loss: 0.4157 - val_mae: 0.5380\n",
            "Epoch 106/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.3798 - mae: 0.5323 - val_loss: 0.4183 - val_mae: 0.5407\n",
            "Epoch 107/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.3771 - mae: 0.5305 - val_loss: 0.4210 - val_mae: 0.5435\n",
            "Epoch 108/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 0.3744 - mae: 0.5288 - val_loss: 0.4236 - val_mae: 0.5462\n",
            "Epoch 109/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 0.3718 - mae: 0.5270 - val_loss: 0.4263 - val_mae: 0.5489\n",
            "Epoch 110/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.3691 - mae: 0.5252 - val_loss: 0.4289 - val_mae: 0.5516\n",
            "Epoch 111/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.3665 - mae: 0.5234 - val_loss: 0.4316 - val_mae: 0.5543\n",
            "Epoch 112/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.3639 - mae: 0.5217 - val_loss: 0.4343 - val_mae: 0.5570\n",
            "Epoch 113/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.3614 - mae: 0.5199 - val_loss: 0.4370 - val_mae: 0.5596\n",
            "Epoch 114/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 0.3589 - mae: 0.5181 - val_loss: 0.4397 - val_mae: 0.5623\n",
            "Epoch 115/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.3564 - mae: 0.5164 - val_loss: 0.4424 - val_mae: 0.5649\n",
            "Epoch 116/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.3539 - mae: 0.5147 - val_loss: 0.4451 - val_mae: 0.5675\n",
            "Epoch 117/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.3514 - mae: 0.5130 - val_loss: 0.4478 - val_mae: 0.5701\n",
            "Epoch 118/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.3490 - mae: 0.5114 - val_loss: 0.4505 - val_mae: 0.5727\n",
            "Epoch 119/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - loss: 0.3466 - mae: 0.5097 - val_loss: 0.4532 - val_mae: 0.5753\n",
            "Epoch 120/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - loss: 0.3442 - mae: 0.5080 - val_loss: 0.4560 - val_mae: 0.5778\n",
            "Epoch 121/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.3419 - mae: 0.5064 - val_loss: 0.4587 - val_mae: 0.5804\n",
            "Epoch 122/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.3395 - mae: 0.5050 - val_loss: 0.4614 - val_mae: 0.5829\n",
            "Epoch 123/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.3372 - mae: 0.5035 - val_loss: 0.4642 - val_mae: 0.5854\n",
            "Epoch 124/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.3349 - mae: 0.5021 - val_loss: 0.4669 - val_mae: 0.5879\n",
            "Epoch 125/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.3326 - mae: 0.5007 - val_loss: 0.4697 - val_mae: 0.5904\n",
            "Epoch 126/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 0.3304 - mae: 0.4992 - val_loss: 0.4724 - val_mae: 0.5929\n",
            "Epoch 127/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.3282 - mae: 0.4978 - val_loss: 0.4752 - val_mae: 0.5954\n",
            "Epoch 128/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 0.3260 - mae: 0.4964 - val_loss: 0.4780 - val_mae: 0.5978\n",
            "Epoch 129/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.3238 - mae: 0.4950 - val_loss: 0.4807 - val_mae: 0.6003\n",
            "Epoch 130/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.3216 - mae: 0.4935 - val_loss: 0.4835 - val_mae: 0.6027\n",
            "Epoch 131/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 0.3195 - mae: 0.4921 - val_loss: 0.4863 - val_mae: 0.6052\n",
            "Epoch 132/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step - loss: 0.3174 - mae: 0.4907 - val_loss: 0.4891 - val_mae: 0.6076\n",
            "Epoch 133/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.3153 - mae: 0.4893 - val_loss: 0.4918 - val_mae: 0.6100\n",
            "Epoch 134/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.3132 - mae: 0.4879 - val_loss: 0.4946 - val_mae: 0.6124\n",
            "Epoch 135/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.3112 - mae: 0.4865 - val_loss: 0.4974 - val_mae: 0.6148\n",
            "Epoch 136/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.3091 - mae: 0.4852 - val_loss: 0.5002 - val_mae: 0.6171\n",
            "Epoch 137/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - loss: 0.3071 - mae: 0.4838 - val_loss: 0.5030 - val_mae: 0.6195\n",
            "Epoch 138/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.3051 - mae: 0.4824 - val_loss: 0.5058 - val_mae: 0.6218\n",
            "Epoch 139/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.3032 - mae: 0.4810 - val_loss: 0.5086 - val_mae: 0.6242\n",
            "Epoch 140/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 0.3012 - mae: 0.4797 - val_loss: 0.5114 - val_mae: 0.6265\n",
            "Epoch 141/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.2993 - mae: 0.4783 - val_loss: 0.5142 - val_mae: 0.6288\n",
            "Epoch 142/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.2974 - mae: 0.4769 - val_loss: 0.5170 - val_mae: 0.6311\n",
            "Epoch 143/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.2955 - mae: 0.4756 - val_loss: 0.5198 - val_mae: 0.6334\n",
            "Epoch 144/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 0.2936 - mae: 0.4742 - val_loss: 0.5226 - val_mae: 0.6357\n",
            "Epoch 145/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 0.2917 - mae: 0.4729 - val_loss: 0.5254 - val_mae: 0.6380\n",
            "Epoch 146/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 0.2899 - mae: 0.4716 - val_loss: 0.5282 - val_mae: 0.6403\n",
            "Epoch 147/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - loss: 0.2881 - mae: 0.4702 - val_loss: 0.5310 - val_mae: 0.6425\n",
            "Epoch 148/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 0.2863 - mae: 0.4689 - val_loss: 0.5338 - val_mae: 0.6448\n",
            "Epoch 149/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 307ms/step - loss: 0.2845 - mae: 0.4676 - val_loss: 0.5366 - val_mae: 0.6470\n",
            "Epoch 150/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - loss: 0.2827 - mae: 0.4663 - val_loss: 0.5394 - val_mae: 0.6492\n",
            "Epoch 151/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 0.2810 - mae: 0.4649 - val_loss: 0.5422 - val_mae: 0.6514\n",
            "Epoch 152/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 0.2793 - mae: 0.4636 - val_loss: 0.5450 - val_mae: 0.6536\n",
            "Epoch 153/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step - loss: 0.2775 - mae: 0.4623 - val_loss: 0.5478 - val_mae: 0.6558\n",
            "Epoch 154/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - loss: 0.2758 - mae: 0.4610 - val_loss: 0.5506 - val_mae: 0.6580\n",
            "Epoch 155/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - loss: 0.2742 - mae: 0.4597 - val_loss: 0.5534 - val_mae: 0.6602\n",
            "Epoch 156/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - loss: 0.2725 - mae: 0.4584 - val_loss: 0.5562 - val_mae: 0.6623\n",
            "Epoch 157/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334ms/step - loss: 0.2709 - mae: 0.4571 - val_loss: 0.5590 - val_mae: 0.6645\n",
            "Epoch 158/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - loss: 0.2692 - mae: 0.4559 - val_loss: 0.5618 - val_mae: 0.6666\n",
            "Epoch 159/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.2676 - mae: 0.4546 - val_loss: 0.5646 - val_mae: 0.6687\n",
            "Epoch 160/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.2660 - mae: 0.4533 - val_loss: 0.5674 - val_mae: 0.6708\n",
            "Epoch 161/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.2644 - mae: 0.4521 - val_loss: 0.5702 - val_mae: 0.6729\n",
            "Epoch 162/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 0.2629 - mae: 0.4508 - val_loss: 0.5730 - val_mae: 0.6750\n",
            "Epoch 163/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.2613 - mae: 0.4495 - val_loss: 0.5758 - val_mae: 0.6771\n",
            "Epoch 164/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.2598 - mae: 0.4483 - val_loss: 0.5785 - val_mae: 0.6792\n",
            "Epoch 165/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - loss: 0.2583 - mae: 0.4470 - val_loss: 0.5813 - val_mae: 0.6812\n",
            "Epoch 166/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.2568 - mae: 0.4458 - val_loss: 0.5841 - val_mae: 0.6833\n",
            "Epoch 167/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.2553 - mae: 0.4446 - val_loss: 0.5868 - val_mae: 0.6853\n",
            "Epoch 168/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.2538 - mae: 0.4433 - val_loss: 0.5896 - val_mae: 0.6874\n",
            "Epoch 169/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.2523 - mae: 0.4421 - val_loss: 0.5924 - val_mae: 0.6894\n",
            "Epoch 170/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.2509 - mae: 0.4409 - val_loss: 0.5951 - val_mae: 0.6914\n",
            "Epoch 171/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.2495 - mae: 0.4397 - val_loss: 0.5979 - val_mae: 0.6934\n",
            "Epoch 172/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.2480 - mae: 0.4384 - val_loss: 0.6006 - val_mae: 0.6953\n",
            "Epoch 173/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 0.2466 - mae: 0.4372 - val_loss: 0.6034 - val_mae: 0.6973\n",
            "Epoch 174/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.2453 - mae: 0.4360 - val_loss: 0.6061 - val_mae: 0.6993\n",
            "Epoch 175/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.2439 - mae: 0.4348 - val_loss: 0.6088 - val_mae: 0.7012\n",
            "Epoch 176/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.2425 - mae: 0.4336 - val_loss: 0.6115 - val_mae: 0.7032\n",
            "Epoch 177/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - loss: 0.2412 - mae: 0.4325 - val_loss: 0.6143 - val_mae: 0.7051\n",
            "Epoch 178/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.2398 - mae: 0.4313 - val_loss: 0.6170 - val_mae: 0.7070\n",
            "Epoch 179/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.2385 - mae: 0.4301 - val_loss: 0.6197 - val_mae: 0.7089\n",
            "Epoch 180/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 0.2372 - mae: 0.4289 - val_loss: 0.6224 - val_mae: 0.7108\n",
            "Epoch 181/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.2359 - mae: 0.4278 - val_loss: 0.6251 - val_mae: 0.7127\n",
            "Epoch 182/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 0.2346 - mae: 0.4266 - val_loss: 0.6277 - val_mae: 0.7145\n",
            "Epoch 183/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.2334 - mae: 0.4255 - val_loss: 0.6304 - val_mae: 0.7164\n",
            "Epoch 184/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 0.2321 - mae: 0.4243 - val_loss: 0.6331 - val_mae: 0.7182\n",
            "Epoch 185/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 0.2309 - mae: 0.4232 - val_loss: 0.6357 - val_mae: 0.7201\n",
            "Epoch 186/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.2296 - mae: 0.4220 - val_loss: 0.6384 - val_mae: 0.7219\n",
            "Epoch 187/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - loss: 0.2284 - mae: 0.4209 - val_loss: 0.6410 - val_mae: 0.7237\n",
            "Epoch 188/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.2272 - mae: 0.4198 - val_loss: 0.6437 - val_mae: 0.7255\n",
            "Epoch 189/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.2260 - mae: 0.4186 - val_loss: 0.6463 - val_mae: 0.7273\n",
            "Epoch 190/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.2248 - mae: 0.4175 - val_loss: 0.6489 - val_mae: 0.7291\n",
            "Epoch 191/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.2236 - mae: 0.4164 - val_loss: 0.6515 - val_mae: 0.7308\n",
            "Epoch 192/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - loss: 0.2225 - mae: 0.4153 - val_loss: 0.6541 - val_mae: 0.7326\n",
            "Epoch 193/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - loss: 0.2213 - mae: 0.4142 - val_loss: 0.6567 - val_mae: 0.7343\n",
            "Epoch 194/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.2202 - mae: 0.4131 - val_loss: 0.6593 - val_mae: 0.7361\n",
            "Epoch 195/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.2191 - mae: 0.4120 - val_loss: 0.6619 - val_mae: 0.7378\n",
            "Epoch 196/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.2179 - mae: 0.4109 - val_loss: 0.6644 - val_mae: 0.7395\n",
            "Epoch 197/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 0.2168 - mae: 0.4099 - val_loss: 0.6670 - val_mae: 0.7412\n",
            "Epoch 198/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 0.2157 - mae: 0.4088 - val_loss: 0.6696 - val_mae: 0.7429\n",
            "Epoch 199/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - loss: 0.2146 - mae: 0.4077 - val_loss: 0.6721 - val_mae: 0.7446\n",
            "Epoch 200/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step - loss: 0.2136 - mae: 0.4067 - val_loss: 0.6746 - val_mae: 0.7462\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "    # Vorhersage (skaliert) -> zurückskalieren\n",
        "    y_hat_train_s = model.predict(X_train_z, verbose=0)\n",
        "    y_hat_val_s   = model.predict(X_val_z,   verbose=0)\n",
        "    y_hat_test_s  = model.predict(X_test_z,  verbose=0)\n",
        "\n",
        "    y_hat_train = inv_y(y_hat_train_s)          # (n,2) in realen Einheiten\n",
        "    y_hat_val   = inv_y(y_hat_val_s)\n",
        "    y_hat_test  = inv_y(y_hat_test_s)"
      ],
      "metadata": {
        "id": "0YBfUSrKBSZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Input, Dropout\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "transfer_functions = {\n",
        "    'relu': 'ReLU',\n",
        "    'tanh': 'Tanh',\n",
        "    'sigmoid': 'Sigmoid',\n",
        "    'softplus': 'Softplus'\n",
        "}\n",
        "\n",
        "mse_results = []\n",
        "\n",
        "for activation, name in transfer_functions.items():\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=(X_train.shape[1],)))\n",
        "    model.add(Dense(16, activation=activation))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(2, activation='tanh'))   # ⬅️ zwei Outputs: [Mn, Mw]\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    model.fit(X_train, y_train, batch_size=4, epochs=50, verbose=0)\n",
        "    y_pred = model.predict(X_test, verbose=0)  # Form (n,2)\n",
        "    # Durchschnitts-MSE über beide Outputs (Mn & Mw)\n",
        "    mse = mean_squared_error(y_test, y_pred)   # = uniform_average\n",
        "    mse_results.append(mse)\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(list(transfer_functions.values()), mse_results, marker='o', linestyle='-')\n",
        "plt.title('Mean MSE (Mn & Mw) vs. Transfer Function')\n",
        "plt.xlabel('Transfer Function')\n",
        "plt.ylabel('Mean Squared Error')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "Q9ZIfV65BSWm",
        "outputId": "6998d8e4-f6a1-4037-c092-cbc25bf21aaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ky2flHEEBSUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mEyyme3-BSSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KhVOphxKBSPj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
