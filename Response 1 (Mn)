{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOyv2P2QXfaaf8ypeseEOuX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elhamshaerirahbar-bot/my-colab-project/blob/main/Untitled8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy pandas tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BN3YxBT6udRD",
        "outputId": "f9bb4b6c-7780-4b56-955c-7a7d7e8be643"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.14.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.74.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.8.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02KteuGwudO_",
        "outputId": "52c625b6-cee1-43b6-8291-06fbb5a40750"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np, pandas as pd, re, unicodedata\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, callbacks\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
      ],
      "metadata": {
        "id": "I-aRJMvYudMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd, re, unicodedata\n",
        "from difflib import get_close_matches\n",
        "\n",
        "WANTED = ['factor A','factor B','factor C','factor D','Response 1 (Mn)']\n",
        "\n",
        "def norm(s: str) -> str:\n",
        "    s = unicodedata.normalize(\"NFKC\", str(s))\n",
        "    s = s.replace(\"\\ufeff\",\"\").replace(\"\\u00a0\",\" \")\n",
        "    s = re.sub(r\"\\s+\",\" \", s).strip()\n",
        "    return s.lower()\n",
        "\n",
        "df = pd.read_csv('Python.csv', sep=';', encoding='utf-8-sig')\n",
        "\n",
        "\n",
        "name_map = {norm(c): c for c in df.columns}\n",
        "\n",
        "def map_col(wanted: str):\n",
        "    k = norm(wanted)\n",
        "    if k in name_map:\n",
        "        return name_map[k]\n",
        "\n",
        "    cand = get_close_matches(k, list(name_map.keys()), n=1, cutoff=0.7)\n",
        "    return name_map[cand[0]] if cand else None\n",
        "\n",
        "mapped = [(w, map_col(w)) for w in WANTED]\n",
        "missing = [w for w,c in mapped if c is None]\n",
        "cols    = [c for _,c in mapped if c is not None]\n",
        "\n",
        "print(f\"Missing: {missing}\")\n",
        "\n",
        "n = 5\n",
        "view = df[cols].head(n)\n",
        "try:\n",
        "    display(view)\n",
        "except NameError:\n",
        "    print(view.to_string(index=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "omHH0QstudKS",
        "outputId": "b95d42cd-dce1-4878-b522-c69295fc7cff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing: []\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   factor A  factor B  factor C  factor D        Response 1 (Mn)\n",
              "0       110         7        50        10                1127.19\n",
              "1        85         4        50        30                1127.20\n",
              "2       101         1       500        60                1127.21\n",
              "3        79         1       219        10                1127.22\n",
              "4        50         1       500        20                1127.23"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b20515ac-65c0-4201-a119-d08a82ebd4ee\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>factor A</th>\n",
              "      <th>factor B</th>\n",
              "      <th>factor C</th>\n",
              "      <th>factor D</th>\n",
              "      <th>Response 1 (Mn)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>110</td>\n",
              "      <td>7</td>\n",
              "      <td>50</td>\n",
              "      <td>10</td>\n",
              "      <td>1127.19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>85</td>\n",
              "      <td>4</td>\n",
              "      <td>50</td>\n",
              "      <td>30</td>\n",
              "      <td>1127.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>101</td>\n",
              "      <td>1</td>\n",
              "      <td>500</td>\n",
              "      <td>60</td>\n",
              "      <td>1127.21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>79</td>\n",
              "      <td>1</td>\n",
              "      <td>219</td>\n",
              "      <td>10</td>\n",
              "      <td>1127.22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "      <td>500</td>\n",
              "      <td>20</td>\n",
              "      <td>1127.23</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b20515ac-65c0-4201-a119-d08a82ebd4ee')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b20515ac-65c0-4201-a119-d08a82ebd4ee button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b20515ac-65c0-4201-a119-d08a82ebd4ee');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-b44d00ab-4068-4625-8e8b-6e9e18065a27\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b44d00ab-4068-4625-8e8b-6e9e18065a27')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-b44d00ab-4068-4625-8e8b-6e9e18065a27 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_f7fa0a70-f21d-4080-9a46-c20852414ab8\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('view')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_f7fa0a70-f21d-4080-9a46-c20852414ab8 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('view');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "view",
              "summary": "{\n  \"name\": \"view\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"factor A\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 23,\n        \"min\": 50,\n        \"max\": 110,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          85,\n          50,\n          101\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"factor B\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 1,\n        \"max\": 7,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          7,\n          4,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"factor C\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 226,\n        \"min\": 50,\n        \"max\": 500,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          50,\n          500,\n          219\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"factor D\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 20,\n        \"min\": 10,\n        \"max\": 60,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          30,\n          20,\n          10\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"      Response 1 (Mn)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.015811388300827515,\n        \"min\": 1127.19,\n        \"max\": 1127.23,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1127.2,\n          1127.23,\n          1127.21\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- pick columns via your map_col (no warnings) ----\n",
        "FEATURES = [map_col('factor A'), map_col('factor B'),\n",
        "            map_col('factor C'), map_col('factor D')]\n",
        "TARGET   = map_col('Response 1 (Mn)')\n",
        "\n",
        "X = df[FEATURES].astype(float).to_numpy()      # (n,4)\n",
        "y = df[[TARGET]].astype(float).to_numpy()      # (n,1)"
      ],
      "metadata": {
        "id": "R-HWX3TLudHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.20, shuffle=True, random_state=55\n",
        ")\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train, y_train, test_size=0.20, shuffle=True, random_state=55\n",
        ")\n",
        "\n",
        "SEED = 42\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, shuffle=True, random_state=SEED\n",
        ")"
      ],
      "metadata": {
        "id": "YPmGmQsTudFV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "x_scaler = StandardScaler().fit(X_train)\n",
        "X_train_z = x_scaler.transform(X_train)\n",
        "X_val_z   = x_scaler.transform(X_val)\n",
        "X_test_z  = x_scaler.transform(X_test)\n",
        "\n",
        "y_scaler  = MinMaxScaler(feature_range=(-1, 1)).fit(y_train)\n",
        "y_train_s = y_scaler.transform(y_train)\n",
        "y_val_s   = y_scaler.transform(y_val)\n",
        "y_test_s  = y_scaler.transform(y_test)\n",
        "\n",
        "def inv_y(y_s):\n",
        "    return y_scaler.inverse_transform(y_s)"
      ],
      "metadata": {
        "id": "BsP8ub6RudBK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ann = tf.keras.models.Sequential()"
      ],
      "metadata": {
        "id": "M0WgYx7Tuc8w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(16, activation='relu', input_shape=(X_train.shape[1],)))  # لایه اول\n",
        "model.add(Dropout(0.2))   # 👈 Dropout بعد از هر لایه Dense\n",
        "model.add(Dense(1,  activation='tanh'))  # خروجی\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4OdAY7Uuc6a",
        "outputId": "8f2d44b8-7c27-4ed5-a1cc-00ff0e879e44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RepeatedKFold\n",
        "rkf = RepeatedKFold(n_splits=5, n_repeats=10, random_state=55)"
      ],
      "metadata": {
        "id": "xE_fwP2iuc3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "\n",
        "early_stop = callbacks.EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
        "\n",
        "history = model.fit(\n",
        "    X_train_z, y_train_s,\n",
        "    validation_data=(X_val_z, y_val_s),\n",
        "    epochs=500, batch_size=16, callbacks=[early_stop], verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsPibS17uc1Q",
        "outputId": "9d8c4f0a-2000-4310-8c4f-3f1ec5b0bca1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 417ms/step - loss: 0.5731 - mae: 0.6195 - val_loss: 0.2339 - val_mae: 0.3471\n",
            "Epoch 2/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.4709 - mae: 0.5552 - val_loss: 0.2306 - val_mae: 0.3410\n",
            "Epoch 3/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 246ms/step - loss: 0.6284 - mae: 0.6481 - val_loss: 0.2287 - val_mae: 0.3356\n",
            "Epoch 4/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - loss: 0.6743 - mae: 0.6937 - val_loss: 0.2271 - val_mae: 0.3319\n",
            "Epoch 5/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 323ms/step - loss: 0.5091 - mae: 0.6042 - val_loss: 0.2255 - val_mae: 0.3276\n",
            "Epoch 6/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - loss: 0.4422 - mae: 0.5478 - val_loss: 0.2241 - val_mae: 0.3221\n",
            "Epoch 7/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 426ms/step - loss: 0.4737 - mae: 0.5788 - val_loss: 0.2228 - val_mae: 0.3166\n",
            "Epoch 8/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - loss: 0.4977 - mae: 0.5462 - val_loss: 0.2219 - val_mae: 0.3124\n",
            "Epoch 9/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - loss: 0.4427 - mae: 0.5394 - val_loss: 0.2215 - val_mae: 0.3102\n",
            "Epoch 10/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293ms/step - loss: 0.5807 - mae: 0.6404 - val_loss: 0.2213 - val_mae: 0.3081\n",
            "Epoch 11/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: 0.4252 - mae: 0.4838 - val_loss: 0.2210 - val_mae: 0.3057\n",
            "Epoch 12/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - loss: 0.4684 - mae: 0.5690 - val_loss: 0.2204 - val_mae: 0.3030\n",
            "Epoch 13/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3697 - mae: 0.5205 - val_loss: 0.2196 - val_mae: 0.2998\n",
            "Epoch 14/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3656 - mae: 0.5093 - val_loss: 0.2190 - val_mae: 0.2969\n",
            "Epoch 15/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.5185 - mae: 0.6015 - val_loss: 0.2185 - val_mae: 0.2943\n",
            "Epoch 16/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.4549 - mae: 0.5577 - val_loss: 0.2181 - val_mae: 0.2920\n",
            "Epoch 17/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.4931 - mae: 0.5748 - val_loss: 0.2183 - val_mae: 0.2897\n",
            "Epoch 18/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.4463 - mae: 0.5338 - val_loss: 0.2187 - val_mae: 0.2874\n",
            "Epoch 19/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.4843 - mae: 0.5432 - val_loss: 0.2193 - val_mae: 0.2850\n",
            "Epoch 20/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.4670 - mae: 0.5449 - val_loss: 0.2198 - val_mae: 0.2825\n",
            "Epoch 21/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.5280 - mae: 0.6248 - val_loss: 0.2202 - val_mae: 0.2802\n",
            "Epoch 22/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.5593 - mae: 0.6288 - val_loss: 0.2208 - val_mae: 0.2782\n",
            "Epoch 23/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.4337 - mae: 0.5184 - val_loss: 0.2215 - val_mae: 0.2760\n",
            "Epoch 24/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.4279 - mae: 0.5077 - val_loss: 0.2222 - val_mae: 0.2741\n",
            "Epoch 25/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.3982 - mae: 0.4961 - val_loss: 0.2231 - val_mae: 0.2722\n",
            "Epoch 26/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.3947 - mae: 0.5395 - val_loss: 0.2238 - val_mae: 0.2701\n",
            "Epoch 27/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.5057 - mae: 0.6059 - val_loss: 0.2243 - val_mae: 0.2685\n",
            "Epoch 28/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.4749 - mae: 0.5889 - val_loss: 0.2243 - val_mae: 0.2709\n",
            "Epoch 29/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.4093 - mae: 0.5073 - val_loss: 0.2236 - val_mae: 0.2716\n",
            "Epoch 30/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.5190 - mae: 0.5943 - val_loss: 0.2222 - val_mae: 0.2718\n",
            "Epoch 31/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.4243 - mae: 0.5107 - val_loss: 0.2211 - val_mae: 0.2728\n",
            "Epoch 32/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.4615 - mae: 0.5525 - val_loss: 0.2203 - val_mae: 0.2743\n",
            "Epoch 33/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.4966 - mae: 0.5959 - val_loss: 0.2191 - val_mae: 0.2754\n",
            "Epoch 34/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.4260 - mae: 0.5615 - val_loss: 0.2183 - val_mae: 0.2763\n",
            "Epoch 35/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3696 - mae: 0.5170 - val_loss: 0.2175 - val_mae: 0.2770\n",
            "Epoch 36/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3976 - mae: 0.5312 - val_loss: 0.2162 - val_mae: 0.2769\n",
            "Epoch 37/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.4333 - mae: 0.5747 - val_loss: 0.2141 - val_mae: 0.2756\n",
            "Epoch 38/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.3711 - mae: 0.4733 - val_loss: 0.2116 - val_mae: 0.2743\n",
            "Epoch 39/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.4042 - mae: 0.5223 - val_loss: 0.2100 - val_mae: 0.2742\n",
            "Epoch 40/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3727 - mae: 0.4915 - val_loss: 0.2089 - val_mae: 0.2748\n",
            "Epoch 41/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.4299 - mae: 0.5643 - val_loss: 0.2084 - val_mae: 0.2764\n",
            "Epoch 42/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3839 - mae: 0.5043 - val_loss: 0.2083 - val_mae: 0.2784\n",
            "Epoch 43/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.4227 - mae: 0.5526 - val_loss: 0.2085 - val_mae: 0.2808\n",
            "Epoch 44/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.4342 - mae: 0.5412 - val_loss: 0.2085 - val_mae: 0.2828\n",
            "Epoch 45/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3693 - mae: 0.5485 - val_loss: 0.2077 - val_mae: 0.2833\n",
            "Epoch 46/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.4258 - mae: 0.5311 - val_loss: 0.2070 - val_mae: 0.2839\n",
            "Epoch 47/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.4522 - mae: 0.5519 - val_loss: 0.2069 - val_mae: 0.2850\n",
            "Epoch 48/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3494 - mae: 0.4660 - val_loss: 0.2075 - val_mae: 0.2873\n",
            "Epoch 49/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.2561 - mae: 0.4277 - val_loss: 0.2083 - val_mae: 0.2900\n",
            "Epoch 50/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.4170 - mae: 0.5631 - val_loss: 0.2090 - val_mae: 0.2924\n",
            "Epoch 51/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3710 - mae: 0.5316 - val_loss: 0.2093 - val_mae: 0.2942\n",
            "Epoch 52/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.4312 - mae: 0.5214 - val_loss: 0.2096 - val_mae: 0.2955\n",
            "Epoch 53/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.3583 - mae: 0.5043 - val_loss: 0.2101 - val_mae: 0.2971\n",
            "Epoch 54/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.3487 - mae: 0.4792 - val_loss: 0.2104 - val_mae: 0.2987\n",
            "Epoch 55/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3709 - mae: 0.5185 - val_loss: 0.2107 - val_mae: 0.3002\n",
            "Epoch 56/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3562 - mae: 0.5076 - val_loss: 0.2113 - val_mae: 0.3021\n",
            "Epoch 57/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.4310 - mae: 0.5722 - val_loss: 0.2126 - val_mae: 0.3048\n",
            "Epoch 58/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.4021 - mae: 0.5027 - val_loss: 0.2135 - val_mae: 0.3070\n",
            "Epoch 59/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3937 - mae: 0.5481 - val_loss: 0.2139 - val_mae: 0.3085\n",
            "Epoch 60/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.4036 - mae: 0.5643 - val_loss: 0.2141 - val_mae: 0.3098\n",
            "Epoch 61/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.4451 - mae: 0.5765 - val_loss: 0.2144 - val_mae: 0.3109\n",
            "Epoch 62/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.3235 - mae: 0.4739 - val_loss: 0.2149 - val_mae: 0.3125\n",
            "Epoch 63/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3075 - mae: 0.4529 - val_loss: 0.2156 - val_mae: 0.3140\n",
            "Epoch 64/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.4539 - mae: 0.6045 - val_loss: 0.2164 - val_mae: 0.3156\n",
            "Epoch 65/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.4299 - mae: 0.5630 - val_loss: 0.2169 - val_mae: 0.3166\n",
            "Epoch 66/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.3703 - mae: 0.5073 - val_loss: 0.2164 - val_mae: 0.3161\n",
            "Epoch 67/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.3721 - mae: 0.4848 - val_loss: 0.2155 - val_mae: 0.3150\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "y_hat_train = inv_y(model.predict(X_train_z, verbose=1))\n",
        "y_hat_val   = inv_y(model.predict(X_val_z,   verbose=1))\n",
        "y_hat_test  = inv_y(model.predict(X_test_z,  verbose=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLMBpR1Vucu9",
        "outputId": "1d952781-3c25-4c54-ba53-e3c41537e87f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install matplotlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLe3GkNIucqB",
        "outputId": "b6213314-a5ba-4605-db26-b57fbdddeef8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.59.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "a-l59rc2v88f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def report(name, yt, yp):\n",
        "    mse = mean_squared_error(yt, yp)\n",
        "    mae = mean_absolute_error(yt, yp)\n",
        "    r2  = r2_score(yt, yp)\n",
        "    print(f\"[{name}] MSE={mse:.6f}  MAE={mae:.6f}  R²={r2:.4f}\")\n",
        "\n",
        "print(\"\\n== Performance (real units) ==\")\n",
        "report(\"Train\", y_train, y_hat_train)\n",
        "report(\"Val  \", y_val,   y_hat_val)\n",
        "report(\"Test \", y_test,  y_hat_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRI-nPxRv855",
        "outputId": "68ce3d7b-f2e1-4805-99aa-86ee52ea106e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "== Performance (real units) ==\n",
            "[Train] MSE=0.004872  MAE=0.058823  R²=0.0273\n",
            "[Val  ] MSE=0.002734  MAE=0.032738  R²=0.0655\n",
            "[Test ] MSE=0.002997  MAE=0.050315  R²=0.4958\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np, pandas as pd\n",
        "\n",
        "def make_table(split, y_true, y_pred, n=None):\n",
        "    y_true = np.asarray(y_true).reshape(-1)\n",
        "    y_pred = np.asarray(y_pred).reshape(-1)\n",
        "    tbl = pd.DataFrame({\n",
        "        \"split\":     split,\n",
        "        \"actual\":    y_true,\n",
        "        \"predicted\": y_pred,\n",
        "    })\n",
        "    tbl[\"residual\"]  = tbl[\"actual\"] - tbl[\"predicted\"]\n",
        "    tbl[\"abs_error\"] = tbl[\"residual\"].abs()\n",
        "    tbl[\"pct_error\"] = 100 * tbl[\"abs_error\"] / np.maximum(1e-8, np.abs(tbl[\"actual\"]))\n",
        "    return tbl if n is None else tbl.head(n)\n",
        "\n",
        "tbl_train = make_table(\"Train\", y_train, y_hat_train)\n",
        "tbl_val   = make_table(\"Val\",   y_val,   y_hat_val)\n",
        "tbl_test  = make_table(\"Test\",  y_test,  y_hat_test)\n",
        "\n",
        "tbl_all = pd.concat([tbl_train, tbl_val, tbl_test], ignore_index=True)\n",
        "print(tbl_all.to_string(index=False))         # یا display(tbl_all) در نوت‌بوک"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9ynSIXXBe9K",
        "outputId": "dca090bf-9607-462a-a97a-deca0f529aea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "split  actual   predicted  residual  abs_error  pct_error\n",
            "Train 1127.28 1127.326538 -0.046538   0.046538   0.004128\n",
            "Train 1127.32 1127.330688 -0.010688   0.010688   0.000948\n",
            "Train 1127.20 1127.295776 -0.095776   0.095776   0.008497\n",
            "Train 1127.41 1127.306763  0.103237   0.103237   0.009157\n",
            "Train 1127.24 1127.289429 -0.049429   0.049429   0.004385\n",
            "Train 1127.21 1127.305786 -0.095786   0.095786   0.008498\n",
            "Train 1127.31 1127.335205 -0.025205   0.025205   0.002236\n",
            "Train 1127.34 1127.305786  0.034214   0.034214   0.003035\n",
            "Train 1127.22 1127.295776 -0.075776   0.075776   0.006722\n",
            "Train 1127.23 1127.374268 -0.144268   0.144268   0.012798\n",
            "Train 1127.39 1127.296631  0.093369   0.093369   0.008282\n",
            "Train 1127.36 1127.326294  0.033706   0.033706   0.002990\n",
            "Train 1127.40 1127.326538  0.073462   0.073462   0.006516\n",
            "Train 1127.37 1127.311768  0.058232   0.058232   0.005165\n",
            "Train 1127.43 1127.326904  0.103096   0.103096   0.009144\n",
            "Train 1127.26 1127.324097 -0.064097   0.064097   0.005686\n",
            "Train 1127.29 1127.276733  0.013267   0.013267   0.001177\n",
            "Train 1127.33 1127.289429  0.040571   0.040571   0.003599\n",
            "Train 1127.38 1127.376099  0.003901   0.003901   0.000346\n",
            "Train 1127.25 1127.261841 -0.011841   0.011841   0.001050\n",
            "  Val 1127.38 1127.376099  0.003901   0.003901   0.000346\n",
            "  Val 1127.32 1127.330688 -0.010688   0.010688   0.000948\n",
            "  Val 1127.29 1127.276733  0.013267   0.013267   0.001177\n",
            "  Val 1127.43 1127.326904  0.103096   0.103096   0.009144\n",
            " Test 1127.27 1127.347046 -0.077046   0.077046   0.006835\n",
            " Test 1127.35 1127.330688  0.019312   0.019312   0.001713\n",
            " Test 1127.19 1127.227539 -0.037539   0.037539   0.003330\n",
            " Test 1127.42 1127.374268  0.045732   0.045732   0.004056\n",
            " Test 1127.30 1127.371948 -0.071948   0.071948   0.006382\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "def diag(name, y_true, y_pred):\n",
        "    var = np.var(y_true, ddof=0)\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    mse_mean = mean_squared_error(y_true, np.full_like(y_true, y_true.mean()))\n",
        "    r2  = r2_score(y_true, y_pred)\n",
        "    print(f\"{name}: n={len(y_true)}  Var(y)={var:.6f}  MSE(model)={mse:.6f}  MSE(mean)={mse_mean:.6f}  R²={r2:.4f}\")\n",
        "\n",
        "diag(\"Train\", y_train, y_hat_train)\n",
        "diag(\"Val  \", y_val,   y_hat_val)\n",
        "diag(\"Test \", y_test,  y_hat_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fGsA0jcv83V",
        "outputId": "ce3b53ca-6bde-4db5-c464-6e34b0a9ea7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: n=20  Var(y)=0.005009  MSE(model)=0.004872  MSE(mean)=0.005009  R²=0.0273\n",
            "Val  : n=4  Var(y)=0.002925  MSE(model)=0.002734  MSE(mean)=0.002925  R²=0.0655\n",
            "Test : n=5  Var(y)=0.005944  MSE(model)=0.002997  MSE(mean)=0.005944  R²=0.4958\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.model_selection import RepeatedKFold, cross_val_score\n",
        "import numpy as np\n",
        "\n",
        "rkf = RepeatedKFold(n_splits=5, n_repeats=20, random_state=42)\n",
        "\n",
        "pipe = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"ridge\", Ridge(alpha=1.0))\n",
        "])\n",
        "\n",
        "scores = cross_val_score(pipe, X, y.ravel(), cv=rkf, scoring=\"r2\")\n",
        "print(\"Baseline Ridge  R²: mean=%.3f  std=%.3f\" % (scores.mean(), scores.std()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4m-KcWfy72q",
        "outputId": "36365bbe-d263-4c36-b067-c06142f32a02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline Ridge  R²: mean=-1.314  std=2.614\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- 0) Reproducibility / Determinism ----\n",
        "import os, random, numpy as np, tensorflow as tf\n",
        "\n",
        "SEED = 42\n",
        "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
        "os.environ[\"TF_DETERMINISTIC_OPS\"] = \"1\"\n",
        "\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "try:\n",
        "    tf.keras.utils.set_random_seed(SEED)\n",
        "    tf.config.experimental.enable_op_determinism(True)\n",
        "except Exception:\n",
        "    pass"
      ],
      "metadata": {
        "id": "nLu32xtozCkz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- 5) Activation (Transfer Function) sweep on hidden layers ----\n",
        "import random, numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, optimizers\n",
        "\n",
        "activations = ['relu', 'tanh', 'sigmoid', 'softplus']\n",
        "labels      = ['ReLU', 'Tanh', 'Sigmoid', 'Softplus']\n",
        "\n",
        "val_mse_real  = []\n",
        "test_mse_real = []"
      ],
      "metadata": {
        "id": "c8DT07SNzCiM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for act in activations:\n",
        "\n",
        "    tf.keras.backend.clear_session()\n",
        "    np.random.seed(SEED); random.seed(SEED); tf.random.set_seed(SEED)\n",
        "\n",
        "    model = tf.keras.Sequential([\n",
        "        layers.Input(shape=(X_train_z.shape[1],)),\n",
        "        layers.Dense(16, activation=act),\n",
        "        layers.Dense(1,  activation='tanh')\n",
        "    ])\n",
        "    model.compile(optimizer=optimizers.Adam(learning_rate=1e-3), loss='mse')\n",
        "\n",
        "\n",
        "    history = model.fit(\n",
        "        X_train_z, y_train_s,\n",
        "        validation_data=(X_val_z, y_val_s),\n",
        "        epochs=200, batch_size=16, shuffle=True, verbose=1,\n",
        "        callbacks=[]\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qr5llTjvzCgH",
        "outputId": "0c8758c6-f4a5-44b1-98cb-6326925d2823"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 185ms/step - loss: 0.6411 - val_loss: 0.1833\n",
            "Epoch 2/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.6328 - val_loss: 0.1837\n",
            "Epoch 3/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.6257 - val_loss: 0.1838\n",
            "Epoch 4/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.6187 - val_loss: 0.1839\n",
            "Epoch 5/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.6118 - val_loss: 0.1840\n",
            "Epoch 6/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.6050 - val_loss: 0.1842\n",
            "Epoch 7/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.5982 - val_loss: 0.1849\n",
            "Epoch 8/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.5915 - val_loss: 0.1856\n",
            "Epoch 9/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.5847 - val_loss: 0.1863\n",
            "Epoch 10/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.5779 - val_loss: 0.1870\n",
            "Epoch 11/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.5712 - val_loss: 0.1876\n",
            "Epoch 12/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.5644 - val_loss: 0.1882\n",
            "Epoch 13/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.5576 - val_loss: 0.1887\n",
            "Epoch 14/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.5508 - val_loss: 0.1892\n",
            "Epoch 15/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.5440 - val_loss: 0.1897\n",
            "Epoch 16/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.5373 - val_loss: 0.1901\n",
            "Epoch 17/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.5305 - val_loss: 0.1904\n",
            "Epoch 18/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.5238 - val_loss: 0.1907\n",
            "Epoch 19/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.5171 - val_loss: 0.1909\n",
            "Epoch 20/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.5104 - val_loss: 0.1911\n",
            "Epoch 21/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.5039 - val_loss: 0.1912\n",
            "Epoch 22/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.4974 - val_loss: 0.1912\n",
            "Epoch 23/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.4909 - val_loss: 0.1911\n",
            "Epoch 24/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.4844 - val_loss: 0.1909\n",
            "Epoch 25/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.4781 - val_loss: 0.1906\n",
            "Epoch 26/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.4719 - val_loss: 0.1902\n",
            "Epoch 27/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.4659 - val_loss: 0.1897\n",
            "Epoch 28/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.4600 - val_loss: 0.1892\n",
            "Epoch 29/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.4544 - val_loss: 0.1885\n",
            "Epoch 30/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.4490 - val_loss: 0.1878\n",
            "Epoch 31/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.4438 - val_loss: 0.1871\n",
            "Epoch 32/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.4388 - val_loss: 0.1862\n",
            "Epoch 33/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.4342 - val_loss: 0.1854\n",
            "Epoch 34/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.4298 - val_loss: 0.1844\n",
            "Epoch 35/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.4256 - val_loss: 0.1834\n",
            "Epoch 36/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.4216 - val_loss: 0.1823\n",
            "Epoch 37/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.4179 - val_loss: 0.1812\n",
            "Epoch 38/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.4143 - val_loss: 0.1800\n",
            "Epoch 39/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.4109 - val_loss: 0.1788\n",
            "Epoch 40/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.4077 - val_loss: 0.1776\n",
            "Epoch 41/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.4046 - val_loss: 0.1764\n",
            "Epoch 42/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.4017 - val_loss: 0.1752\n",
            "Epoch 43/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.3988 - val_loss: 0.1741\n",
            "Epoch 44/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.3961 - val_loss: 0.1729\n",
            "Epoch 45/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.3936 - val_loss: 0.1718\n",
            "Epoch 46/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.3911 - val_loss: 0.1707\n",
            "Epoch 47/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.3887 - val_loss: 0.1696\n",
            "Epoch 48/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.3864 - val_loss: 0.1686\n",
            "Epoch 49/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3842 - val_loss: 0.1676\n",
            "Epoch 50/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.3820 - val_loss: 0.1667\n",
            "Epoch 51/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.3799 - val_loss: 0.1658\n",
            "Epoch 52/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.3779 - val_loss: 0.1649\n",
            "Epoch 53/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.3760 - val_loss: 0.1641\n",
            "Epoch 54/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.3741 - val_loss: 0.1634\n",
            "Epoch 55/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.3722 - val_loss: 0.1626\n",
            "Epoch 56/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.3705 - val_loss: 0.1619\n",
            "Epoch 57/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.3688 - val_loss: 0.1613\n",
            "Epoch 58/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.3672 - val_loss: 0.1607\n",
            "Epoch 59/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3656 - val_loss: 0.1601\n",
            "Epoch 60/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.3641 - val_loss: 0.1596\n",
            "Epoch 61/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.3628 - val_loss: 0.1591\n",
            "Epoch 62/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.3615 - val_loss: 0.1586\n",
            "Epoch 63/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3602 - val_loss: 0.1581\n",
            "Epoch 64/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.3590 - val_loss: 0.1576\n",
            "Epoch 65/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3579 - val_loss: 0.1572\n",
            "Epoch 66/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3567 - val_loss: 0.1567\n",
            "Epoch 67/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3556 - val_loss: 0.1563\n",
            "Epoch 68/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3546 - val_loss: 0.1560\n",
            "Epoch 69/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.3535 - val_loss: 0.1556\n",
            "Epoch 70/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.3526 - val_loss: 0.1553\n",
            "Epoch 71/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.3516 - val_loss: 0.1551\n",
            "Epoch 72/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3508 - val_loss: 0.1548\n",
            "Epoch 73/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3499 - val_loss: 0.1545\n",
            "Epoch 74/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3491 - val_loss: 0.1541\n",
            "Epoch 75/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.3482 - val_loss: 0.1538\n",
            "Epoch 76/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3474 - val_loss: 0.1535\n",
            "Epoch 77/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3467 - val_loss: 0.1533\n",
            "Epoch 78/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.3459 - val_loss: 0.1530\n",
            "Epoch 79/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.3451 - val_loss: 0.1527\n",
            "Epoch 80/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.3444 - val_loss: 0.1525\n",
            "Epoch 81/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.3437 - val_loss: 0.1522\n",
            "Epoch 82/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3430 - val_loss: 0.1519\n",
            "Epoch 83/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.3423 - val_loss: 0.1517\n",
            "Epoch 84/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.3416 - val_loss: 0.1514\n",
            "Epoch 85/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.3409 - val_loss: 0.1512\n",
            "Epoch 86/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.3402 - val_loss: 0.1509\n",
            "Epoch 87/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3396 - val_loss: 0.1507\n",
            "Epoch 88/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.3390 - val_loss: 0.1505\n",
            "Epoch 89/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.3383 - val_loss: 0.1503\n",
            "Epoch 90/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.3377 - val_loss: 0.1502\n",
            "Epoch 91/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3371 - val_loss: 0.1500\n",
            "Epoch 92/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.3365 - val_loss: 0.1498\n",
            "Epoch 93/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3359 - val_loss: 0.1497\n",
            "Epoch 94/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.3353 - val_loss: 0.1495\n",
            "Epoch 95/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.3348 - val_loss: 0.1494\n",
            "Epoch 96/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.3342 - val_loss: 0.1492\n",
            "Epoch 97/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.3336 - val_loss: 0.1491\n",
            "Epoch 98/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.3330 - val_loss: 0.1489\n",
            "Epoch 99/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.3325 - val_loss: 0.1487\n",
            "Epoch 100/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.3319 - val_loss: 0.1486\n",
            "Epoch 101/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3314 - val_loss: 0.1484\n",
            "Epoch 102/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.3308 - val_loss: 0.1482\n",
            "Epoch 103/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.3303 - val_loss: 0.1481\n",
            "Epoch 104/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.3297 - val_loss: 0.1479\n",
            "Epoch 105/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.3292 - val_loss: 0.1477\n",
            "Epoch 106/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.3287 - val_loss: 0.1476\n",
            "Epoch 107/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.3282 - val_loss: 0.1475\n",
            "Epoch 108/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3277 - val_loss: 0.1473\n",
            "Epoch 109/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.3272 - val_loss: 0.1472\n",
            "Epoch 110/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.3268 - val_loss: 0.1470\n",
            "Epoch 111/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.3263 - val_loss: 0.1468\n",
            "Epoch 112/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.3258 - val_loss: 0.1467\n",
            "Epoch 113/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3253 - val_loss: 0.1466\n",
            "Epoch 114/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.3249 - val_loss: 0.1464\n",
            "Epoch 115/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3244 - val_loss: 0.1462\n",
            "Epoch 116/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.3240 - val_loss: 0.1461\n",
            "Epoch 117/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3235 - val_loss: 0.1459\n",
            "Epoch 118/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.3231 - val_loss: 0.1457\n",
            "Epoch 119/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.3227 - val_loss: 0.1456\n",
            "Epoch 120/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.3222 - val_loss: 0.1454\n",
            "Epoch 121/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3218 - val_loss: 0.1453\n",
            "Epoch 122/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.3214 - val_loss: 0.1451\n",
            "Epoch 123/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3210 - val_loss: 0.1449\n",
            "Epoch 124/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3206 - val_loss: 0.1448\n",
            "Epoch 125/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.3202 - val_loss: 0.1446\n",
            "Epoch 126/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.3198 - val_loss: 0.1445\n",
            "Epoch 127/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.3194 - val_loss: 0.1445\n",
            "Epoch 128/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.3191 - val_loss: 0.1444\n",
            "Epoch 129/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.3187 - val_loss: 0.1444\n",
            "Epoch 130/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.3183 - val_loss: 0.1444\n",
            "Epoch 131/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3180 - val_loss: 0.1443\n",
            "Epoch 132/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.3176 - val_loss: 0.1443\n",
            "Epoch 133/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.3173 - val_loss: 0.1443\n",
            "Epoch 134/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.3169 - val_loss: 0.1443\n",
            "Epoch 135/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.3165 - val_loss: 0.1442\n",
            "Epoch 136/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 0.3162 - val_loss: 0.1441\n",
            "Epoch 137/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.3158 - val_loss: 0.1441\n",
            "Epoch 138/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.3155 - val_loss: 0.1441\n",
            "Epoch 139/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3152 - val_loss: 0.1440\n",
            "Epoch 140/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.3148 - val_loss: 0.1439\n",
            "Epoch 141/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.3145 - val_loss: 0.1439\n",
            "Epoch 142/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3141 - val_loss: 0.1438\n",
            "Epoch 143/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.3138 - val_loss: 0.1438\n",
            "Epoch 144/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3134 - val_loss: 0.1437\n",
            "Epoch 145/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3131 - val_loss: 0.1436\n",
            "Epoch 146/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.3128 - val_loss: 0.1436\n",
            "Epoch 147/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.3125 - val_loss: 0.1435\n",
            "Epoch 148/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.3122 - val_loss: 0.1434\n",
            "Epoch 149/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.3118 - val_loss: 0.1434\n",
            "Epoch 150/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.3115 - val_loss: 0.1433\n",
            "Epoch 151/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.3112 - val_loss: 0.1432\n",
            "Epoch 152/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.3109 - val_loss: 0.1431\n",
            "Epoch 153/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.3105 - val_loss: 0.1430\n",
            "Epoch 154/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3102 - val_loss: 0.1430\n",
            "Epoch 155/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3099 - val_loss: 0.1429\n",
            "Epoch 156/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3096 - val_loss: 0.1428\n",
            "Epoch 157/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.3093 - val_loss: 0.1427\n",
            "Epoch 158/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.3089 - val_loss: 0.1426\n",
            "Epoch 159/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.3086 - val_loss: 0.1425\n",
            "Epoch 160/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.3083 - val_loss: 0.1424\n",
            "Epoch 161/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3080 - val_loss: 0.1422\n",
            "Epoch 162/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.3077 - val_loss: 0.1422\n",
            "Epoch 163/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3074 - val_loss: 0.1421\n",
            "Epoch 164/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3071 - val_loss: 0.1420\n",
            "Epoch 165/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.3068 - val_loss: 0.1419\n",
            "Epoch 166/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3064 - val_loss: 0.1418\n",
            "Epoch 167/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3061 - val_loss: 0.1417\n",
            "Epoch 168/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.3058 - val_loss: 0.1416\n",
            "Epoch 169/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.3055 - val_loss: 0.1414\n",
            "Epoch 170/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3052 - val_loss: 0.1413\n",
            "Epoch 171/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3049 - val_loss: 0.1412\n",
            "Epoch 172/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3046 - val_loss: 0.1411\n",
            "Epoch 173/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3043 - val_loss: 0.1410\n",
            "Epoch 174/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3040 - val_loss: 0.1408\n",
            "Epoch 175/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.3037 - val_loss: 0.1407\n",
            "Epoch 176/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3034 - val_loss: 0.1406\n",
            "Epoch 177/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.3031 - val_loss: 0.1405\n",
            "Epoch 178/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.3028 - val_loss: 0.1404\n",
            "Epoch 179/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.3025 - val_loss: 0.1402\n",
            "Epoch 180/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3022 - val_loss: 0.1401\n",
            "Epoch 181/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.3019 - val_loss: 0.1400\n",
            "Epoch 182/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3016 - val_loss: 0.1399\n",
            "Epoch 183/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.3013 - val_loss: 0.1398\n",
            "Epoch 184/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.3010 - val_loss: 0.1396\n",
            "Epoch 185/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.3007 - val_loss: 0.1395\n",
            "Epoch 186/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3004 - val_loss: 0.1393\n",
            "Epoch 187/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3001 - val_loss: 0.1392\n",
            "Epoch 188/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.2998 - val_loss: 0.1390\n",
            "Epoch 189/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.2995 - val_loss: 0.1388\n",
            "Epoch 190/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.2993 - val_loss: 0.1385\n",
            "Epoch 191/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.2990 - val_loss: 0.1384\n",
            "Epoch 192/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.2988 - val_loss: 0.1382\n",
            "Epoch 193/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.2985 - val_loss: 0.1380\n",
            "Epoch 194/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2982 - val_loss: 0.1378\n",
            "Epoch 195/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.2979 - val_loss: 0.1377\n",
            "Epoch 196/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2976 - val_loss: 0.1375\n",
            "Epoch 197/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.2973 - val_loss: 0.1374\n",
            "Epoch 198/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.2971 - val_loss: 0.1372\n",
            "Epoch 199/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.2968 - val_loss: 0.1370\n",
            "Epoch 200/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.2965 - val_loss: 0.1368\n",
            "Epoch 1/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 181ms/step - loss: 0.8246 - val_loss: 0.1316\n",
            "Epoch 2/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.8169 - val_loss: 0.1276\n",
            "Epoch 3/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.8101 - val_loss: 0.1236\n",
            "Epoch 4/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.8034 - val_loss: 0.1199\n",
            "Epoch 5/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.7966 - val_loss: 0.1166\n",
            "Epoch 6/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.7897 - val_loss: 0.1136\n",
            "Epoch 7/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.7828 - val_loss: 0.1110\n",
            "Epoch 8/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.7757 - val_loss: 0.1088\n",
            "Epoch 9/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.7685 - val_loss: 0.1069\n",
            "Epoch 10/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.7611 - val_loss: 0.1053\n",
            "Epoch 11/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.7536 - val_loss: 0.1040\n",
            "Epoch 12/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.7459 - val_loss: 0.1029\n",
            "Epoch 13/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.7380 - val_loss: 0.1021\n",
            "Epoch 14/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.7299 - val_loss: 0.1014\n",
            "Epoch 15/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.7217 - val_loss: 0.1010\n",
            "Epoch 16/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.7133 - val_loss: 0.1007\n",
            "Epoch 17/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.7047 - val_loss: 0.1005\n",
            "Epoch 18/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.6960 - val_loss: 0.1005\n",
            "Epoch 19/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.6871 - val_loss: 0.1005\n",
            "Epoch 20/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.6782 - val_loss: 0.1007\n",
            "Epoch 21/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.6692 - val_loss: 0.1009\n",
            "Epoch 22/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 0.6602 - val_loss: 0.1011\n",
            "Epoch 23/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.6512 - val_loss: 0.1015\n",
            "Epoch 24/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.6423 - val_loss: 0.1018\n",
            "Epoch 25/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.6334 - val_loss: 0.1022\n",
            "Epoch 26/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.6247 - val_loss: 0.1025\n",
            "Epoch 27/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.6162 - val_loss: 0.1029\n",
            "Epoch 28/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.6079 - val_loss: 0.1033\n",
            "Epoch 29/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.5998 - val_loss: 0.1037\n",
            "Epoch 30/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.5921 - val_loss: 0.1041\n",
            "Epoch 31/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.5846 - val_loss: 0.1044\n",
            "Epoch 32/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.5775 - val_loss: 0.1047\n",
            "Epoch 33/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.5707 - val_loss: 0.1050\n",
            "Epoch 34/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.5643 - val_loss: 0.1052\n",
            "Epoch 35/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.5582 - val_loss: 0.1054\n",
            "Epoch 36/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.5524 - val_loss: 0.1055\n",
            "Epoch 37/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.5469 - val_loss: 0.1056\n",
            "Epoch 38/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.5417 - val_loss: 0.1057\n",
            "Epoch 39/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.5367 - val_loss: 0.1057\n",
            "Epoch 40/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.5319 - val_loss: 0.1057\n",
            "Epoch 41/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.5273 - val_loss: 0.1057\n",
            "Epoch 42/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.5229 - val_loss: 0.1056\n",
            "Epoch 43/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.5186 - val_loss: 0.1056\n",
            "Epoch 44/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.5145 - val_loss: 0.1056\n",
            "Epoch 45/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.5104 - val_loss: 0.1056\n",
            "Epoch 46/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.5065 - val_loss: 0.1057\n",
            "Epoch 47/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.5026 - val_loss: 0.1058\n",
            "Epoch 48/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.4989 - val_loss: 0.1059\n",
            "Epoch 49/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.4953 - val_loss: 0.1061\n",
            "Epoch 50/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.4917 - val_loss: 0.1064\n",
            "Epoch 51/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.4882 - val_loss: 0.1068\n",
            "Epoch 52/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.4849 - val_loss: 0.1072\n",
            "Epoch 53/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.4816 - val_loss: 0.1076\n",
            "Epoch 54/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.4785 - val_loss: 0.1081\n",
            "Epoch 55/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.4754 - val_loss: 0.1087\n",
            "Epoch 56/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.4724 - val_loss: 0.1093\n",
            "Epoch 57/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.4696 - val_loss: 0.1100\n",
            "Epoch 58/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.4668 - val_loss: 0.1107\n",
            "Epoch 59/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.4642 - val_loss: 0.1114\n",
            "Epoch 60/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.4616 - val_loss: 0.1121\n",
            "Epoch 61/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.4592 - val_loss: 0.1128\n",
            "Epoch 62/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.4568 - val_loss: 0.1135\n",
            "Epoch 63/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.4545 - val_loss: 0.1143\n",
            "Epoch 64/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.4523 - val_loss: 0.1150\n",
            "Epoch 65/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.4502 - val_loss: 0.1157\n",
            "Epoch 66/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.4482 - val_loss: 0.1164\n",
            "Epoch 67/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.4462 - val_loss: 0.1170\n",
            "Epoch 68/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.4443 - val_loss: 0.1177\n",
            "Epoch 69/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.4425 - val_loss: 0.1183\n",
            "Epoch 70/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.4408 - val_loss: 0.1189\n",
            "Epoch 71/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.4391 - val_loss: 0.1195\n",
            "Epoch 72/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.4375 - val_loss: 0.1200\n",
            "Epoch 73/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.4359 - val_loss: 0.1206\n",
            "Epoch 74/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.4344 - val_loss: 0.1211\n",
            "Epoch 75/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.4330 - val_loss: 0.1216\n",
            "Epoch 76/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.4316 - val_loss: 0.1220\n",
            "Epoch 77/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.4302 - val_loss: 0.1225\n",
            "Epoch 78/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.4289 - val_loss: 0.1229\n",
            "Epoch 79/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.4277 - val_loss: 0.1233\n",
            "Epoch 80/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.4265 - val_loss: 0.1237\n",
            "Epoch 81/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.4253 - val_loss: 0.1241\n",
            "Epoch 82/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.4242 - val_loss: 0.1245\n",
            "Epoch 83/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.4231 - val_loss: 0.1249\n",
            "Epoch 84/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.4220 - val_loss: 0.1252\n",
            "Epoch 85/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.4210 - val_loss: 0.1255\n",
            "Epoch 86/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.4200 - val_loss: 0.1259\n",
            "Epoch 87/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.4191 - val_loss: 0.1262\n",
            "Epoch 88/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.4181 - val_loss: 0.1265\n",
            "Epoch 89/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.4172 - val_loss: 0.1268\n",
            "Epoch 90/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.4164 - val_loss: 0.1271\n",
            "Epoch 91/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.4155 - val_loss: 0.1274\n",
            "Epoch 92/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.4147 - val_loss: 0.1276\n",
            "Epoch 93/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.4139 - val_loss: 0.1279\n",
            "Epoch 94/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.4131 - val_loss: 0.1281\n",
            "Epoch 95/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.4124 - val_loss: 0.1284\n",
            "Epoch 96/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.4116 - val_loss: 0.1286\n",
            "Epoch 97/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.4109 - val_loss: 0.1288\n",
            "Epoch 98/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.4102 - val_loss: 0.1290\n",
            "Epoch 99/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.4095 - val_loss: 0.1292\n",
            "Epoch 100/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.4089 - val_loss: 0.1294\n",
            "Epoch 101/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.4082 - val_loss: 0.1296\n",
            "Epoch 102/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.4076 - val_loss: 0.1298\n",
            "Epoch 103/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.4069 - val_loss: 0.1299\n",
            "Epoch 104/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.4063 - val_loss: 0.1301\n",
            "Epoch 105/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.4057 - val_loss: 0.1302\n",
            "Epoch 106/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.4051 - val_loss: 0.1304\n",
            "Epoch 107/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.4045 - val_loss: 0.1305\n",
            "Epoch 108/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.4040 - val_loss: 0.1306\n",
            "Epoch 109/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.4034 - val_loss: 0.1307\n",
            "Epoch 110/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.4028 - val_loss: 0.1308\n",
            "Epoch 111/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.4023 - val_loss: 0.1309\n",
            "Epoch 112/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.4018 - val_loss: 0.1309\n",
            "Epoch 113/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.4012 - val_loss: 0.1310\n",
            "Epoch 114/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.4007 - val_loss: 0.1310\n",
            "Epoch 115/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.4002 - val_loss: 0.1311\n",
            "Epoch 116/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.3997 - val_loss: 0.1311\n",
            "Epoch 117/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.3992 - val_loss: 0.1311\n",
            "Epoch 118/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.3987 - val_loss: 0.1312\n",
            "Epoch 119/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3982 - val_loss: 0.1312\n",
            "Epoch 120/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3977 - val_loss: 0.1312\n",
            "Epoch 121/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.3972 - val_loss: 0.1312\n",
            "Epoch 122/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3967 - val_loss: 0.1311\n",
            "Epoch 123/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.3963 - val_loss: 0.1311\n",
            "Epoch 124/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3958 - val_loss: 0.1311\n",
            "Epoch 125/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.3953 - val_loss: 0.1311\n",
            "Epoch 126/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3949 - val_loss: 0.1310\n",
            "Epoch 127/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.3944 - val_loss: 0.1310\n",
            "Epoch 128/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3940 - val_loss: 0.1309\n",
            "Epoch 129/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3935 - val_loss: 0.1308\n",
            "Epoch 130/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.3931 - val_loss: 0.1308\n",
            "Epoch 131/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3926 - val_loss: 0.1307\n",
            "Epoch 132/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.3922 - val_loss: 0.1306\n",
            "Epoch 133/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3917 - val_loss: 0.1305\n",
            "Epoch 134/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3913 - val_loss: 0.1304\n",
            "Epoch 135/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.3909 - val_loss: 0.1303\n",
            "Epoch 136/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3904 - val_loss: 0.1302\n",
            "Epoch 137/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3900 - val_loss: 0.1301\n",
            "Epoch 138/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.3896 - val_loss: 0.1300\n",
            "Epoch 139/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3891 - val_loss: 0.1298\n",
            "Epoch 140/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3887 - val_loss: 0.1297\n",
            "Epoch 141/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3883 - val_loss: 0.1296\n",
            "Epoch 142/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3879 - val_loss: 0.1294\n",
            "Epoch 143/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.3875 - val_loss: 0.1293\n",
            "Epoch 144/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3870 - val_loss: 0.1292\n",
            "Epoch 145/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.3866 - val_loss: 0.1290\n",
            "Epoch 146/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3862 - val_loss: 0.1289\n",
            "Epoch 147/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3858 - val_loss: 0.1287\n",
            "Epoch 148/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.3854 - val_loss: 0.1286\n",
            "Epoch 149/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.3850 - val_loss: 0.1284\n",
            "Epoch 150/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.3846 - val_loss: 0.1282\n",
            "Epoch 151/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3842 - val_loss: 0.1281\n",
            "Epoch 152/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.3838 - val_loss: 0.1279\n",
            "Epoch 153/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.3834 - val_loss: 0.1277\n",
            "Epoch 154/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.3830 - val_loss: 0.1276\n",
            "Epoch 155/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.3826 - val_loss: 0.1274\n",
            "Epoch 156/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.3822 - val_loss: 0.1272\n",
            "Epoch 157/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3818 - val_loss: 0.1270\n",
            "Epoch 158/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.3814 - val_loss: 0.1268\n",
            "Epoch 159/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3810 - val_loss: 0.1266\n",
            "Epoch 160/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3806 - val_loss: 0.1265\n",
            "Epoch 161/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3802 - val_loss: 0.1263\n",
            "Epoch 162/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3798 - val_loss: 0.1261\n",
            "Epoch 163/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3794 - val_loss: 0.1259\n",
            "Epoch 164/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3790 - val_loss: 0.1257\n",
            "Epoch 165/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.3786 - val_loss: 0.1255\n",
            "Epoch 166/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.3782 - val_loss: 0.1253\n",
            "Epoch 167/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3778 - val_loss: 0.1251\n",
            "Epoch 168/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.3774 - val_loss: 0.1249\n",
            "Epoch 169/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3770 - val_loss: 0.1247\n",
            "Epoch 170/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3766 - val_loss: 0.1245\n",
            "Epoch 171/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.3762 - val_loss: 0.1243\n",
            "Epoch 172/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3758 - val_loss: 0.1241\n",
            "Epoch 173/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3754 - val_loss: 0.1239\n",
            "Epoch 174/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3750 - val_loss: 0.1237\n",
            "Epoch 175/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3746 - val_loss: 0.1235\n",
            "Epoch 176/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.3743 - val_loss: 0.1233\n",
            "Epoch 177/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3739 - val_loss: 0.1231\n",
            "Epoch 178/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3735 - val_loss: 0.1229\n",
            "Epoch 179/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3731 - val_loss: 0.1227\n",
            "Epoch 180/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.3727 - val_loss: 0.1225\n",
            "Epoch 181/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.3723 - val_loss: 0.1223\n",
            "Epoch 182/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3719 - val_loss: 0.1221\n",
            "Epoch 183/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3715 - val_loss: 0.1219\n",
            "Epoch 184/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.3712 - val_loss: 0.1216\n",
            "Epoch 185/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.3708 - val_loss: 0.1214\n",
            "Epoch 186/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3704 - val_loss: 0.1212\n",
            "Epoch 187/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.3700 - val_loss: 0.1210\n",
            "Epoch 188/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.3696 - val_loss: 0.1208\n",
            "Epoch 189/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.3692 - val_loss: 0.1206\n",
            "Epoch 190/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3688 - val_loss: 0.1204\n",
            "Epoch 191/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3684 - val_loss: 0.1202\n",
            "Epoch 192/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3681 - val_loss: 0.1200\n",
            "Epoch 193/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3677 - val_loss: 0.1198\n",
            "Epoch 194/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3673 - val_loss: 0.1196\n",
            "Epoch 195/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3669 - val_loss: 0.1193\n",
            "Epoch 196/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3665 - val_loss: 0.1191\n",
            "Epoch 197/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3661 - val_loss: 0.1189\n",
            "Epoch 198/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.3658 - val_loss: 0.1187\n",
            "Epoch 199/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3654 - val_loss: 0.1185\n",
            "Epoch 200/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.3650 - val_loss: 0.1183\n",
            "Epoch 1/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 290ms/step - loss: 0.4733 - val_loss: 0.2375\n",
            "Epoch 2/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.4694 - val_loss: 0.2434\n",
            "Epoch 3/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.4661 - val_loss: 0.2487\n",
            "Epoch 4/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.4630 - val_loss: 0.2534\n",
            "Epoch 5/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.4602 - val_loss: 0.2572\n",
            "Epoch 6/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.4576 - val_loss: 0.2602\n",
            "Epoch 7/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.4551 - val_loss: 0.2621\n",
            "Epoch 8/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.4528 - val_loss: 0.2631\n",
            "Epoch 9/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.4505 - val_loss: 0.2631\n",
            "Epoch 10/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.4483 - val_loss: 0.2622\n",
            "Epoch 11/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.4461 - val_loss: 0.2605\n",
            "Epoch 12/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.4439 - val_loss: 0.2581\n",
            "Epoch 13/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.4418 - val_loss: 0.2551\n",
            "Epoch 14/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.4397 - val_loss: 0.2518\n",
            "Epoch 15/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.4376 - val_loss: 0.2482\n",
            "Epoch 16/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.4356 - val_loss: 0.2444\n",
            "Epoch 17/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.4336 - val_loss: 0.2407\n",
            "Epoch 18/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.4316 - val_loss: 0.2370\n",
            "Epoch 19/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.4298 - val_loss: 0.2335\n",
            "Epoch 20/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.4279 - val_loss: 0.2301\n",
            "Epoch 21/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.4261 - val_loss: 0.2270\n",
            "Epoch 22/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.4244 - val_loss: 0.2242\n",
            "Epoch 23/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.4227 - val_loss: 0.2215\n",
            "Epoch 24/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.4210 - val_loss: 0.2191\n",
            "Epoch 25/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.4194 - val_loss: 0.2169\n",
            "Epoch 26/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.4178 - val_loss: 0.2148\n",
            "Epoch 27/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.4163 - val_loss: 0.2128\n",
            "Epoch 28/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.4147 - val_loss: 0.2109\n",
            "Epoch 29/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.4133 - val_loss: 0.2091\n",
            "Epoch 30/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.4118 - val_loss: 0.2073\n",
            "Epoch 31/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.4104 - val_loss: 0.2056\n",
            "Epoch 32/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.4091 - val_loss: 0.2038\n",
            "Epoch 33/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.4078 - val_loss: 0.2020\n",
            "Epoch 34/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.4065 - val_loss: 0.2002\n",
            "Epoch 35/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.4053 - val_loss: 0.1984\n",
            "Epoch 36/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.4041 - val_loss: 0.1966\n",
            "Epoch 37/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.4029 - val_loss: 0.1948\n",
            "Epoch 38/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.4018 - val_loss: 0.1930\n",
            "Epoch 39/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.4007 - val_loss: 0.1912\n",
            "Epoch 40/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.3997 - val_loss: 0.1895\n",
            "Epoch 41/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3987 - val_loss: 0.1879\n",
            "Epoch 42/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3977 - val_loss: 0.1863\n",
            "Epoch 43/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3968 - val_loss: 0.1847\n",
            "Epoch 44/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.3959 - val_loss: 0.1832\n",
            "Epoch 45/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3950 - val_loss: 0.1818\n",
            "Epoch 46/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3942 - val_loss: 0.1804\n",
            "Epoch 47/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.3934 - val_loss: 0.1790\n",
            "Epoch 48/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3926 - val_loss: 0.1777\n",
            "Epoch 49/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3919 - val_loss: 0.1764\n",
            "Epoch 50/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3912 - val_loss: 0.1752\n",
            "Epoch 51/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3905 - val_loss: 0.1740\n",
            "Epoch 52/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3899 - val_loss: 0.1729\n",
            "Epoch 53/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3893 - val_loss: 0.1718\n",
            "Epoch 54/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3887 - val_loss: 0.1707\n",
            "Epoch 55/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3881 - val_loss: 0.1696\n",
            "Epoch 56/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3876 - val_loss: 0.1686\n",
            "Epoch 57/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.3871 - val_loss: 0.1676\n",
            "Epoch 58/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3866 - val_loss: 0.1666\n",
            "Epoch 59/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3861 - val_loss: 0.1657\n",
            "Epoch 60/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.3857 - val_loss: 0.1648\n",
            "Epoch 61/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3853 - val_loss: 0.1639\n",
            "Epoch 62/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.3849 - val_loss: 0.1630\n",
            "Epoch 63/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3845 - val_loss: 0.1622\n",
            "Epoch 64/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3842 - val_loss: 0.1614\n",
            "Epoch 65/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3838 - val_loss: 0.1606\n",
            "Epoch 66/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3835 - val_loss: 0.1599\n",
            "Epoch 67/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3832 - val_loss: 0.1592\n",
            "Epoch 68/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3830 - val_loss: 0.1585\n",
            "Epoch 69/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3827 - val_loss: 0.1578\n",
            "Epoch 70/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3825 - val_loss: 0.1572\n",
            "Epoch 71/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.3822 - val_loss: 0.1566\n",
            "Epoch 72/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3820 - val_loss: 0.1560\n",
            "Epoch 73/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.3818 - val_loss: 0.1554\n",
            "Epoch 74/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3817 - val_loss: 0.1549\n",
            "Epoch 75/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3815 - val_loss: 0.1543\n",
            "Epoch 76/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3814 - val_loss: 0.1538\n",
            "Epoch 77/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3812 - val_loss: 0.1533\n",
            "Epoch 78/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3811 - val_loss: 0.1529\n",
            "Epoch 79/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3810 - val_loss: 0.1524\n",
            "Epoch 80/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.3809 - val_loss: 0.1520\n",
            "Epoch 81/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3808 - val_loss: 0.1516\n",
            "Epoch 82/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3807 - val_loss: 0.1512\n",
            "Epoch 83/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3806 - val_loss: 0.1508\n",
            "Epoch 84/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3806 - val_loss: 0.1504\n",
            "Epoch 85/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3805 - val_loss: 0.1501\n",
            "Epoch 86/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.3804 - val_loss: 0.1497\n",
            "Epoch 87/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.3804 - val_loss: 0.1494\n",
            "Epoch 88/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.3804 - val_loss: 0.1491\n",
            "Epoch 89/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.3803 - val_loss: 0.1488\n",
            "Epoch 90/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.3803 - val_loss: 0.1485\n",
            "Epoch 91/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.3803 - val_loss: 0.1483\n",
            "Epoch 92/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.3803 - val_loss: 0.1480\n",
            "Epoch 93/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.3803 - val_loss: 0.1478\n",
            "Epoch 94/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.3803 - val_loss: 0.1475\n",
            "Epoch 95/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.3803 - val_loss: 0.1473\n",
            "Epoch 96/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.3803 - val_loss: 0.1471\n",
            "Epoch 97/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.3803 - val_loss: 0.1469\n",
            "Epoch 98/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.3804 - val_loss: 0.1467\n",
            "Epoch 99/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.3804 - val_loss: 0.1465\n",
            "Epoch 100/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3804 - val_loss: 0.1464\n",
            "Epoch 101/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.3804 - val_loss: 0.1462\n",
            "Epoch 102/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.3805 - val_loss: 0.1460\n",
            "Epoch 103/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.3805 - val_loss: 0.1459\n",
            "Epoch 104/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.3805 - val_loss: 0.1458\n",
            "Epoch 105/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3806 - val_loss: 0.1456\n",
            "Epoch 106/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3806 - val_loss: 0.1455\n",
            "Epoch 107/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.3807 - val_loss: 0.1454\n",
            "Epoch 108/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3807 - val_loss: 0.1453\n",
            "Epoch 109/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3808 - val_loss: 0.1452\n",
            "Epoch 110/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.3808 - val_loss: 0.1451\n",
            "Epoch 111/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.3808 - val_loss: 0.1450\n",
            "Epoch 112/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.3809 - val_loss: 0.1449\n",
            "Epoch 113/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3809 - val_loss: 0.1448\n",
            "Epoch 114/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3810 - val_loss: 0.1448\n",
            "Epoch 115/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3810 - val_loss: 0.1447\n",
            "Epoch 116/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3811 - val_loss: 0.1446\n",
            "Epoch 117/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.3812 - val_loss: 0.1446\n",
            "Epoch 118/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3812 - val_loss: 0.1445\n",
            "Epoch 119/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3813 - val_loss: 0.1445\n",
            "Epoch 120/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3813 - val_loss: 0.1444\n",
            "Epoch 121/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3814 - val_loss: 0.1444\n",
            "Epoch 122/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.3814 - val_loss: 0.1443\n",
            "Epoch 123/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3815 - val_loss: 0.1443\n",
            "Epoch 124/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.3815 - val_loss: 0.1443\n",
            "Epoch 125/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3816 - val_loss: 0.1443\n",
            "Epoch 126/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3816 - val_loss: 0.1442\n",
            "Epoch 127/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3817 - val_loss: 0.1442\n",
            "Epoch 128/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3817 - val_loss: 0.1442\n",
            "Epoch 129/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.3818 - val_loss: 0.1442\n",
            "Epoch 130/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3818 - val_loss: 0.1442\n",
            "Epoch 131/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3819 - val_loss: 0.1442\n",
            "Epoch 132/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.3819 - val_loss: 0.1441\n",
            "Epoch 133/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3820 - val_loss: 0.1441\n",
            "Epoch 134/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3820 - val_loss: 0.1441\n",
            "Epoch 135/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3821 - val_loss: 0.1441\n",
            "Epoch 136/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3821 - val_loss: 0.1441\n",
            "Epoch 137/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.3822 - val_loss: 0.1441\n",
            "Epoch 138/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3822 - val_loss: 0.1442\n",
            "Epoch 139/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.3823 - val_loss: 0.1442\n",
            "Epoch 140/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3823 - val_loss: 0.1442\n",
            "Epoch 141/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3823 - val_loss: 0.1442\n",
            "Epoch 142/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3824 - val_loss: 0.1442\n",
            "Epoch 143/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3824 - val_loss: 0.1442\n",
            "Epoch 144/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3825 - val_loss: 0.1442\n",
            "Epoch 145/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.3825 - val_loss: 0.1442\n",
            "Epoch 146/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3825 - val_loss: 0.1443\n",
            "Epoch 147/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.3826 - val_loss: 0.1443\n",
            "Epoch 148/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.3826 - val_loss: 0.1443\n",
            "Epoch 149/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.3826 - val_loss: 0.1443\n",
            "Epoch 150/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3827 - val_loss: 0.1443\n",
            "Epoch 151/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.3827 - val_loss: 0.1443\n",
            "Epoch 152/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3827 - val_loss: 0.1444\n",
            "Epoch 153/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3828 - val_loss: 0.1444\n",
            "Epoch 154/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3828 - val_loss: 0.1444\n",
            "Epoch 155/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3828 - val_loss: 0.1444\n",
            "Epoch 156/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3829 - val_loss: 0.1445\n",
            "Epoch 157/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.3829 - val_loss: 0.1445\n",
            "Epoch 158/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.3829 - val_loss: 0.1445\n",
            "Epoch 159/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3829 - val_loss: 0.1445\n",
            "Epoch 160/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3830 - val_loss: 0.1446\n",
            "Epoch 161/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3830 - val_loss: 0.1446\n",
            "Epoch 162/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3830 - val_loss: 0.1446\n",
            "Epoch 163/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3830 - val_loss: 0.1447\n",
            "Epoch 164/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3830 - val_loss: 0.1447\n",
            "Epoch 165/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3831 - val_loss: 0.1447\n",
            "Epoch 166/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3831 - val_loss: 0.1447\n",
            "Epoch 167/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3831 - val_loss: 0.1448\n",
            "Epoch 168/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3831 - val_loss: 0.1448\n",
            "Epoch 169/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.3831 - val_loss: 0.1448\n",
            "Epoch 170/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3831 - val_loss: 0.1448\n",
            "Epoch 171/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.3832 - val_loss: 0.1449\n",
            "Epoch 172/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.3832 - val_loss: 0.1449\n",
            "Epoch 173/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.3832 - val_loss: 0.1449\n",
            "Epoch 174/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3832 - val_loss: 0.1450\n",
            "Epoch 175/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.3832 - val_loss: 0.1450\n",
            "Epoch 176/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.3832 - val_loss: 0.1450\n",
            "Epoch 177/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.3832 - val_loss: 0.1450\n",
            "Epoch 178/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3832 - val_loss: 0.1451\n",
            "Epoch 179/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3832 - val_loss: 0.1451\n",
            "Epoch 180/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.3832 - val_loss: 0.1451\n",
            "Epoch 181/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.3832 - val_loss: 0.1452\n",
            "Epoch 182/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.3832 - val_loss: 0.1452\n",
            "Epoch 183/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.3833 - val_loss: 0.1452\n",
            "Epoch 184/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.3833 - val_loss: 0.1452\n",
            "Epoch 185/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.3833 - val_loss: 0.1453\n",
            "Epoch 186/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.3833 - val_loss: 0.1453\n",
            "Epoch 187/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.3833 - val_loss: 0.1453\n",
            "Epoch 188/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 0.3833 - val_loss: 0.1453\n",
            "Epoch 189/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.3833 - val_loss: 0.1454\n",
            "Epoch 190/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.3833 - val_loss: 0.1454\n",
            "Epoch 191/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.3833 - val_loss: 0.1454\n",
            "Epoch 192/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.3833 - val_loss: 0.1454\n",
            "Epoch 193/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.3833 - val_loss: 0.1455\n",
            "Epoch 194/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3832 - val_loss: 0.1455\n",
            "Epoch 195/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.3832 - val_loss: 0.1455\n",
            "Epoch 196/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.3832 - val_loss: 0.1455\n",
            "Epoch 197/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.3832 - val_loss: 0.1456\n",
            "Epoch 198/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3832 - val_loss: 0.1456\n",
            "Epoch 199/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.3832 - val_loss: 0.1456\n",
            "Epoch 200/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.3832 - val_loss: 0.1456\n",
            "Epoch 1/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 186ms/step - loss: 0.6699 - val_loss: 0.1733\n",
            "Epoch 2/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.6611 - val_loss: 0.1778\n",
            "Epoch 3/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.6529 - val_loss: 0.1822\n",
            "Epoch 4/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.6447 - val_loss: 0.1864\n",
            "Epoch 5/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.6365 - val_loss: 0.1906\n",
            "Epoch 6/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.6285 - val_loss: 0.1946\n",
            "Epoch 7/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.6204 - val_loss: 0.1986\n",
            "Epoch 8/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.6125 - val_loss: 0.2023\n",
            "Epoch 9/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.6047 - val_loss: 0.2058\n",
            "Epoch 10/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.5969 - val_loss: 0.2089\n",
            "Epoch 11/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.5893 - val_loss: 0.2118\n",
            "Epoch 12/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.5819 - val_loss: 0.2142\n",
            "Epoch 13/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.5747 - val_loss: 0.2161\n",
            "Epoch 14/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.5676 - val_loss: 0.2175\n",
            "Epoch 15/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.5607 - val_loss: 0.2184\n",
            "Epoch 16/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.5539 - val_loss: 0.2186\n",
            "Epoch 17/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.5474 - val_loss: 0.2182\n",
            "Epoch 18/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.5411 - val_loss: 0.2171\n",
            "Epoch 19/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.5349 - val_loss: 0.2153\n",
            "Epoch 20/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.5289 - val_loss: 0.2130\n",
            "Epoch 21/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.5230 - val_loss: 0.2101\n",
            "Epoch 22/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.5173 - val_loss: 0.2066\n",
            "Epoch 23/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.5117 - val_loss: 0.2027\n",
            "Epoch 24/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.5063 - val_loss: 0.1985\n",
            "Epoch 25/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.5010 - val_loss: 0.1940\n",
            "Epoch 26/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.4959 - val_loss: 0.1893\n",
            "Epoch 27/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.4909 - val_loss: 0.1846\n",
            "Epoch 28/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.4861 - val_loss: 0.1799\n",
            "Epoch 29/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.4815 - val_loss: 0.1753\n",
            "Epoch 30/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.4770 - val_loss: 0.1709\n",
            "Epoch 31/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.4727 - val_loss: 0.1667\n",
            "Epoch 32/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.4686 - val_loss: 0.1628\n",
            "Epoch 33/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.4647 - val_loss: 0.1592\n",
            "Epoch 34/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.4609 - val_loss: 0.1558\n",
            "Epoch 35/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.4573 - val_loss: 0.1528\n",
            "Epoch 36/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.4539 - val_loss: 0.1500\n",
            "Epoch 37/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.4506 - val_loss: 0.1476\n",
            "Epoch 38/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.4475 - val_loss: 0.1454\n",
            "Epoch 39/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.4446 - val_loss: 0.1434\n",
            "Epoch 40/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.4418 - val_loss: 0.1417\n",
            "Epoch 41/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.4392 - val_loss: 0.1401\n",
            "Epoch 42/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.4366 - val_loss: 0.1388\n",
            "Epoch 43/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.4342 - val_loss: 0.1376\n",
            "Epoch 44/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.4320 - val_loss: 0.1365\n",
            "Epoch 45/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.4298 - val_loss: 0.1356\n",
            "Epoch 46/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.4278 - val_loss: 0.1347\n",
            "Epoch 47/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.4259 - val_loss: 0.1340\n",
            "Epoch 48/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.4240 - val_loss: 0.1333\n",
            "Epoch 49/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.4223 - val_loss: 0.1327\n",
            "Epoch 50/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.4207 - val_loss: 0.1322\n",
            "Epoch 51/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.4191 - val_loss: 0.1317\n",
            "Epoch 52/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.4177 - val_loss: 0.1313\n",
            "Epoch 53/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.4163 - val_loss: 0.1310\n",
            "Epoch 54/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.4149 - val_loss: 0.1307\n",
            "Epoch 55/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.4137 - val_loss: 0.1305\n",
            "Epoch 56/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.4125 - val_loss: 0.1303\n",
            "Epoch 57/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.4113 - val_loss: 0.1302\n",
            "Epoch 58/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 0.4103 - val_loss: 0.1301\n",
            "Epoch 59/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 0.4092 - val_loss: 0.1301\n",
            "Epoch 60/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 0.4082 - val_loss: 0.1301\n",
            "Epoch 61/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.4073 - val_loss: 0.1301\n",
            "Epoch 62/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.4063 - val_loss: 0.1302\n",
            "Epoch 63/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.4055 - val_loss: 0.1303\n",
            "Epoch 64/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.4046 - val_loss: 0.1304\n",
            "Epoch 65/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.4038 - val_loss: 0.1306\n",
            "Epoch 66/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.4030 - val_loss: 0.1308\n",
            "Epoch 67/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.4022 - val_loss: 0.1310\n",
            "Epoch 68/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.4015 - val_loss: 0.1313\n",
            "Epoch 69/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.4007 - val_loss: 0.1315\n",
            "Epoch 70/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.4000 - val_loss: 0.1318\n",
            "Epoch 71/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3993 - val_loss: 0.1321\n",
            "Epoch 72/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3987 - val_loss: 0.1324\n",
            "Epoch 73/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3980 - val_loss: 0.1327\n",
            "Epoch 74/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3974 - val_loss: 0.1330\n",
            "Epoch 75/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3968 - val_loss: 0.1334\n",
            "Epoch 76/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.3962 - val_loss: 0.1337\n",
            "Epoch 77/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3956 - val_loss: 0.1341\n",
            "Epoch 78/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3950 - val_loss: 0.1344\n",
            "Epoch 79/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3945 - val_loss: 0.1348\n",
            "Epoch 80/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.3939 - val_loss: 0.1351\n",
            "Epoch 81/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3934 - val_loss: 0.1355\n",
            "Epoch 82/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3929 - val_loss: 0.1359\n",
            "Epoch 83/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3923 - val_loss: 0.1363\n",
            "Epoch 84/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3918 - val_loss: 0.1366\n",
            "Epoch 85/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3914 - val_loss: 0.1370\n",
            "Epoch 86/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.3909 - val_loss: 0.1374\n",
            "Epoch 87/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3904 - val_loss: 0.1378\n",
            "Epoch 88/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.3900 - val_loss: 0.1382\n",
            "Epoch 89/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3895 - val_loss: 0.1386\n",
            "Epoch 90/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3891 - val_loss: 0.1390\n",
            "Epoch 91/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.3886 - val_loss: 0.1393\n",
            "Epoch 92/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3882 - val_loss: 0.1397\n",
            "Epoch 93/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3878 - val_loss: 0.1401\n",
            "Epoch 94/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3874 - val_loss: 0.1405\n",
            "Epoch 95/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3870 - val_loss: 0.1409\n",
            "Epoch 96/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3866 - val_loss: 0.1413\n",
            "Epoch 97/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.3863 - val_loss: 0.1416\n",
            "Epoch 98/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3859 - val_loss: 0.1420\n",
            "Epoch 99/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.3855 - val_loss: 0.1424\n",
            "Epoch 100/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3852 - val_loss: 0.1427\n",
            "Epoch 101/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.3848 - val_loss: 0.1431\n",
            "Epoch 102/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.3845 - val_loss: 0.1435\n",
            "Epoch 103/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3841 - val_loss: 0.1438\n",
            "Epoch 104/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.3838 - val_loss: 0.1442\n",
            "Epoch 105/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.3835 - val_loss: 0.1445\n",
            "Epoch 106/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.3832 - val_loss: 0.1448\n",
            "Epoch 107/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.3829 - val_loss: 0.1452\n",
            "Epoch 108/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3826 - val_loss: 0.1455\n",
            "Epoch 109/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.3823 - val_loss: 0.1458\n",
            "Epoch 110/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3820 - val_loss: 0.1461\n",
            "Epoch 111/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.3817 - val_loss: 0.1464\n",
            "Epoch 112/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.3814 - val_loss: 0.1467\n",
            "Epoch 113/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3811 - val_loss: 0.1470\n",
            "Epoch 114/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3809 - val_loss: 0.1473\n",
            "Epoch 115/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3806 - val_loss: 0.1476\n",
            "Epoch 116/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3803 - val_loss: 0.1479\n",
            "Epoch 117/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3801 - val_loss: 0.1482\n",
            "Epoch 118/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.3798 - val_loss: 0.1484\n",
            "Epoch 119/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3796 - val_loss: 0.1487\n",
            "Epoch 120/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.3794 - val_loss: 0.1490\n",
            "Epoch 121/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3791 - val_loss: 0.1492\n",
            "Epoch 122/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.3789 - val_loss: 0.1495\n",
            "Epoch 123/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3787 - val_loss: 0.1497\n",
            "Epoch 124/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3784 - val_loss: 0.1499\n",
            "Epoch 125/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.3782 - val_loss: 0.1502\n",
            "Epoch 126/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3780 - val_loss: 0.1504\n",
            "Epoch 127/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.3778 - val_loss: 0.1506\n",
            "Epoch 128/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3776 - val_loss: 0.1508\n",
            "Epoch 129/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3774 - val_loss: 0.1510\n",
            "Epoch 130/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3772 - val_loss: 0.1512\n",
            "Epoch 131/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.3770 - val_loss: 0.1514\n",
            "Epoch 132/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3768 - val_loss: 0.1516\n",
            "Epoch 133/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3766 - val_loss: 0.1518\n",
            "Epoch 134/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.3764 - val_loss: 0.1519\n",
            "Epoch 135/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3762 - val_loss: 0.1521\n",
            "Epoch 136/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.3761 - val_loss: 0.1523\n",
            "Epoch 137/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3759 - val_loss: 0.1524\n",
            "Epoch 138/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3757 - val_loss: 0.1526\n",
            "Epoch 139/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.3755 - val_loss: 0.1527\n",
            "Epoch 140/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3754 - val_loss: 0.1528\n",
            "Epoch 141/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.3752 - val_loss: 0.1530\n",
            "Epoch 142/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3750 - val_loss: 0.1531\n",
            "Epoch 143/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3749 - val_loss: 0.1532\n",
            "Epoch 144/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3747 - val_loss: 0.1533\n",
            "Epoch 145/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.3746 - val_loss: 0.1534\n",
            "Epoch 146/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.3744 - val_loss: 0.1535\n",
            "Epoch 147/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.3742 - val_loss: 0.1536\n",
            "Epoch 148/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.3741 - val_loss: 0.1537\n",
            "Epoch 149/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.3739 - val_loss: 0.1538\n",
            "Epoch 150/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.3738 - val_loss: 0.1539\n",
            "Epoch 151/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.3737 - val_loss: 0.1540\n",
            "Epoch 152/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.3735 - val_loss: 0.1541\n",
            "Epoch 153/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 0.3734 - val_loss: 0.1542\n",
            "Epoch 154/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.3732 - val_loss: 0.1542\n",
            "Epoch 155/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.3731 - val_loss: 0.1543\n",
            "Epoch 156/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.3730 - val_loss: 0.1543\n",
            "Epoch 157/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.3728 - val_loss: 0.1544\n",
            "Epoch 158/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.3727 - val_loss: 0.1544\n",
            "Epoch 159/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.3726 - val_loss: 0.1545\n",
            "Epoch 160/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.3724 - val_loss: 0.1545\n",
            "Epoch 161/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.3723 - val_loss: 0.1546\n",
            "Epoch 162/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.3722 - val_loss: 0.1546\n",
            "Epoch 163/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.3720 - val_loss: 0.1546\n",
            "Epoch 164/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.3719 - val_loss: 0.1547\n",
            "Epoch 165/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.3718 - val_loss: 0.1547\n",
            "Epoch 166/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.3717 - val_loss: 0.1547\n",
            "Epoch 167/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.3716 - val_loss: 0.1547\n",
            "Epoch 168/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.3714 - val_loss: 0.1547\n",
            "Epoch 169/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.3713 - val_loss: 0.1548\n",
            "Epoch 170/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.3712 - val_loss: 0.1548\n",
            "Epoch 171/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.3711 - val_loss: 0.1548\n",
            "Epoch 172/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.3710 - val_loss: 0.1548\n",
            "Epoch 173/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.3709 - val_loss: 0.1548\n",
            "Epoch 174/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.3707 - val_loss: 0.1548\n",
            "Epoch 175/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.3706 - val_loss: 0.1548\n",
            "Epoch 176/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.3705 - val_loss: 0.1547\n",
            "Epoch 177/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.3704 - val_loss: 0.1547\n",
            "Epoch 178/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.3703 - val_loss: 0.1547\n",
            "Epoch 179/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.3702 - val_loss: 0.1547\n",
            "Epoch 180/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.3701 - val_loss: 0.1547\n",
            "Epoch 181/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.3700 - val_loss: 0.1547\n",
            "Epoch 182/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.3699 - val_loss: 0.1546\n",
            "Epoch 183/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.3698 - val_loss: 0.1546\n",
            "Epoch 184/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.3697 - val_loss: 0.1546\n",
            "Epoch 185/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.3696 - val_loss: 0.1545\n",
            "Epoch 186/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.3695 - val_loss: 0.1545\n",
            "Epoch 187/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.3694 - val_loss: 0.1545\n",
            "Epoch 188/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.3692 - val_loss: 0.1544\n",
            "Epoch 189/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.3691 - val_loss: 0.1544\n",
            "Epoch 190/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.3690 - val_loss: 0.1543\n",
            "Epoch 191/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.3689 - val_loss: 0.1543\n",
            "Epoch 192/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.3688 - val_loss: 0.1543\n",
            "Epoch 193/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.3687 - val_loss: 0.1542\n",
            "Epoch 194/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.3687 - val_loss: 0.1542\n",
            "Epoch 195/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.3686 - val_loss: 0.1541\n",
            "Epoch 196/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.3685 - val_loss: 0.1541\n",
            "Epoch 197/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.3684 - val_loss: 0.1540\n",
            "Epoch 198/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.3683 - val_loss: 0.1539\n",
            "Epoch 199/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.3682 - val_loss: 0.1539\n",
            "Epoch 200/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.3681 - val_loss: 0.1538\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_val_pred_real  = inv_y(model.predict(X_val_z,  verbose=0))\n",
        "y_test_pred_real = inv_y(model.predict(X_test_z, verbose=0))\n",
        "\n",
        "val_mse_real.append(mean_squared_error(y_val,  y_val_pred_real))\n",
        "test_mse_real.append(mean_squared_error(y_test, y_test_pred_real))"
      ],
      "metadata": {
        "id": "pte4Sl2lzviq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "transfer_functions = {\n",
        "    'relu': 'ReLU',\n",
        "    'tanh': 'Tanh',\n",
        "    'sigmoid': 'Sigmoid',\n",
        "    'softplus': 'Softplus'\n",
        "}\n",
        "\n",
        "mse_results = []\n",
        "\n",
        "for activation, name in transfer_functions.items():\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=(X_train.shape[1],)))\n",
        "    model.add(Dense(16, activation=activation))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(1, activation='tanh'))\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    model.fit(X_train, y_train, batch_size=4, epochs=50, verbose=0)\n",
        "    y_pred = model.predict(X_test)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    mse_results.append(mse)\n",
        "\n",
        "# حالا که mse_results پر شده، رسم کن:\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(list(transfer_functions.values()), mse_results, marker='o', linestyle='-', color='blue')\n",
        "plt.title('Mean MSE of Mn vs Transfer Function')\n",
        "plt.xlabel('Transfer Function')\n",
        "plt.ylabel('Mean Squared Error')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        },
        "id": "mi4HD3HvzvgE",
        "outputId": "8d2c5b03-b7a9-4bd0-c7a3-b6961e4b8d43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = y.ravel()\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import KFold, cross_val_predict\n",
        "\n",
        "pipe = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"lr\", LinearRegression())\n",
        "])\n",
        "\n",
        "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "y_pred = cross_val_predict(pipe, X, y, cv=cv)"
      ],
      "metadata": {
        "id": "EDPOy53izvXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import PredictionErrorDisplay\n",
        "\n",
        "fig, axs = plt.subplots(ncols=2, figsize=(8, 4))\n",
        "\n",
        "# نمودار Actual vs Predicted\n",
        "PredictionErrorDisplay.from_predictions(\n",
        "    y_true=y,\n",
        "    y_pred=y_pred,\n",
        "    kind=\"actual_vs_predicted\",\n",
        "    subsample=None,          # ← تغییر نسبت به 25\n",
        "    ax=axs[0],\n",
        "    random_state=42,\n",
        ")\n",
        "axs[0].set_title(\"Actual vs. Predicted values\")\n",
        "\n",
        "# نمودار Residual vs Predicted\n",
        "PredictionErrorDisplay.from_predictions(\n",
        "    y_true=y,\n",
        "    y_pred=y_pred,\n",
        "    kind=\"residual_vs_predicted\",\n",
        "    subsample=None,          # ← تغییر نسبت به 25\n",
        "    ax=axs[1],\n",
        "    random_state=42,\n",
        ")\n",
        "axs[1].set_title(\"Residuals vs. Predicted Values\")\n",
        "\n",
        "fig.suptitle(\"Cross-validated predictions (OOF)\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "id": "44mdFAH_zvVL",
        "outputId": "15f6c05f-e34c-4356-8184-a6d84c86d382"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "from sklearn.metrics import (\n",
        "    r2_score, mean_absolute_percentage_error, mean_squared_error,\n",
        "    mean_squared_log_error, explained_variance_score, max_error,\n",
        "    median_absolute_error\n",
        ")"
      ],
      "metadata": {
        "id": "9mx0YxFMdt-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"Python.csv\", engine=\"python\", sep=r\";\")\n",
        "df.columns = (df.columns\n",
        "              .str.replace('\\ufeff', '', regex=False)   # حذف BOM\n",
        "              .str.strip()\n",
        "              .str.replace(r'\\s+', ' ', regex=True))    # یکی‌کردن فاصله‌ها\n",
        "\n",
        "print(\"ستون‌های موجود:\", list(df.columns))  # کمک برای چک کردن\n",
        "\n",
        "# 2) نگاشتِ نام‌ها به‌صورت Case-Insensitive (بی‌حساسیت به بزرگی/کوچکی حروف)\n",
        "def pick_cols(df, names):\n",
        "    lookup = {c.casefold(): c for c in df.columns}\n",
        "    missing = [n for n in names if n.casefold() not in lookup]\n",
        "    if missing:\n",
        "        raise KeyError(f\"ستون‌های پیدا نشدند: {missing}\\nموجود: {list(df.columns)}\")\n",
        "    return [lookup[n.casefold()] for n in names]\n",
        "\n",
        "FEATURES_REQ = ['factor A', 'factor B', 'factor C', 'factor D']\n",
        "TARGETS_REQ  = ['Response 1 (Mn)', 'Response 2 (Mw)']\n",
        "\n",
        "FEATURES = pick_cols(df, FEATURES_REQ)\n",
        "TARGETS  = pick_cols(df, TARGETS_REQ)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OuGC1xUdxOh",
        "outputId": "41b8fa28-f7e4-4c5e-e2b7-fec0a8706c60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ستون‌های موجود: ['factor A', 'factor B', 'factor C', 'factor D', 'Response 1 (Mn)', 'Response 2 (Mw)']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df[FEATURES].to_numpy(dtype=float)\n",
        "Y = df[TARGETS].to_numpy(dtype=float)\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(\n",
        "    X, Y, test_size=0.2, random_state=42, shuffle=True\n",
        ")\n",
        "\n",
        "X_trval, X_test, Y_trval, Y_test = train_test_split(\n",
        "    X, Y, test_size=5, random_state=42, shuffle=True\n",
        ")\n",
        "\n",
        "n_samples = X.shape[0]\n",
        "\n",
        "print(f\"Training set: {X_train.shape[0]} samples\")\n",
        "print(f\"Validation set: {X_trval.shape[0]} samples\")\n",
        "print(f\"Test set: {X_test.shape[0]} samples\")\n",
        "print(f\"Total: {n_samples} samples\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYDUPyluge6O",
        "outputId": "907fd173-7b0c-4807-aeb7-839722a0d3ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set: 20 samples\n",
            "Validation set: 20 samples\n",
            "Test set: 5 samples\n",
            "Total: 25 samples\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for col in FEATURES + TARGETS:\n",
        "    df[col] = pd.to_numeric(df[col].astype(str).str.replace(',', '.').str.strip(),\n",
        "                            errors='coerce')\n",
        "\n",
        "# 4) ساخت X و Y\n",
        "X = df[FEATURES].to_numpy(dtype=float)\n",
        "Y = df[TARGETS].to_numpy(dtype=float)\n",
        "\n",
        "print(\"X shape:\", X.shape, \"Y shape:\", Y.shape)\n",
        "n_samples = X.shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udQ4D7d6i3pR",
        "outputId": "1823136b-cee3-43f2-9961-0f0dd44f126a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape: (25, 4) Y shape: (25, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_svr = make_pipeline(StandardScaler(),SVR(kernel='poly', C=1 , epsilon= 0.1, gamma='scale')\n",
        ")\n",
        "model = MultiOutputRegressor(base_svr)\n",
        "model.fit(X_train, Y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "id": "vWonnDhpu9mM",
        "outputId": "0e5b5b4f-8306-4eaa-f925-3df33906cc2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultiOutputRegressor(estimator=Pipeline(steps=[('standardscaler',\n",
              "                                                StandardScaler()),\n",
              "                                               ('svr',\n",
              "                                                SVR(C=1, kernel='poly'))]))"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultiOutputRegressor(estimator=Pipeline(steps=[(&#x27;standardscaler&#x27;,\n",
              "                                                StandardScaler()),\n",
              "                                               (&#x27;svr&#x27;,\n",
              "                                                SVR(C=1, kernel=&#x27;poly&#x27;))]))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>MultiOutputRegressor</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.multioutput.MultiOutputRegressor.html\">?<span>Documentation for MultiOutputRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>MultiOutputRegressor(estimator=Pipeline(steps=[(&#x27;standardscaler&#x27;,\n",
              "                                                StandardScaler()),\n",
              "                                               (&#x27;svr&#x27;,\n",
              "                                                SVR(C=1, kernel=&#x27;poly&#x27;))]))</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>estimator: Pipeline</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
              "                (&#x27;svr&#x27;, SVR(C=1, kernel=&#x27;poly&#x27;))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>StandardScaler</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>StandardScaler()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>SVR</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.svm.SVR.html\">?<span>Documentation for SVR</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>SVR(C=1, kernel=&#x27;poly&#x27;)</pre></div> </div></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 224
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, Y_train)\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
        "Y_pred = model.predict(X_test)\n",
        "print(\"Test predictions shape:\", Y_pred.shape)\n",
        "def overall_metrics(y_true, y_pred):\n",
        "    r2   = r2_score(y_true, y_pred, multioutput='uniform_average')\n",
        "    evs  = explained_variance_score(y_true, y_pred, multioutput='uniform_average')\n",
        "    mape = mean_absolute_percentage_error(y_true, y_pred, multioutput='uniform_average')\n",
        "    mse  = mean_squared_error(y_true, y_pred, multioutput='uniform_average')\n",
        "    try:\n",
        "        msle = mean_squared_log_error(y_true, y_pred, multioutput='uniform_average')\n",
        "    except ValueError:\n",
        "        msle = np.nan\n",
        "    # Median AE را دستی روی هر خروجی بگیریم و میانگین کنیم\n",
        "    mae_med = np.mean([median_absolute_error(y_true[:,i], y_pred[:,i]) for i in range(y_true.shape[1])])\n",
        "    # Max Error را روی کل عناصر محاسبه کنیم\n",
        "    maxerr = np.max(np.abs(y_true - y_pred))\n",
        "    return evs, maxerr, mape, mse, msle, mae_med, r2\n",
        "evs, maxerr, mape, mse, msle, mae_med, r2 = overall_metrics(Y_test, Y_pred)\n",
        "print(\"SVM Results:\")\n",
        "print(f\"Explained Variance: {evs:.6f}\")\n",
        "print(f\"Max Error: {maxerr:.6f}\")\n",
        "print(f\"MAPE: {mape:.6f}\")\n",
        "print(f\"MSE: {mse:.6f}\")\n",
        "print(f\"MSLE: {msle:.6f}\")\n",
        "print(f\"Median AE: {mae_med:.6f}\")\n",
        "print(f\"R²: {r2:.6f}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R51IYeAhp-eF",
        "outputId": "500146fa-fd72-4aa6-9aad-5f493644b1f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test predictions shape: (5, 2)\n",
            "SVM Results:\n",
            "Explained Variance: 0.371681\n",
            "Max Error: 0.093440\n",
            "MAPE: 0.000045\n",
            "MSE: 0.003752\n",
            "MSLE: 0.000000\n",
            "Median AE: 0.050647\n",
            "R²: 0.368801\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.DataFrame({\n",
        "    \"Actual_Mn\":     Y_test[:,0],\n",
        "    \"Actual_Mw\":     Y_test[:,1],\n",
        "    \"Predicted_Mn\":  Y_pred[:,0],\n",
        "    \"Predicted_Mw\":  Y_pred[:,1],\n",
        "})\n",
        "print(\"Actual vs Predicted Comparison (Test):\")\n",
        "print(test_df.to_string(index=False))\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ksflBmCxuYo",
        "outputId": "d7f324eb-c72a-4d81-f898-5ad6674051b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual vs Predicted Comparison (Test):\n",
            " Actual_Mn  Actual_Mw  Predicted_Mn  Predicted_Mw\n",
            "   1127.27    1321.73   1127.320647   1321.780647\n",
            "   1127.35    1321.81   1127.317766   1321.777766\n",
            "   1127.19    1321.65   1127.268218   1321.728218\n",
            "   1127.42    1321.88   1127.326560   1321.786560\n",
            "   1127.30    1321.76   1127.317493   1321.777493\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "r2_list, mse_list, mape_list = [], [], []\n",
        "\n",
        "for tr_idx, va_idx in kf.split(X):\n",
        "    X_tr, X_va = X[tr_idx], X[va_idx]\n",
        "    Y_tr, Y_va = Y[tr_idx], Y[va_idx]\n",
        "    m = MultiOutputRegressor(make_pipeline(StandardScaler(), SVR(kernel='poly', C=1, epsilon=0.1, gamma='scale')))\n",
        "    m.fit(X_tr, Y_tr)\n",
        "    Y_va_pred = m.predict(X_va)\n",
        "    r2_list.append(r2_score(Y_va, Y_va_pred, multioutput='uniform_average'))\n",
        "    mse_list.append(mean_squared_error(Y_va, Y_va_pred, multioutput='uniform_average'))\n",
        "    mape_list.append(mean_absolute_percentage_error(Y_va, Y_va_pred, multioutput='uniform_average'))\n",
        "\n",
        "r2_arr   = np.array(r2_list)\n",
        "mse_arr  = np.array(mse_list)\n",
        "mape_arr = np.array(mape_list)\n",
        "\n",
        "print(\"\\n5-FOLD CROSS VALIDATION RESULTS\")\n",
        "print(\"============================================================\")\n",
        "print(f\"R² Mean: {r2_arr.mean():.4f} (±{r2_arr.std():.4f})\")\n",
        "print(f\"MSE Mean: {mse_arr.mean():.4f} (±{mse_arr.std():.4f})\")\n",
        "print(f\"MAPE Mean: {mape_arr.mean():.4f} (±{mape_arr.std():.4f})\\n\")\n",
        "\n",
        "print(\"Individual R² scores:\", np.array2string(r2_arr, precision=4))\n",
        "print(\"Individual MSE scores:\", np.array2string(mse_arr, precision=4))\n",
        "print(\"Individual MAPE scores:\", np.array2string(mape_arr, precision=4))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXL7AbhmyjB4",
        "outputId": "a648ac41-2dc6-4206-da28-b15a87a2a45c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "5-FOLD CROSS VALIDATION RESULTS\n",
            "============================================================\n",
            "R² Mean: -2.4861 (±4.4807)\n",
            "MSE Mean: 0.0052 (±0.0020)\n",
            "MAPE Mean: 0.0001 (±0.0000)\n",
            "\n",
            "Individual R² scores: [  0.3688  -0.2553  -1.2842 -11.3763   0.1165]\n",
            "Individual MSE scores: [0.0038 0.0065 0.0063 0.0074 0.002 ]\n",
            "Individual MAPE scores: [4.4712e-05 5.6870e-05 5.1566e-05 6.7652e-05 3.0318e-05]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_all = MultiOutputRegressor(make_pipeline(StandardScaler(), SVR(kernel='rbf', C=10.0, epsilon=0.01, gamma='scale')))\n",
        "model_all.fit(X, Y)\n",
        "Y_all_pred = model_all.predict(X)\n",
        "\n",
        "all_df = pd.DataFrame({\n",
        "    \"Sample\": np.arange(1, n_samples+1),\n",
        "    \"Actual_Mn\": Y[:,0],\n",
        "    \"Actual_Mw\": Y[:,1],\n",
        "    \"Predicted_Mn\": Y_all_pred[:,0],\n",
        "    \"Predicted_Mw\": Y_all_pred[:,1],\n",
        "})\n",
        "all_df[\"Error_Mn\"] = (all_df[\"Actual_Mn\"] - all_df[\"Predicted_Mn\"]).abs()\n",
        "all_df[\"Error_Mw\"] = (all_df[\"Actual_Mw\"] - all_df[\"Predicted_Mw\"]).abs()\n",
        "\n",
        "print(\"\\nActual vs Predicted Comparison (All samples):\")\n",
        "for i, row in all_df.iterrows():\n",
        "    a_mn, a_mw = row[\"Actual_Mn\"], row[\"Actual_Mw\"]\n",
        "    p_mn, p_mw = row[\"Predicted_Mn\"], row[\"Predicted_Mw\"]\n",
        "    print(f\"Sample {int(row['Sample']):2d}: Actual=[ {a_mn:7.2f}, {a_mw:7.2f} ] | Predicted=[ {p_mn:7.2f}, {p_mw:7.2f} ]\")\n",
        "\n",
        "print(\"\\nDetailed Comparison Table:\")\n",
        "print(all_df.to_string(index=False))\n",
        "# ==== end ===="
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h69WHf600b4j",
        "outputId": "51143a62-9213-496c-a26c-5f38ee94f961"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Actual vs Predicted Comparison (All samples):\n",
            "Sample  1: Actual=[ 1127.19, 1321.65 ] | Predicted=[ 1127.20, 1321.66 ]\n",
            "Sample  2: Actual=[ 1127.20, 1321.66 ] | Predicted=[ 1127.21, 1321.67 ]\n",
            "Sample  3: Actual=[ 1127.21, 1321.67 ] | Predicted=[ 1127.33, 1321.79 ]\n",
            "Sample  4: Actual=[ 1127.22, 1321.68 ] | Predicted=[ 1127.23, 1321.69 ]\n",
            "Sample  5: Actual=[ 1127.23, 1321.69 ] | Predicted=[ 1127.30, 1321.76 ]\n",
            "Sample  6: Actual=[ 1127.24, 1321.70 ] | Predicted=[ 1127.31, 1321.77 ]\n",
            "Sample  7: Actual=[ 1127.25, 1321.71 ] | Predicted=[ 1127.26, 1321.72 ]\n",
            "Sample  8: Actual=[ 1127.26, 1321.72 ] | Predicted=[ 1127.27, 1321.73 ]\n",
            "Sample  9: Actual=[ 1127.27, 1321.73 ] | Predicted=[ 1127.28, 1321.74 ]\n",
            "Sample 10: Actual=[ 1127.28, 1321.74 ] | Predicted=[ 1127.29, 1321.75 ]\n",
            "Sample 11: Actual=[ 1127.29, 1321.75 ] | Predicted=[ 1127.28, 1321.74 ]\n",
            "Sample 12: Actual=[ 1127.30, 1321.76 ] | Predicted=[ 1127.31, 1321.77 ]\n",
            "Sample 13: Actual=[ 1127.31, 1321.77 ] | Predicted=[ 1127.32, 1321.78 ]\n",
            "Sample 14: Actual=[ 1127.32, 1321.78 ] | Predicted=[ 1127.34, 1321.80 ]\n",
            "Sample 15: Actual=[ 1127.33, 1321.79 ] | Predicted=[ 1127.31, 1321.77 ]\n",
            "Sample 16: Actual=[ 1127.34, 1321.80 ] | Predicted=[ 1127.33, 1321.79 ]\n",
            "Sample 17: Actual=[ 1127.35, 1321.81 ] | Predicted=[ 1127.34, 1321.80 ]\n",
            "Sample 18: Actual=[ 1127.36, 1321.82 ] | Predicted=[ 1127.35, 1321.81 ]\n",
            "Sample 19: Actual=[ 1127.37, 1321.83 ] | Predicted=[ 1127.36, 1321.82 ]\n",
            "Sample 20: Actual=[ 1127.38, 1321.84 ] | Predicted=[ 1127.37, 1321.83 ]\n",
            "Sample 21: Actual=[ 1127.39, 1321.85 ] | Predicted=[ 1127.38, 1321.84 ]\n",
            "Sample 22: Actual=[ 1127.40, 1321.86 ] | Predicted=[ 1127.29, 1321.75 ]\n",
            "Sample 23: Actual=[ 1127.41, 1321.87 ] | Predicted=[ 1127.40, 1321.86 ]\n",
            "Sample 24: Actual=[ 1127.42, 1321.88 ] | Predicted=[ 1127.30, 1321.76 ]\n",
            "Sample 25: Actual=[ 1127.43, 1321.89 ] | Predicted=[ 1127.42, 1321.88 ]\n",
            "\n",
            "Detailed Comparison Table:\n",
            " Sample  Actual_Mn  Actual_Mw  Predicted_Mn  Predicted_Mw  Error_Mn  Error_Mw\n",
            "      1    1127.19    1321.65   1127.199959   1321.659959  0.009959  0.009959\n",
            "      2    1127.20    1321.66   1127.210334   1321.670334  0.010334  0.010334\n",
            "      3    1127.21    1321.67   1127.330189   1321.790189  0.120189  0.120189\n",
            "      4    1127.22    1321.68   1127.230125   1321.690125  0.010125  0.010125\n",
            "      5    1127.23    1321.69   1127.297105   1321.757105  0.067105  0.067105\n",
            "      6    1127.24    1321.70   1127.309089   1321.769089  0.069089  0.069089\n",
            "      7    1127.25    1321.71   1127.260441   1321.720441  0.010441  0.010441\n",
            "      8    1127.26    1321.72   1127.270042   1321.730042  0.010042  0.010042\n",
            "      9    1127.27    1321.73   1127.280134   1321.740134  0.010134  0.010134\n",
            "     10    1127.28    1321.74   1127.289654   1321.749654  0.009654  0.009654\n",
            "     11    1127.29    1321.75   1127.279448   1321.739448  0.010552  0.010552\n",
            "     12    1127.30    1321.76   1127.309844   1321.769844  0.009844  0.009844\n",
            "     13    1127.31    1321.77   1127.320125   1321.780125  0.010125  0.010125\n",
            "     14    1127.32    1321.78   1127.340116   1321.800116  0.020116  0.020116\n",
            "     15    1127.33    1321.79   1127.309089   1321.769089  0.020911  0.020911\n",
            "     16    1127.34    1321.80   1127.330189   1321.790189  0.009811  0.009811\n",
            "     17    1127.35    1321.81   1127.340116   1321.800116  0.009884  0.009884\n",
            "     18    1127.36    1321.82   1127.349577   1321.809577  0.010423  0.010423\n",
            "     19    1127.37    1321.83   1127.360067   1321.820067  0.009933  0.009933\n",
            "     20    1127.38    1321.84   1127.370311   1321.830311  0.009689  0.009689\n",
            "     21    1127.39    1321.85   1127.379637   1321.839637  0.010363  0.010363\n",
            "     22    1127.40    1321.86   1127.289654   1321.749654  0.110346  0.110346\n",
            "     23    1127.41    1321.87   1127.399985   1321.859985  0.010015  0.010015\n",
            "     24    1127.42    1321.88   1127.297105   1321.757105  0.122895  0.122895\n",
            "     25    1127.43    1321.89   1127.420013   1321.880013  0.009987  0.009987\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g = GridSearchCV(base, param_grid, cv=cv, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
        "model = MultiOutputRegressor(g)\n",
        "model.fit(X, Y)\n",
        "for i, t in enumerate(TARGETS):\n",
        "    best = model.estimators_[i].best_params_\n",
        "    print(f\"Best params for {t}: {best}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ie32vD4Vq6uH",
        "outputId": "a636d21f-f075-406f-fb51-1a95a9e0a0fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best params for Response 1 (Mn): {'svr__C': 1, 'svr__epsilon': 0.1, 'svr__gamma': 'scale', 'svr__kernel': 'poly'}\n",
            "Best params for Response 2 (Mw): {'svr__C': 1, 'svr__epsilon': 0.1, 'svr__gamma': 'scale', 'svr__kernel': 'poly'}\n"
          ]
        }
      ]
    }
  ]
}
