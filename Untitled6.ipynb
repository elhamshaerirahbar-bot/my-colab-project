{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elhamshaerirahbar-bot/my-colab-project/blob/main/Untitled6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7PCY5nnfk-j",
        "outputId": "fc25fd5f-2b4a-48a7-ce37-7e46ae6f4162"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.14.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.74.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.8.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy pandas tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Ply4xLZf99B",
        "outputId": "3e42f9ff-bebe-4937-a419-9dc83c67a289"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np, pandas as pd, re, unicodedata\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, callbacks\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.metrics import mean_absolute_percentage_error"
      ],
      "metadata": {
        "id": "RoYIR3-bTQYb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd, re, unicodedata\n",
        "from difflib import get_close_matches\n",
        "\n",
        "WANTED = ['factor A','factor B','factor C','factor D','Response 2 (Mw)']\n",
        "\n",
        "def norm(s: str) -> str:\n",
        "    s = unicodedata.normalize(\"NFKC\", str(s))\n",
        "    s = s.replace(\"\\ufeff\",\"\").replace(\"\\u00a0\",\" \")\n",
        "    s = re.sub(r\"\\s+\",\" \", s).strip()\n",
        "    return s.lower()\n",
        "\n",
        "df = pd.read_csv('Python.csv', sep=';', encoding='utf-8-sig')\n",
        "\n",
        "\n",
        "name_map = {norm(c): c for c in df.columns}\n",
        "\n",
        "def map_col(wanted: str):\n",
        "    k = norm(wanted)\n",
        "    if k in name_map:\n",
        "        return name_map[k]\n",
        "\n",
        "    cand = get_close_matches(k, list(name_map.keys()), n=1, cutoff=0.7)\n",
        "    return name_map[cand[0]] if cand else None\n",
        "\n",
        "mapped = [(w, map_col(w)) for w in WANTED]\n",
        "missing = [w for w,c in mapped if c is None]\n",
        "cols    = [c for _,c in mapped if c is not None]\n",
        "\n",
        "print(f\"Missing: {missing}\")\n",
        "\n",
        "n = 5\n",
        "view = df[cols].head(n)\n",
        "try:\n",
        "    display(view)\n",
        "except NameError:\n",
        "    print(view.to_string(index=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "lf9CE9iHTS4y",
        "outputId": "5364a0be-9170-4360-bdff-a435fb0661c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing: []\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   factor A  factor B  factor C  factor D       Response 2 (Mw)\n",
              "0       110         7        50        10               1321.65\n",
              "1        85         4        50        30               1321.66\n",
              "2       101         1       500        60               1321.67\n",
              "3        79         1       219        10               1321.68\n",
              "4        50         1       500        20               1321.69"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d37abe5e-eac6-44fc-901a-98c080ac6f79\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>factor A</th>\n",
              "      <th>factor B</th>\n",
              "      <th>factor C</th>\n",
              "      <th>factor D</th>\n",
              "      <th>Response 2 (Mw)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>110</td>\n",
              "      <td>7</td>\n",
              "      <td>50</td>\n",
              "      <td>10</td>\n",
              "      <td>1321.65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>85</td>\n",
              "      <td>4</td>\n",
              "      <td>50</td>\n",
              "      <td>30</td>\n",
              "      <td>1321.66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>101</td>\n",
              "      <td>1</td>\n",
              "      <td>500</td>\n",
              "      <td>60</td>\n",
              "      <td>1321.67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>79</td>\n",
              "      <td>1</td>\n",
              "      <td>219</td>\n",
              "      <td>10</td>\n",
              "      <td>1321.68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "      <td>500</td>\n",
              "      <td>20</td>\n",
              "      <td>1321.69</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d37abe5e-eac6-44fc-901a-98c080ac6f79')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d37abe5e-eac6-44fc-901a-98c080ac6f79 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d37abe5e-eac6-44fc-901a-98c080ac6f79');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-f7f30747-431b-4b74-ab72-4c8ea364afb6\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f7f30747-431b-4b74-ab72-4c8ea364afb6')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-f7f30747-431b-4b74-ab72-4c8ea364afb6 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_769020a5-03f2-420b-bc36-4c55c8d8608c\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('view')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_769020a5-03f2-420b-bc36-4c55c8d8608c button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('view');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "view",
              "summary": "{\n  \"name\": \"view\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"factor A\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 23,\n        \"min\": 50,\n        \"max\": 110,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          85,\n          50,\n          101\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"factor B\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 1,\n        \"max\": 7,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          7,\n          4,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"factor C\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 226,\n        \"min\": 50,\n        \"max\": 500,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          50,\n          500,\n          219\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"factor D\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 20,\n        \"min\": 10,\n        \"max\": 60,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          30,\n          20,\n          10\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"     Response 2 (Mw)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.015811388300827515,\n        \"min\": 1321.65,\n        \"max\": 1321.69,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1321.66,\n          1321.69,\n          1321.67\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- pick columns via your map_col (no warnings) ----\n",
        "FEATURES = [map_col('factor A'), map_col('factor B'),\n",
        "            map_col('factor C'), map_col('factor D')]\n",
        "TARGET   = map_col('Response 1 (Mw)')\n",
        "\n",
        "X = df[FEATURES].astype(float).to_numpy()      # (n,4)\n",
        "y = df[[TARGET]].astype(float).to_numpy()      # (n,1)"
      ],
      "metadata": {
        "id": "zoROFQAITYgL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.20, shuffle=True, random_state=55\n",
        ")\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train, y_train, test_size=0.20, shuffle=True, random_state=55\n",
        ")\n",
        "\n",
        "SEED = 42\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, shuffle=True, random_state=SEED\n",
        ")"
      ],
      "metadata": {
        "id": "YPBXRXMkTlnO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "x_scaler = StandardScaler().fit(X_train)\n",
        "X_train_z = x_scaler.transform(X_train)\n",
        "X_val_z   = x_scaler.transform(X_val)\n",
        "X_test_z  = x_scaler.transform(X_test)\n",
        "\n",
        "y_scaler  = MinMaxScaler(feature_range=(-1, 1)).fit(y_train)\n",
        "y_train_s = y_scaler.transform(y_train)\n",
        "y_val_s   = y_scaler.transform(y_val)\n",
        "y_test_s  = y_scaler.transform(y_test)\n",
        "\n",
        "def inv_y(y_s):\n",
        "    return y_scaler.inverse_transform(y_s)"
      ],
      "metadata": {
        "id": "xStCRF8qTpOQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ann = tf.keras.models.Sequential()"
      ],
      "metadata": {
        "id": "IyrP3XFrpbc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(16, activation='relu', input_shape=(X_train.shape[1],)))  # لایه اول\n",
        "model.add(Dropout(0.2))   # 👈 Dropout بعد از هر لایه Dense\n",
        "model.add(Dense(1,  activation='tanh'))  # خروجی\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae', 'mape'])"
      ],
      "metadata": {
        "id": "s9CsQjDiTtro",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13f4b513-2648-4963-889b-f1d72f8530ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RepeatedKFold\n",
        "rkf = RepeatedKFold(n_splits=5, n_repeats=10, random_state=55)"
      ],
      "metadata": {
        "id": "IrGpwk1fTw94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='mse', metrics=['mae', 'mape'])\n",
        "\n",
        "early_stop = callbacks.EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
        "\n",
        "history = model.fit(\n",
        "    X_train_z, y_train_s,\n",
        "    validation_data=(X_val_z, y_val_s),\n",
        "    epochs=500, batch_size=16, callbacks=[early_stop], verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FgqaS2a0T0wB",
        "outputId": "cee74e4f-3322-48c6-fa6f-55ea0b13faa3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 664ms/step - loss: 0.7251 - mae: 0.7122 - mape: 259.6328 - val_loss: 1.1416 - val_mae: 1.0207 - val_mape: 606.3148\n",
            "Epoch 2/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 0.7523 - mae: 0.7184 - mape: 249.7076 - val_loss: 1.1279 - val_mae: 1.0152 - val_mape: 603.5591\n",
            "Epoch 3/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 311ms/step - loss: 0.7781 - mae: 0.7356 - mape: 358.6148 - val_loss: 1.1125 - val_mae: 1.0087 - val_mape: 600.3607\n",
            "Epoch 4/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 277ms/step - loss: 0.7419 - mae: 0.7490 - mape: 345.9778 - val_loss: 1.0970 - val_mae: 1.0023 - val_mape: 597.1298\n",
            "Epoch 5/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 246ms/step - loss: 0.6482 - mae: 0.6927 - mape: 309.2624 - val_loss: 1.0811 - val_mae: 0.9956 - val_mape: 593.6129\n",
            "Epoch 6/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - loss: 0.6981 - mae: 0.7005 - mape: 343.0630 - val_loss: 1.0657 - val_mae: 0.9890 - val_mape: 590.0312\n",
            "Epoch 7/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.6852 - mae: 0.6895 - mape: 329.7541 - val_loss: 1.0510 - val_mae: 0.9827 - val_mape: 586.7754\n",
            "Epoch 8/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.6327 - mae: 0.6589 - mape: 314.4793 - val_loss: 1.0352 - val_mae: 0.9760 - val_mape: 583.3589\n",
            "Epoch 9/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.5441 - mae: 0.6559 - mape: 324.7816 - val_loss: 1.0194 - val_mae: 0.9691 - val_mape: 579.8895\n",
            "Epoch 10/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.7491 - mae: 0.7427 - mape: 330.7146 - val_loss: 1.0037 - val_mae: 0.9622 - val_mape: 576.2928\n",
            "Epoch 11/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.5503 - mae: 0.6496 - mape: 304.1240 - val_loss: 0.9885 - val_mae: 0.9554 - val_mape: 572.8712\n",
            "Epoch 12/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.7135 - mae: 0.7009 - mape: 344.6247 - val_loss: 0.9735 - val_mae: 0.9487 - val_mape: 569.4096\n",
            "Epoch 13/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.7293 - mae: 0.7086 - mape: 332.4359 - val_loss: 0.9589 - val_mae: 0.9421 - val_mape: 565.9823\n",
            "Epoch 14/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.6905 - mae: 0.7154 - mape: 309.2361 - val_loss: 0.9448 - val_mae: 0.9357 - val_mape: 562.5607\n",
            "Epoch 15/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.7185 - mae: 0.7498 - mape: 360.7705 - val_loss: 0.9306 - val_mae: 0.9292 - val_mape: 559.1196\n",
            "Epoch 16/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.7777 - mae: 0.7716 - mape: 355.3322 - val_loss: 0.9164 - val_mae: 0.9225 - val_mape: 555.4782\n",
            "Epoch 17/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.6039 - mae: 0.6876 - mape: 330.4028 - val_loss: 0.9019 - val_mae: 0.9158 - val_mape: 551.8148\n",
            "Epoch 18/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.7324 - mae: 0.7510 - mape: 331.4006 - val_loss: 0.8869 - val_mae: 0.9087 - val_mape: 547.8726\n",
            "Epoch 19/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.6018 - mae: 0.6458 - mape: 314.2457 - val_loss: 0.8713 - val_mae: 0.9012 - val_mape: 543.5883\n",
            "Epoch 20/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.7347 - mae: 0.7506 - mape: 346.4950 - val_loss: 0.8556 - val_mae: 0.8936 - val_mape: 539.2861\n",
            "Epoch 21/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.6024 - mae: 0.6541 - mape: 312.1823 - val_loss: 0.8406 - val_mae: 0.8862 - val_mape: 535.0854\n",
            "Epoch 22/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.4785 - mae: 0.6169 - mape: 295.4795 - val_loss: 0.8256 - val_mae: 0.8788 - val_mape: 530.8881\n",
            "Epoch 23/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.6030 - mae: 0.6836 - mape: 339.0143 - val_loss: 0.8111 - val_mae: 0.8715 - val_mape: 526.8946\n",
            "Epoch 24/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.6773 - mae: 0.7098 - mape: 290.4320 - val_loss: 0.7965 - val_mae: 0.8641 - val_mape: 522.8073\n",
            "Epoch 25/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.6432 - mae: 0.6861 - mape: 313.6291 - val_loss: 0.7821 - val_mae: 0.8568 - val_mape: 518.7153\n",
            "Epoch 26/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.6040 - mae: 0.6767 - mape: 317.3711 - val_loss: 0.7679 - val_mae: 0.8494 - val_mape: 514.5832\n",
            "Epoch 27/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.6117 - mae: 0.6810 - mape: 305.1279 - val_loss: 0.7538 - val_mae: 0.8420 - val_mape: 510.1562\n",
            "Epoch 28/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.6124 - mae: 0.6663 - mape: 319.5830 - val_loss: 0.7401 - val_mae: 0.8346 - val_mape: 505.6700\n",
            "Epoch 29/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.5541 - mae: 0.6306 - mape: 311.2568 - val_loss: 0.7264 - val_mae: 0.8272 - val_mape: 501.2193\n",
            "Epoch 30/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.6706 - mae: 0.7110 - mape: 322.4297 - val_loss: 0.7126 - val_mae: 0.8196 - val_mape: 496.5865\n",
            "Epoch 31/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.5815 - mae: 0.6645 - mape: 285.6085 - val_loss: 0.6989 - val_mae: 0.8121 - val_mape: 491.9364\n",
            "Epoch 32/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.4859 - mae: 0.6029 - mape: 301.7787 - val_loss: 0.6860 - val_mae: 0.8049 - val_mape: 487.5061\n",
            "Epoch 33/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.6155 - mae: 0.6918 - mape: 334.7932 - val_loss: 0.6723 - val_mae: 0.7972 - val_mape: 482.8561\n",
            "Epoch 34/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.5199 - mae: 0.6079 - mape: 295.1797 - val_loss: 0.6586 - val_mae: 0.7893 - val_mape: 478.1812\n",
            "Epoch 35/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.5351 - mae: 0.6298 - mape: 286.7770 - val_loss: 0.6451 - val_mae: 0.7815 - val_mape: 473.5103\n",
            "Epoch 36/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.6295 - mae: 0.6863 - mape: 306.6167 - val_loss: 0.6317 - val_mae: 0.7737 - val_mape: 468.7092\n",
            "Epoch 37/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.5761 - mae: 0.6673 - mape: 303.5607 - val_loss: 0.6187 - val_mae: 0.7659 - val_mape: 463.8762\n",
            "Epoch 38/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.5816 - mae: 0.6708 - mape: 309.2606 - val_loss: 0.6057 - val_mae: 0.7580 - val_mape: 459.0537\n",
            "Epoch 39/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.6640 - mae: 0.6674 - mape: 161.0511 - val_loss: 0.5929 - val_mae: 0.7502 - val_mape: 454.2307\n",
            "Epoch 40/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.4291 - mae: 0.5632 - mape: 281.5261 - val_loss: 0.5805 - val_mae: 0.7426 - val_mape: 449.5651\n",
            "Epoch 41/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.5876 - mae: 0.6530 - mape: 275.1003 - val_loss: 0.5686 - val_mae: 0.7351 - val_mape: 444.9748\n",
            "Epoch 42/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.6243 - mae: 0.6989 - mape: 315.2896 - val_loss: 0.5576 - val_mae: 0.7282 - val_mape: 440.6376\n",
            "Epoch 43/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.5979 - mae: 0.6997 - mape: 316.2350 - val_loss: 0.5466 - val_mae: 0.7212 - val_mape: 436.2401\n",
            "Epoch 44/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.4747 - mae: 0.6182 - mape: 288.2130 - val_loss: 0.5365 - val_mae: 0.7146 - val_mape: 431.9213\n",
            "Epoch 45/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.5912 - mae: 0.6829 - mape: 295.7486 - val_loss: 0.5266 - val_mae: 0.7082 - val_mape: 427.7264\n",
            "Epoch 46/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.5937 - mae: 0.6740 - mape: 260.8639 - val_loss: 0.5166 - val_mae: 0.7015 - val_mape: 423.4061\n",
            "Epoch 47/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.4269 - mae: 0.5438 - mape: 236.9548 - val_loss: 0.5061 - val_mae: 0.6945 - val_mape: 418.9416\n",
            "Epoch 48/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.4887 - mae: 0.6118 - mape: 268.9280 - val_loss: 0.4959 - val_mae: 0.6875 - val_mape: 414.4860\n",
            "Epoch 49/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.5051 - mae: 0.6100 - mape: 224.5142 - val_loss: 0.4871 - val_mae: 0.6814 - val_mape: 410.7089\n",
            "Epoch 50/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.5381 - mae: 0.6461 - mape: 216.9520 - val_loss: 0.4790 - val_mae: 0.6758 - val_mape: 407.3337\n",
            "Epoch 51/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.4957 - mae: 0.6127 - mape: 278.2968 - val_loss: 0.4710 - val_mae: 0.6702 - val_mape: 403.9015\n",
            "Epoch 52/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.5796 - mae: 0.6810 - mape: 301.4895 - val_loss: 0.4623 - val_mae: 0.6640 - val_mape: 400.0577\n",
            "Epoch 53/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.4559 - mae: 0.6003 - mape: 262.8665 - val_loss: 0.4539 - val_mae: 0.6579 - val_mape: 396.2507\n",
            "Epoch 54/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.6162 - mae: 0.6781 - mape: 279.4978 - val_loss: 0.4453 - val_mae: 0.6515 - val_mape: 392.2163\n",
            "Epoch 55/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.5722 - mae: 0.6900 - mape: 293.0988 - val_loss: 0.4372 - val_mae: 0.6454 - val_mape: 388.3882\n",
            "Epoch 56/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.5059 - mae: 0.6215 - mape: 269.1666 - val_loss: 0.4297 - val_mae: 0.6397 - val_mape: 384.7554\n",
            "Epoch 57/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.4912 - mae: 0.5976 - mape: 213.8641 - val_loss: 0.4223 - val_mae: 0.6340 - val_mape: 381.3569\n",
            "Epoch 58/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.5524 - mae: 0.6466 - mape: 198.5623 - val_loss: 0.4150 - val_mae: 0.6284 - val_mape: 378.0367\n",
            "Epoch 59/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 0.4618 - mae: 0.5994 - mape: 246.6885 - val_loss: 0.4079 - val_mae: 0.6228 - val_mape: 374.8029\n",
            "Epoch 60/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.4913 - mae: 0.6145 - mape: 233.5425 - val_loss: 0.4011 - val_mae: 0.6174 - val_mape: 371.3564\n",
            "Epoch 61/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 0.5505 - mae: 0.6123 - mape: 135.3608 - val_loss: 0.3941 - val_mae: 0.6117 - val_mape: 367.8489\n",
            "Epoch 62/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.5008 - mae: 0.6243 - mape: 283.6748 - val_loss: 0.3871 - val_mae: 0.6060 - val_mape: 364.1488\n",
            "Epoch 63/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.5446 - mae: 0.6424 - mape: 280.2004 - val_loss: 0.3800 - val_mae: 0.6000 - val_mape: 360.1678\n",
            "Epoch 64/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.3727 - mae: 0.4880 - mape: 218.2522 - val_loss: 0.3732 - val_mae: 0.5942 - val_mape: 356.1770\n",
            "Epoch 65/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.4614 - mae: 0.6074 - mape: 235.0092 - val_loss: 0.3660 - val_mae: 0.5880 - val_mape: 351.7657\n",
            "Epoch 66/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.4921 - mae: 0.5904 - mape: 218.2909 - val_loss: 0.3588 - val_mae: 0.5818 - val_mape: 347.3922\n",
            "Epoch 67/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.4312 - mae: 0.5938 - mape: 262.5453 - val_loss: 0.3524 - val_mae: 0.5761 - val_mape: 343.4424\n",
            "Epoch 68/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.4268 - mae: 0.5368 - mape: 213.3329 - val_loss: 0.3467 - val_mae: 0.5710 - val_mape: 339.9960\n",
            "Epoch 69/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3691 - mae: 0.5178 - mape: 241.9166 - val_loss: 0.3410 - val_mae: 0.5658 - val_mape: 336.2866\n",
            "Epoch 70/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.4443 - mae: 0.5441 - mape: 263.4874 - val_loss: 0.3352 - val_mae: 0.5605 - val_mape: 332.3299\n",
            "Epoch 71/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.4336 - mae: 0.5341 - mape: 162.3985 - val_loss: 0.3291 - val_mae: 0.5548 - val_mape: 328.2538\n",
            "Epoch 72/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.4326 - mae: 0.5767 - mape: 186.9257 - val_loss: 0.3229 - val_mae: 0.5490 - val_mape: 324.0750\n",
            "Epoch 73/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.3920 - mae: 0.5481 - mape: 246.2722 - val_loss: 0.3167 - val_mae: 0.5431 - val_mape: 320.1554\n",
            "Epoch 74/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.3852 - mae: 0.5093 - mape: 195.3512 - val_loss: 0.3105 - val_mae: 0.5370 - val_mape: 315.9575\n",
            "Epoch 75/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.4304 - mae: 0.5892 - mape: 233.6662 - val_loss: 0.3041 - val_mae: 0.5307 - val_mape: 311.6319\n",
            "Epoch 76/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.4534 - mae: 0.6126 - mape: 282.5532 - val_loss: 0.2974 - val_mae: 0.5240 - val_mape: 306.9392\n",
            "Epoch 77/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.4035 - mae: 0.5692 - mape: 259.5698 - val_loss: 0.2906 - val_mae: 0.5170 - val_mape: 301.9702\n",
            "Epoch 78/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3931 - mae: 0.5383 - mape: 201.0124 - val_loss: 0.2842 - val_mae: 0.5103 - val_mape: 296.8284\n",
            "Epoch 79/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.5266 - mae: 0.6431 - mape: 213.8441 - val_loss: 0.2785 - val_mae: 0.5043 - val_mape: 292.1180\n",
            "Epoch 80/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.4719 - mae: 0.5772 - mape: 212.2674 - val_loss: 0.2734 - val_mae: 0.4987 - val_mape: 287.5070\n",
            "Epoch 81/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.4939 - mae: 0.6144 - mape: 268.6705 - val_loss: 0.2681 - val_mae: 0.4929 - val_mape: 283.0207\n",
            "Epoch 82/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.3943 - mae: 0.5526 - mape: 210.3468 - val_loss: 0.2628 - val_mae: 0.4869 - val_mape: 278.3795\n",
            "Epoch 83/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.3709 - mae: 0.4821 - mape: 171.5886 - val_loss: 0.2574 - val_mae: 0.4809 - val_mape: 273.9143\n",
            "Epoch 84/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.3937 - mae: 0.5254 - mape: 186.6964 - val_loss: 0.2525 - val_mae: 0.4754 - val_mape: 270.1292\n",
            "Epoch 85/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.4392 - mae: 0.5649 - mape: 197.6221 - val_loss: 0.2481 - val_mae: 0.4704 - val_mape: 266.8764\n",
            "Epoch 86/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.3464 - mae: 0.5005 - mape: 202.4272 - val_loss: 0.2441 - val_mae: 0.4658 - val_mape: 263.8251\n",
            "Epoch 87/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.3901 - mae: 0.5510 - mape: 233.8573 - val_loss: 0.2403 - val_mae: 0.4612 - val_mape: 260.7680\n",
            "Epoch 88/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.3733 - mae: 0.5544 - mape: 229.0070 - val_loss: 0.2366 - val_mae: 0.4567 - val_mape: 257.7998\n",
            "Epoch 89/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.4149 - mae: 0.5631 - mape: 198.4765 - val_loss: 0.2331 - val_mae: 0.4524 - val_mape: 254.5976\n",
            "Epoch 90/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.4670 - mae: 0.5899 - mape: 230.7622 - val_loss: 0.2296 - val_mae: 0.4479 - val_mape: 251.2002\n",
            "Epoch 91/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.5246 - mae: 0.6212 - mape: 223.0760 - val_loss: 0.2261 - val_mae: 0.4435 - val_mape: 247.9102\n",
            "Epoch 92/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.4457 - mae: 0.5658 - mape: 204.6268 - val_loss: 0.2230 - val_mae: 0.4394 - val_mape: 244.7921\n",
            "Epoch 93/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.3843 - mae: 0.5413 - mape: 176.0215 - val_loss: 0.2197 - val_mae: 0.4351 - val_mape: 241.6515\n",
            "Epoch 94/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.4006 - mae: 0.5452 - mape: 188.9120 - val_loss: 0.2165 - val_mae: 0.4308 - val_mape: 238.3958\n",
            "Epoch 95/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.3653 - mae: 0.5142 - mape: 206.7730 - val_loss: 0.2134 - val_mae: 0.4267 - val_mape: 235.1124\n",
            "Epoch 96/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.4504 - mae: 0.5851 - mape: 188.8030 - val_loss: 0.2110 - val_mae: 0.4232 - val_mape: 232.7025\n",
            "Epoch 97/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.3559 - mae: 0.5173 - mape: 193.2496 - val_loss: 0.2089 - val_mae: 0.4202 - val_mape: 230.2375\n",
            "Epoch 98/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.3089 - mae: 0.4774 - mape: 187.1137 - val_loss: 0.2063 - val_mae: 0.4164 - val_mape: 227.0046\n",
            "Epoch 99/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.3946 - mae: 0.5556 - mape: 186.7295 - val_loss: 0.2041 - val_mae: 0.4132 - val_mape: 224.2265\n",
            "Epoch 100/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.3306 - mae: 0.4923 - mape: 152.4368 - val_loss: 0.2020 - val_mae: 0.4102 - val_mape: 221.4034\n",
            "Epoch 101/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.4398 - mae: 0.5833 - mape: 201.6792 - val_loss: 0.2002 - val_mae: 0.4075 - val_mape: 218.7528\n",
            "Epoch 102/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.4224 - mae: 0.5532 - mape: 160.5457 - val_loss: 0.1986 - val_mae: 0.4050 - val_mape: 216.5586\n",
            "Epoch 103/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.3258 - mae: 0.4867 - mape: 151.3437 - val_loss: 0.1967 - val_mae: 0.4022 - val_mape: 214.1479\n",
            "Epoch 104/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.3186 - mae: 0.4534 - mape: 148.1538 - val_loss: 0.1949 - val_mae: 0.3996 - val_mape: 212.1336\n",
            "Epoch 105/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.4524 - mae: 0.5676 - mape: 214.4877 - val_loss: 0.1932 - val_mae: 0.3970 - val_mape: 210.1763\n",
            "Epoch 106/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.3422 - mae: 0.4801 - mape: 144.3025 - val_loss: 0.1919 - val_mae: 0.3949 - val_mape: 208.4741\n",
            "Epoch 107/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.4254 - mae: 0.5837 - mape: 241.2328 - val_loss: 0.1907 - val_mae: 0.3929 - val_mape: 206.4106\n",
            "Epoch 108/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.4484 - mae: 0.5596 - mape: 216.5192 - val_loss: 0.1892 - val_mae: 0.3903 - val_mape: 203.7657\n",
            "Epoch 109/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.3492 - mae: 0.4712 - mape: 162.2825 - val_loss: 0.1877 - val_mae: 0.3879 - val_mape: 201.0968\n",
            "Epoch 110/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.3455 - mae: 0.4958 - mape: 150.8833 - val_loss: 0.1864 - val_mae: 0.3855 - val_mape: 198.2643\n",
            "Epoch 111/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.4622 - mae: 0.5608 - mape: 160.2384 - val_loss: 0.1853 - val_mae: 0.3834 - val_mape: 195.8177\n",
            "Epoch 112/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.4083 - mae: 0.5510 - mape: 160.7509 - val_loss: 0.1845 - val_mae: 0.3817 - val_mape: 193.8159\n",
            "Epoch 113/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.3858 - mae: 0.5095 - mape: 172.4944 - val_loss: 0.1837 - val_mae: 0.3799 - val_mape: 191.7576\n",
            "Epoch 114/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.3334 - mae: 0.5036 - mape: 186.8680 - val_loss: 0.1827 - val_mae: 0.3780 - val_mape: 189.8145\n",
            "Epoch 115/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.3568 - mae: 0.5083 - mape: 182.3714 - val_loss: 0.1815 - val_mae: 0.3761 - val_mape: 188.3651\n",
            "Epoch 116/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.3475 - mae: 0.4767 - mape: 148.7288 - val_loss: 0.1804 - val_mae: 0.3741 - val_mape: 187.1050\n",
            "Epoch 117/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.3952 - mae: 0.5431 - mape: 184.8522 - val_loss: 0.1788 - val_mae: 0.3717 - val_mape: 185.3953\n",
            "Epoch 118/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.4288 - mae: 0.5706 - mape: 196.4134 - val_loss: 0.1777 - val_mae: 0.3696 - val_mape: 183.7834\n",
            "Epoch 119/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.3637 - mae: 0.5158 - mape: 143.3913 - val_loss: 0.1767 - val_mae: 0.3676 - val_mape: 182.0919\n",
            "Epoch 120/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.3058 - mae: 0.4604 - mape: 145.8080 - val_loss: 0.1754 - val_mae: 0.3652 - val_mape: 180.2137\n",
            "Epoch 121/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.3093 - mae: 0.4602 - mape: 108.2910 - val_loss: 0.1742 - val_mae: 0.3630 - val_mape: 178.6236\n",
            "Epoch 122/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.4007 - mae: 0.5252 - mape: 178.0552 - val_loss: 0.1731 - val_mae: 0.3610 - val_mape: 177.4016\n",
            "Epoch 123/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.4548 - mae: 0.5505 - mape: 177.0628 - val_loss: 0.1726 - val_mae: 0.3597 - val_mape: 176.4866\n",
            "Epoch 124/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.4742 - mae: 0.5766 - mape: 171.2261 - val_loss: 0.1721 - val_mae: 0.3584 - val_mape: 175.3760\n",
            "Epoch 125/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.3576 - mae: 0.4945 - mape: 145.3376 - val_loss: 0.1714 - val_mae: 0.3571 - val_mape: 174.3192\n",
            "Epoch 126/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.2715 - mae: 0.4333 - mape: 144.1860 - val_loss: 0.1708 - val_mae: 0.3558 - val_mape: 173.2676\n",
            "Epoch 127/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.3853 - mae: 0.5159 - mape: 185.4192 - val_loss: 0.1700 - val_mae: 0.3545 - val_mape: 172.3757\n",
            "Epoch 128/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.3404 - mae: 0.4817 - mape: 179.8797 - val_loss: 0.1692 - val_mae: 0.3532 - val_mape: 171.5138\n",
            "Epoch 129/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.3315 - mae: 0.4710 - mape: 122.0168 - val_loss: 0.1684 - val_mae: 0.3517 - val_mape: 170.4282\n",
            "Epoch 130/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.3788 - mae: 0.5086 - mape: 139.5569 - val_loss: 0.1674 - val_mae: 0.3500 - val_mape: 168.8177\n",
            "Epoch 131/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.3675 - mae: 0.5004 - mape: 169.9663 - val_loss: 0.1662 - val_mae: 0.3479 - val_mape: 166.8097\n",
            "Epoch 132/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.2760 - mae: 0.4343 - mape: 139.8933 - val_loss: 0.1654 - val_mae: 0.3465 - val_mape: 165.4721\n",
            "Epoch 133/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.3399 - mae: 0.4906 - mape: 154.6313 - val_loss: 0.1649 - val_mae: 0.3454 - val_mape: 164.3498\n",
            "Epoch 134/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.3179 - mae: 0.4715 - mape: 128.0066 - val_loss: 0.1644 - val_mae: 0.3444 - val_mape: 163.4520\n",
            "Epoch 135/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.4038 - mae: 0.5632 - mape: 179.4573 - val_loss: 0.1643 - val_mae: 0.3436 - val_mape: 162.5344\n",
            "Epoch 136/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.2750 - mae: 0.4173 - mape: 116.4721 - val_loss: 0.1645 - val_mae: 0.3431 - val_mape: 161.7348\n",
            "Epoch 137/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.3514 - mae: 0.5104 - mape: 154.0593 - val_loss: 0.1645 - val_mae: 0.3426 - val_mape: 161.2017\n",
            "Epoch 138/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.3703 - mae: 0.4787 - mape: 137.7396 - val_loss: 0.1643 - val_mae: 0.3418 - val_mape: 160.4308\n",
            "Epoch 139/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.3516 - mae: 0.4643 - mape: 114.3340 - val_loss: 0.1641 - val_mae: 0.3411 - val_mape: 159.8291\n",
            "Epoch 140/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.3480 - mae: 0.4787 - mape: 168.6534 - val_loss: 0.1637 - val_mae: 0.3402 - val_mape: 159.1543\n",
            "Epoch 141/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.2753 - mae: 0.4393 - mape: 149.1159 - val_loss: 0.1632 - val_mae: 0.3392 - val_mape: 158.4380\n",
            "Epoch 142/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.4357 - mae: 0.5805 - mape: 227.8795 - val_loss: 0.1631 - val_mae: 0.3388 - val_mape: 158.2056\n",
            "Epoch 143/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 0.4029 - mae: 0.5497 - mape: 156.7982 - val_loss: 0.1632 - val_mae: 0.3384 - val_mape: 157.7314\n",
            "Epoch 144/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.4205 - mae: 0.5408 - mape: 190.3433 - val_loss: 0.1634 - val_mae: 0.3381 - val_mape: 157.1544\n",
            "Epoch 145/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.3751 - mae: 0.5132 - mape: 156.1278 - val_loss: 0.1638 - val_mae: 0.3381 - val_mape: 156.7843\n",
            "Epoch 146/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.3725 - mae: 0.4940 - mape: 119.7047 - val_loss: 0.1640 - val_mae: 0.3379 - val_mape: 156.4534\n",
            "Epoch 147/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 0.3565 - mae: 0.5003 - mape: 194.9971 - val_loss: 0.1641 - val_mae: 0.3374 - val_mape: 155.8080\n",
            "Epoch 148/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - loss: 0.3456 - mae: 0.5035 - mape: 170.9017 - val_loss: 0.1637 - val_mae: 0.3363 - val_mape: 154.7680\n",
            "Epoch 149/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.3616 - mae: 0.5055 - mape: 122.3333 - val_loss: 0.1631 - val_mae: 0.3348 - val_mape: 153.3866\n",
            "Epoch 150/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.3200 - mae: 0.4610 - mape: 128.6347 - val_loss: 0.1622 - val_mae: 0.3331 - val_mape: 152.1320\n",
            "Epoch 151/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.3189 - mae: 0.4411 - mape: 132.6580 - val_loss: 0.1611 - val_mae: 0.3311 - val_mape: 150.6609\n",
            "Epoch 152/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.2876 - mae: 0.4406 - mape: 120.9029 - val_loss: 0.1602 - val_mae: 0.3292 - val_mape: 149.1278\n",
            "Epoch 153/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.3016 - mae: 0.4665 - mape: 150.6026 - val_loss: 0.1597 - val_mae: 0.3279 - val_mape: 147.8085\n",
            "Epoch 154/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.3062 - mae: 0.4489 - mape: 103.9056 - val_loss: 0.1592 - val_mae: 0.3265 - val_mape: 146.4021\n",
            "Epoch 155/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.3938 - mae: 0.5126 - mape: 117.6888 - val_loss: 0.1588 - val_mae: 0.3253 - val_mape: 145.1652\n",
            "Epoch 156/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.2818 - mae: 0.4438 - mape: 120.9991 - val_loss: 0.1586 - val_mae: 0.3244 - val_mape: 144.1082\n",
            "Epoch 157/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.3710 - mae: 0.4904 - mape: 121.0763 - val_loss: 0.1581 - val_mae: 0.3232 - val_mape: 142.9400\n",
            "Epoch 158/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.3439 - mae: 0.4848 - mape: 164.5202 - val_loss: 0.1575 - val_mae: 0.3215 - val_mape: 141.3211\n",
            "Epoch 159/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.3026 - mae: 0.4392 - mape: 128.2079 - val_loss: 0.1569 - val_mae: 0.3201 - val_mape: 140.0415\n",
            "Epoch 160/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.3187 - mae: 0.4593 - mape: 127.2703 - val_loss: 0.1562 - val_mae: 0.3183 - val_mape: 138.7551\n",
            "Epoch 161/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.4094 - mae: 0.5419 - mape: 212.9614 - val_loss: 0.1558 - val_mae: 0.3173 - val_mape: 137.9324\n",
            "Epoch 162/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.2797 - mae: 0.4630 - mape: 181.0971 - val_loss: 0.1556 - val_mae: 0.3165 - val_mape: 137.3508\n",
            "Epoch 163/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.4083 - mae: 0.5404 - mape: 175.3273 - val_loss: 0.1554 - val_mae: 0.3157 - val_mape: 136.8892\n",
            "Epoch 164/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381ms/step - loss: 0.2961 - mae: 0.4288 - mape: 104.9953 - val_loss: 0.1552 - val_mae: 0.3150 - val_mape: 136.3600\n",
            "Epoch 165/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.3541 - mae: 0.4792 - mape: 156.1992 - val_loss: 0.1551 - val_mae: 0.3145 - val_mape: 136.1498\n",
            "Epoch 166/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.3185 - mae: 0.4455 - mape: 148.2184 - val_loss: 0.1555 - val_mae: 0.3150 - val_mape: 136.6019\n",
            "Epoch 167/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.3314 - mae: 0.4806 - mape: 194.7129 - val_loss: 0.1560 - val_mae: 0.3154 - val_mape: 137.0856\n",
            "Epoch 168/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.3098 - mae: 0.4507 - mape: 151.8358 - val_loss: 0.1566 - val_mae: 0.3160 - val_mape: 137.8185\n",
            "Epoch 169/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.3528 - mae: 0.4828 - mape: 129.0100 - val_loss: 0.1566 - val_mae: 0.3158 - val_mape: 138.0112\n",
            "Epoch 170/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.2741 - mae: 0.4163 - mape: 124.1116 - val_loss: 0.1563 - val_mae: 0.3150 - val_mape: 137.5861\n",
            "Epoch 171/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.3015 - mae: 0.4121 - mape: 85.4366 - val_loss: 0.1560 - val_mae: 0.3143 - val_mape: 136.9600\n",
            "Epoch 172/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.3448 - mae: 0.5046 - mape: 208.0132 - val_loss: 0.1560 - val_mae: 0.3140 - val_mape: 136.7268\n",
            "Epoch 173/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.4280 - mae: 0.5380 - mape: 162.6081 - val_loss: 0.1562 - val_mae: 0.3141 - val_mape: 136.8717\n",
            "Epoch 174/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.3576 - mae: 0.5121 - mape: 211.5793 - val_loss: 0.1566 - val_mae: 0.3144 - val_mape: 136.8846\n",
            "Epoch 175/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.4040 - mae: 0.5489 - mape: 152.3794 - val_loss: 0.1569 - val_mae: 0.3146 - val_mape: 136.8900\n",
            "Epoch 176/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.2919 - mae: 0.4032 - mape: 126.2968 - val_loss: 0.1573 - val_mae: 0.3148 - val_mape: 136.8316\n",
            "Epoch 177/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.3597 - mae: 0.5169 - mape: 155.5450 - val_loss: 0.1575 - val_mae: 0.3145 - val_mape: 136.0349\n",
            "Epoch 178/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.2389 - mae: 0.4041 - mape: 143.4986 - val_loss: 0.1572 - val_mae: 0.3137 - val_mape: 135.1102\n",
            "Epoch 179/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.3037 - mae: 0.4630 - mape: 135.3288 - val_loss: 0.1567 - val_mae: 0.3125 - val_mape: 134.0880\n",
            "Epoch 180/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.4504 - mae: 0.5614 - mape: 148.2950 - val_loss: 0.1559 - val_mae: 0.3109 - val_mape: 132.8531\n",
            "Epoch 181/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.3572 - mae: 0.5042 - mape: 152.6522 - val_loss: 0.1549 - val_mae: 0.3090 - val_mape: 131.4485\n",
            "Epoch 182/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.2463 - mae: 0.4124 - mape: 105.4806 - val_loss: 0.1540 - val_mae: 0.3073 - val_mape: 130.3041\n",
            "Epoch 183/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.3956 - mae: 0.4844 - mape: 127.5812 - val_loss: 0.1534 - val_mae: 0.3061 - val_mape: 129.4748\n",
            "Epoch 184/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.4043 - mae: 0.5272 - mape: 176.1127 - val_loss: 0.1529 - val_mae: 0.3052 - val_mape: 128.7831\n",
            "Epoch 185/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.3343 - mae: 0.4855 - mape: 163.4615 - val_loss: 0.1523 - val_mae: 0.3040 - val_mape: 127.9472\n",
            "Epoch 186/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.3262 - mae: 0.4854 - mape: 139.0670 - val_loss: 0.1517 - val_mae: 0.3030 - val_mape: 127.6030\n",
            "Epoch 187/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.3249 - mae: 0.4834 - mape: 218.7047 - val_loss: 0.1511 - val_mae: 0.3021 - val_mape: 127.1557\n",
            "Epoch 188/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.2975 - mae: 0.4571 - mape: 132.8378 - val_loss: 0.1505 - val_mae: 0.3011 - val_mape: 126.7032\n",
            "Epoch 189/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.4062 - mae: 0.5472 - mape: 176.6100 - val_loss: 0.1499 - val_mae: 0.3002 - val_mape: 125.9689\n",
            "Epoch 190/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.3244 - mae: 0.5081 - mape: 216.1195 - val_loss: 0.1497 - val_mae: 0.3000 - val_mape: 125.9351\n",
            "Epoch 191/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.2924 - mae: 0.4538 - mape: 138.5052 - val_loss: 0.1495 - val_mae: 0.2994 - val_mape: 125.4992\n",
            "Epoch 192/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.3203 - mae: 0.4702 - mape: 172.9536 - val_loss: 0.1493 - val_mae: 0.2988 - val_mape: 124.8799\n",
            "Epoch 193/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.2253 - mae: 0.4250 - mape: 137.4972 - val_loss: 0.1491 - val_mae: 0.2980 - val_mape: 123.5737\n",
            "Epoch 194/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.3794 - mae: 0.4984 - mape: 126.5754 - val_loss: 0.1488 - val_mae: 0.2969 - val_mape: 122.0792\n",
            "Epoch 195/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.3297 - mae: 0.4894 - mape: 147.3628 - val_loss: 0.1486 - val_mae: 0.2961 - val_mape: 121.0063\n",
            "Epoch 196/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.3320 - mae: 0.4933 - mape: 162.4604 - val_loss: 0.1484 - val_mae: 0.2952 - val_mape: 119.9084\n",
            "Epoch 197/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.3325 - mae: 0.4742 - mape: 118.4000 - val_loss: 0.1481 - val_mae: 0.2943 - val_mape: 119.0281\n",
            "Epoch 198/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.4377 - mae: 0.5664 - mape: 191.5266 - val_loss: 0.1479 - val_mae: 0.2934 - val_mape: 117.9788\n",
            "Epoch 199/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.3405 - mae: 0.4819 - mape: 142.7320 - val_loss: 0.1480 - val_mae: 0.2928 - val_mape: 117.0315\n",
            "Epoch 200/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.3521 - mae: 0.4698 - mape: 130.1817 - val_loss: 0.1480 - val_mae: 0.2923 - val_mape: 115.9984\n",
            "Epoch 201/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.4191 - mae: 0.5409 - mape: 190.3956 - val_loss: 0.1481 - val_mae: 0.2922 - val_mape: 115.4325\n",
            "Epoch 202/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.2854 - mae: 0.4432 - mape: 165.4580 - val_loss: 0.1481 - val_mae: 0.2919 - val_mape: 114.9364\n",
            "Epoch 203/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.3744 - mae: 0.5193 - mape: 140.4825 - val_loss: 0.1478 - val_mae: 0.2914 - val_mape: 114.5477\n",
            "Epoch 204/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.2698 - mae: 0.4232 - mape: 143.1626 - val_loss: 0.1472 - val_mae: 0.2904 - val_mape: 114.0434\n",
            "Epoch 205/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.3660 - mae: 0.5152 - mape: 150.8652 - val_loss: 0.1470 - val_mae: 0.2900 - val_mape: 114.0676\n",
            "Epoch 206/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.3919 - mae: 0.5712 - mape: 214.3393 - val_loss: 0.1471 - val_mae: 0.2902 - val_mape: 114.4332\n",
            "Epoch 207/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.3076 - mae: 0.4363 - mape: 117.3752 - val_loss: 0.1473 - val_mae: 0.2905 - val_mape: 115.1255\n",
            "Epoch 208/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.3123 - mae: 0.4310 - mape: 163.1129 - val_loss: 0.1476 - val_mae: 0.2911 - val_mape: 115.9494\n",
            "Epoch 209/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.3538 - mae: 0.5037 - mape: 175.8910 - val_loss: 0.1477 - val_mae: 0.2913 - val_mape: 116.6969\n",
            "Epoch 210/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.3145 - mae: 0.4590 - mape: 125.4217 - val_loss: 0.1475 - val_mae: 0.2911 - val_mape: 117.1337\n",
            "Epoch 211/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.3225 - mae: 0.4600 - mape: 135.6528 - val_loss: 0.1474 - val_mae: 0.2908 - val_mape: 117.4579\n",
            "Epoch 212/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.3480 - mae: 0.4742 - mape: 147.8991 - val_loss: 0.1473 - val_mae: 0.2907 - val_mape: 117.7829\n",
            "Epoch 213/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.3360 - mae: 0.4788 - mape: 172.1618 - val_loss: 0.1473 - val_mae: 0.2908 - val_mape: 118.5173\n",
            "Epoch 214/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.3076 - mae: 0.4966 - mape: 198.7778 - val_loss: 0.1472 - val_mae: 0.2907 - val_mape: 119.1248\n",
            "Epoch 215/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.2165 - mae: 0.3776 - mape: 112.2787 - val_loss: 0.1468 - val_mae: 0.2901 - val_mape: 119.3375\n",
            "Epoch 216/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.3091 - mae: 0.4582 - mape: 148.6858 - val_loss: 0.1466 - val_mae: 0.2896 - val_mape: 119.3637\n",
            "Epoch 217/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.2372 - mae: 0.4126 - mape: 138.3745 - val_loss: 0.1463 - val_mae: 0.2891 - val_mape: 119.2571\n",
            "Epoch 218/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.3015 - mae: 0.4580 - mape: 145.0310 - val_loss: 0.1461 - val_mae: 0.2886 - val_mape: 119.1368\n",
            "Epoch 219/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.3005 - mae: 0.4531 - mape: 114.9120 - val_loss: 0.1457 - val_mae: 0.2878 - val_mape: 118.6046\n",
            "Epoch 220/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.3684 - mae: 0.5232 - mape: 181.7346 - val_loss: 0.1450 - val_mae: 0.2866 - val_mape: 117.8754\n",
            "Epoch 221/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.3188 - mae: 0.4521 - mape: 167.3343 - val_loss: 0.1443 - val_mae: 0.2854 - val_mape: 116.9878\n",
            "Epoch 222/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.3094 - mae: 0.4570 - mape: 179.1288 - val_loss: 0.1437 - val_mae: 0.2843 - val_mape: 115.9879\n",
            "Epoch 223/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.3378 - mae: 0.4874 - mape: 201.0032 - val_loss: 0.1432 - val_mae: 0.2833 - val_mape: 114.9902\n",
            "Epoch 224/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.3285 - mae: 0.4851 - mape: 163.6790 - val_loss: 0.1427 - val_mae: 0.2829 - val_mape: 114.3206\n",
            "Epoch 225/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 0.3694 - mae: 0.5184 - mape: 160.9442 - val_loss: 0.1420 - val_mae: 0.2824 - val_mape: 113.7089\n",
            "Epoch 226/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 0.3141 - mae: 0.5029 - mape: 176.3289 - val_loss: 0.1415 - val_mae: 0.2820 - val_mape: 113.2296\n",
            "Epoch 227/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.2848 - mae: 0.4570 - mape: 128.7678 - val_loss: 0.1412 - val_mae: 0.2816 - val_mape: 112.3659\n",
            "Epoch 228/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.3254 - mae: 0.4963 - mape: 162.4992 - val_loss: 0.1412 - val_mae: 0.2814 - val_mape: 111.8850\n",
            "Epoch 229/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 0.2801 - mae: 0.4685 - mape: 141.2798 - val_loss: 0.1410 - val_mae: 0.2812 - val_mape: 111.2214\n",
            "Epoch 230/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.3187 - mae: 0.4558 - mape: 176.2899 - val_loss: 0.1407 - val_mae: 0.2809 - val_mape: 110.5708\n",
            "Epoch 231/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.2870 - mae: 0.4420 - mape: 126.9629 - val_loss: 0.1402 - val_mae: 0.2804 - val_mape: 109.7494\n",
            "Epoch 232/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.3058 - mae: 0.4725 - mape: 205.3549 - val_loss: 0.1398 - val_mae: 0.2801 - val_mape: 109.2650\n",
            "Epoch 233/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.2951 - mae: 0.4479 - mape: 157.1844 - val_loss: 0.1390 - val_mae: 0.2795 - val_mape: 108.5309\n",
            "Epoch 234/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.2293 - mae: 0.3874 - mape: 138.7487 - val_loss: 0.1384 - val_mae: 0.2792 - val_mape: 108.3806\n",
            "Epoch 235/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.3110 - mae: 0.4585 - mape: 107.1134 - val_loss: 0.1377 - val_mae: 0.2790 - val_mape: 108.3390\n",
            "Epoch 236/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.2493 - mae: 0.4192 - mape: 135.9916 - val_loss: 0.1370 - val_mae: 0.2787 - val_mape: 108.1435\n",
            "Epoch 237/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.3408 - mae: 0.5072 - mape: 224.8061 - val_loss: 0.1364 - val_mae: 0.2784 - val_mape: 107.9778\n",
            "Epoch 238/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.3007 - mae: 0.4799 - mape: 167.2281 - val_loss: 0.1361 - val_mae: 0.2782 - val_mape: 107.6632\n",
            "Epoch 239/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.3643 - mae: 0.4917 - mape: 119.3919 - val_loss: 0.1356 - val_mae: 0.2778 - val_mape: 106.9613\n",
            "Epoch 240/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.2918 - mae: 0.4420 - mape: 143.0299 - val_loss: 0.1352 - val_mae: 0.2774 - val_mape: 106.0222\n",
            "Epoch 241/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.3201 - mae: 0.4647 - mape: 128.8749 - val_loss: 0.1349 - val_mae: 0.2770 - val_mape: 105.1842\n",
            "Epoch 242/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.3663 - mae: 0.5251 - mape: 172.8685 - val_loss: 0.1348 - val_mae: 0.2769 - val_mape: 104.9073\n",
            "Epoch 243/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.3579 - mae: 0.5069 - mape: 175.1907 - val_loss: 0.1353 - val_mae: 0.2774 - val_mape: 105.2804\n",
            "Epoch 244/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.2693 - mae: 0.4615 - mape: 189.5707 - val_loss: 0.1360 - val_mae: 0.2779 - val_mape: 105.7786\n",
            "Epoch 245/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.2442 - mae: 0.4000 - mape: 124.5803 - val_loss: 0.1363 - val_mae: 0.2782 - val_mape: 105.9282\n",
            "Epoch 246/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.3034 - mae: 0.4901 - mape: 199.6251 - val_loss: 0.1367 - val_mae: 0.2785 - val_mape: 106.0629\n",
            "Epoch 247/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.2856 - mae: 0.4443 - mape: 160.9081 - val_loss: 0.1374 - val_mae: 0.2791 - val_mape: 106.2667\n",
            "Epoch 248/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.2472 - mae: 0.4193 - mape: 169.7534 - val_loss: 0.1382 - val_mae: 0.2797 - val_mape: 106.4404\n",
            "Epoch 249/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.2812 - mae: 0.4429 - mape: 147.5752 - val_loss: 0.1390 - val_mae: 0.2803 - val_mape: 106.3910\n",
            "Epoch 250/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.2930 - mae: 0.4791 - mape: 208.3167 - val_loss: 0.1393 - val_mae: 0.2806 - val_mape: 106.2020\n",
            "Epoch 251/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.2821 - mae: 0.4618 - mape: 165.1256 - val_loss: 0.1395 - val_mae: 0.2806 - val_mape: 105.5610\n",
            "Epoch 252/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.2681 - mae: 0.4048 - mape: 148.8852 - val_loss: 0.1397 - val_mae: 0.2808 - val_mape: 105.2858\n",
            "Epoch 253/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.2433 - mae: 0.4027 - mape: 109.8849 - val_loss: 0.1399 - val_mae: 0.2812 - val_mape: 105.3456\n",
            "Epoch 254/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.2721 - mae: 0.4615 - mape: 153.2829 - val_loss: 0.1399 - val_mae: 0.2815 - val_mape: 105.3299\n",
            "Epoch 255/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.3788 - mae: 0.5283 - mape: 182.7281 - val_loss: 0.1399 - val_mae: 0.2817 - val_mape: 105.4629\n",
            "Epoch 256/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.2581 - mae: 0.4335 - mape: 131.4788 - val_loss: 0.1398 - val_mae: 0.2818 - val_mape: 105.3240\n",
            "Epoch 257/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.4003 - mae: 0.5593 - mape: 181.7537 - val_loss: 0.1398 - val_mae: 0.2820 - val_mape: 105.4203\n",
            "Epoch 258/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.3624 - mae: 0.5151 - mape: 188.6987 - val_loss: 0.1398 - val_mae: 0.2821 - val_mape: 105.2561\n",
            "Epoch 259/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.3766 - mae: 0.5171 - mape: 137.8907 - val_loss: 0.1399 - val_mae: 0.2824 - val_mape: 105.1812\n",
            "Epoch 260/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.2954 - mae: 0.4811 - mape: 182.2573 - val_loss: 0.1400 - val_mae: 0.2825 - val_mape: 104.7009\n",
            "Epoch 261/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.2652 - mae: 0.4218 - mape: 135.6011 - val_loss: 0.1403 - val_mae: 0.2828 - val_mape: 104.7643\n",
            "Epoch 262/500\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.3383 - mae: 0.4938 - mape: 144.0266 - val_loss: 0.1406 - val_mae: 0.2831 - val_mape: 104.7812\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_hat_train_s = model.predict(X_train_z, verbose=0)\n",
        "y_hat_val_s   = model.predict(X_val_z,   verbose=0)\n",
        "y_hat_test_s  = model.predict(X_test_z,  verbose=0)"
      ],
      "metadata": {
        "id": "VsgYTBPkP8z8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_hat_train = inv_y(model.predict(X_train_z, verbose=1))\n",
        "y_hat_val   = inv_y(model.predict(X_val_z,   verbose=1))\n",
        "y_hat_test  = inv_y(model.predict(X_test_z,  verbose=1))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W48cxUFBT7n0",
        "outputId": "9a1ab0c8-4139-4a03-a2f9-b042c1ab4e09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install matplotlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5TKLdJycUCAq",
        "outputId": "320a66d7-b75d-4dc3-d856-a592c55595a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.59.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "7lCNrtTnUGyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "def report(name, yt, yp):\n",
        "    yt = np.asarray(yt).reshape(-1, 1)\n",
        "    yp = np.asarray(yp).reshape(-1, 1)\n",
        "    mse  = mean_squared_error(yt, yp)\n",
        "    mae  = mean_absolute_error(yt, yp)\n",
        "    mape = mean_absolute_percentage_error(yt, yp)\n",
        "    r2   = r2_score(yt, yp)\n",
        "    print(f\"[{name}] MSE={mse:.6f}  MAE={mae:.6f}  MAPE={mape:.6f}  R²={r2:.4f}\")\n",
        "\n",
        "print(\"\\n== Performance (real units) ==\")\n",
        "report(\"Train\", y_train, y_hat_train)\n",
        "report(\"Val  \", y_val,   y_hat_val)\n",
        "report(\"Test \", y_test,  y_hat_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvkQ8koaUKIN",
        "outputId": "25c9dc8f-2ef8-41f8-b1e0-9ccf5ac99076"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "== Performance (real units) ==\n",
            "[Train] MSE=0.003469  MAE=0.049277  MAPE=0.000037  R²=0.3075\n",
            "[Val  ] MSE=0.001783  MAE=0.031841  MAPE=0.000024  R²=0.3906\n",
            "[Test ] MSE=0.005804  MAE=0.055435  MAPE=0.000042  R²=0.0235\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "def diag(name, y_true, y_pred):\n",
        "    var = np.var(y_true, ddof=0)\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    mse_mean = mean_squared_error(y_true, np.full_like(y_true, y_true.mean()))\n",
        "    r2  = r2_score(y_true, y_pred)\n",
        "    print(f\"{name}: n={len(y_true)}  Var(y)={var:.6f}  MSE(model)={mse:.6f}  MSE(mean)={mse_mean:.6f}  R²={r2:.4f}\")\n",
        "\n",
        "diag(\"Train\", y_train, y_hat_train)\n",
        "diag(\"Val  \", y_val,   y_hat_val)\n",
        "diag(\"Test \", y_test,  y_hat_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGQ4X6nDZ5Gt",
        "outputId": "50692ec2-ef91-49de-fd74-557784274df9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: n=20  Var(y)=0.005009  MSE(model)=0.003469  MSE(mean)=0.005009  R²=0.3075\n",
            "Val  : n=4  Var(y)=0.002925  MSE(model)=0.001783  MSE(mean)=0.002925  R²=0.3906\n",
            "Test : n=5  Var(y)=0.005944  MSE(model)=0.005804  MSE(mean)=0.005944  R²=0.0235\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np, pandas as pd\n",
        "\n",
        "def make_table(split, y_true, y_pred, n=None):\n",
        "    y_true = np.asarray(y_true).reshape(-1)\n",
        "    y_pred = np.asarray(y_pred).reshape(-1)\n",
        "    tbl = pd.DataFrame({\n",
        "        \"split\":     split,\n",
        "        \"actual\":    y_true,\n",
        "        \"predicted\": y_pred,\n",
        "    })\n",
        "    tbl[\"residual\"]  = tbl[\"actual\"] - tbl[\"predicted\"]\n",
        "    tbl[\"abs_error\"] = tbl[\"residual\"].abs()\n",
        "    tbl[\"pct_error\"] = 100 * tbl[\"abs_error\"] / np.maximum(1e-8, np.abs(tbl[\"actual\"]))\n",
        "    return tbl if n is None else tbl.head(n)\n",
        "\n",
        "tbl_train = make_table(\"Train\", y_train, y_hat_train)\n",
        "tbl_val   = make_table(\"Val\",   y_val,   y_hat_val)\n",
        "tbl_test  = make_table(\"Test\",  y_test,  y_hat_test)\n",
        "\n",
        "tbl_all = pd.concat([tbl_train, tbl_val, tbl_test], ignore_index=True)\n",
        "print(tbl_all.to_string(index=False))         # یا display(tbl_all) در نوت‌بوک"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUChBdexaBnr",
        "outputId": "f167ad67-f076-42fd-a8f9-0815d4f6b9c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "split  actual   predicted  residual  abs_error  pct_error\n",
            "Train 1321.74 1321.758545 -0.018545   0.018545   0.001403\n",
            "Train 1321.78 1321.773926  0.006074   0.006074   0.000460\n",
            "Train 1321.66 1321.756226 -0.096226   0.096226   0.007281\n",
            "Train 1321.87 1321.801270  0.068730   0.068730   0.005199\n",
            "Train 1321.70 1321.713501 -0.013501   0.013501   0.001021\n",
            "Train 1321.67 1321.792236 -0.122236   0.122236   0.009249\n",
            "Train 1321.77 1321.804443 -0.034443   0.034443   0.002606\n",
            "Train 1321.80 1321.792236  0.007764   0.007764   0.000587\n",
            "Train 1321.68 1321.710815 -0.030815   0.030815   0.002332\n",
            "Train 1321.69 1321.736450 -0.046450   0.046450   0.003514\n",
            "Train 1321.85 1321.792114  0.057886   0.057886   0.004379\n",
            "Train 1321.82 1321.781128  0.038872   0.038872   0.002941\n",
            "Train 1321.86 1321.758545  0.101455   0.101455   0.007675\n",
            "Train 1321.83 1321.796143  0.033857   0.033857   0.002561\n",
            "Train 1321.89 1321.832397  0.057603   0.057603   0.004358\n",
            "Train 1321.72 1321.783691 -0.063691   0.063691   0.004819\n",
            "Train 1321.75 1321.688599  0.061401   0.061401   0.004645\n",
            "Train 1321.79 1321.713501  0.076499   0.076499   0.005788\n",
            "Train 1321.84 1321.842285 -0.002285   0.002285   0.000173\n",
            "Train 1321.71 1321.757202 -0.047202   0.047202   0.003571\n",
            "  Val 1321.84 1321.842285 -0.002285   0.002285   0.000173\n",
            "  Val 1321.78 1321.773926  0.006074   0.006074   0.000460\n",
            "  Val 1321.75 1321.688599  0.061401   0.061401   0.004645\n",
            "  Val 1321.89 1321.832397  0.057603   0.057603   0.004358\n",
            " Test 1321.73 1321.733765 -0.003765   0.003765   0.000285\n",
            " Test 1321.81 1321.773926  0.036074   0.036074   0.002729\n",
            " Test 1321.65 1321.733643 -0.083643   0.083643   0.006329\n",
            " Test 1321.88 1321.736450  0.143550   0.143550   0.010860\n",
            " Test 1321.76 1321.770142 -0.010142   0.010142   0.000767\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.model_selection import RepeatedKFold, cross_val_score\n",
        "import numpy as np\n",
        "\n",
        "rkf = RepeatedKFold(n_splits=5, n_repeats=20, random_state=42)\n",
        "\n",
        "pipe = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"ridge\", Ridge(alpha=1.0))\n",
        "])\n",
        "\n",
        "scores = cross_val_score(pipe, X, y.ravel(), cv=rkf, scoring=\"r2\")\n",
        "print(\"Baseline Ridge  R²: mean=%.3f  std=%.3f\" % (scores.mean(), scores.std()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gkjscs0jUU8p",
        "outputId": "901bce8b-07f4-49bc-9be9-27a5515ca276"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline Ridge  R²: mean=-1.314  std=2.614\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- 0) Reproducibility / Determinism ----\n",
        "import os, random, numpy as np, tensorflow as tf\n",
        "\n",
        "SEED = 42\n",
        "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
        "os.environ[\"TF_DETERMINISTIC_OPS\"] = \"1\"\n",
        "\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "try:\n",
        "    tf.keras.utils.set_random_seed(SEED)\n",
        "    tf.config.experimental.enable_op_determinism(True)\n",
        "except Exception:\n",
        "    pass"
      ],
      "metadata": {
        "id": "nj2MXYlXUmA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- 5) Activation (Transfer Function) sweep on hidden layers ----\n",
        "import random, numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, optimizers\n",
        "\n",
        "activations = ['relu', 'tanh', 'sigmoid', 'softplus']\n",
        "labels      = ['ReLU', 'Tanh', 'Sigmoid', 'Softplus']\n",
        "\n",
        "val_mse_real  = []\n",
        "test_mse_real = []"
      ],
      "metadata": {
        "id": "PzWt1yEgnzsE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for act in activations:\n",
        "\n",
        "    tf.keras.backend.clear_session()\n",
        "    np.random.seed(SEED); random.seed(SEED); tf.random.set_seed(SEED)\n",
        "\n",
        "    model = tf.keras.Sequential([\n",
        "        layers.Input(shape=(X_train_z.shape[1],)),\n",
        "        layers.Dense(16, activation=act),\n",
        "        layers.Dense(1,  activation='tanh')\n",
        "    ])\n",
        "    early_stop = callbacks.EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
        "\n",
        "    model.compile(optimizer=optimizers.Adam(learning_rate=1e-3), loss='mse')\n",
        "\n",
        "    history = model.fit(\n",
        "        X_train_z, y_train_s,\n",
        "        validation_data=(X_val_z, y_val_s),\n",
        "        epochs=200, batch_size=16, shuffle=True, verbose=1,\n",
        "        callbacks=[]\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4fgwqvyoMns",
        "outputId": "db7be420-39b2-4d80-818d-1f1c1ecd915e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 187ms/step - loss: 0.6411 - val_loss: 0.1833\n",
            "Epoch 2/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.6328 - val_loss: 0.1837\n",
            "Epoch 3/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.6257 - val_loss: 0.1838\n",
            "Epoch 4/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.6187 - val_loss: 0.1839\n",
            "Epoch 5/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.6118 - val_loss: 0.1840\n",
            "Epoch 6/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.6050 - val_loss: 0.1842\n",
            "Epoch 7/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.5982 - val_loss: 0.1849\n",
            "Epoch 8/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.5915 - val_loss: 0.1856\n",
            "Epoch 9/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.5847 - val_loss: 0.1863\n",
            "Epoch 10/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.5779 - val_loss: 0.1870\n",
            "Epoch 11/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.5712 - val_loss: 0.1876\n",
            "Epoch 12/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.5644 - val_loss: 0.1882\n",
            "Epoch 13/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.5576 - val_loss: 0.1887\n",
            "Epoch 14/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.5508 - val_loss: 0.1892\n",
            "Epoch 15/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.5440 - val_loss: 0.1897\n",
            "Epoch 16/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.5373 - val_loss: 0.1901\n",
            "Epoch 17/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.5305 - val_loss: 0.1904\n",
            "Epoch 18/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - loss: 0.5238 - val_loss: 0.1907\n",
            "Epoch 19/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step - loss: 0.5171 - val_loss: 0.1909\n",
            "Epoch 20/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.5104 - val_loss: 0.1911\n",
            "Epoch 21/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - loss: 0.5039 - val_loss: 0.1912\n",
            "Epoch 22/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.4974 - val_loss: 0.1912\n",
            "Epoch 23/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.4909 - val_loss: 0.1911\n",
            "Epoch 24/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.4844 - val_loss: 0.1909\n",
            "Epoch 25/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.4781 - val_loss: 0.1906\n",
            "Epoch 26/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.4719 - val_loss: 0.1902\n",
            "Epoch 27/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.4659 - val_loss: 0.1897\n",
            "Epoch 28/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.4600 - val_loss: 0.1892\n",
            "Epoch 29/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.4544 - val_loss: 0.1885\n",
            "Epoch 30/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.4490 - val_loss: 0.1878\n",
            "Epoch 31/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.4438 - val_loss: 0.1871\n",
            "Epoch 32/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.4388 - val_loss: 0.1862\n",
            "Epoch 33/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.4342 - val_loss: 0.1854\n",
            "Epoch 34/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.4298 - val_loss: 0.1844\n",
            "Epoch 35/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.4256 - val_loss: 0.1834\n",
            "Epoch 36/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.4216 - val_loss: 0.1823\n",
            "Epoch 37/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.4179 - val_loss: 0.1812\n",
            "Epoch 38/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.4143 - val_loss: 0.1800\n",
            "Epoch 39/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.4109 - val_loss: 0.1788\n",
            "Epoch 40/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.4077 - val_loss: 0.1776\n",
            "Epoch 41/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.4046 - val_loss: 0.1764\n",
            "Epoch 42/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.4017 - val_loss: 0.1752\n",
            "Epoch 43/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.3988 - val_loss: 0.1741\n",
            "Epoch 44/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3961 - val_loss: 0.1729\n",
            "Epoch 45/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.3936 - val_loss: 0.1718\n",
            "Epoch 46/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3911 - val_loss: 0.1707\n",
            "Epoch 47/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3887 - val_loss: 0.1696\n",
            "Epoch 48/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.3864 - val_loss: 0.1686\n",
            "Epoch 49/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3842 - val_loss: 0.1676\n",
            "Epoch 50/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3820 - val_loss: 0.1667\n",
            "Epoch 51/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3799 - val_loss: 0.1658\n",
            "Epoch 52/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3779 - val_loss: 0.1649\n",
            "Epoch 53/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.3760 - val_loss: 0.1641\n",
            "Epoch 54/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.3741 - val_loss: 0.1634\n",
            "Epoch 55/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3722 - val_loss: 0.1626\n",
            "Epoch 56/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3705 - val_loss: 0.1619\n",
            "Epoch 57/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3688 - val_loss: 0.1613\n",
            "Epoch 58/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.3672 - val_loss: 0.1607\n",
            "Epoch 59/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3656 - val_loss: 0.1601\n",
            "Epoch 60/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.3641 - val_loss: 0.1596\n",
            "Epoch 61/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.3628 - val_loss: 0.1591\n",
            "Epoch 62/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3615 - val_loss: 0.1586\n",
            "Epoch 63/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3602 - val_loss: 0.1581\n",
            "Epoch 64/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3590 - val_loss: 0.1576\n",
            "Epoch 65/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3579 - val_loss: 0.1572\n",
            "Epoch 66/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.3567 - val_loss: 0.1567\n",
            "Epoch 67/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3556 - val_loss: 0.1563\n",
            "Epoch 68/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3546 - val_loss: 0.1560\n",
            "Epoch 69/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.3535 - val_loss: 0.1556\n",
            "Epoch 70/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.3526 - val_loss: 0.1553\n",
            "Epoch 71/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3516 - val_loss: 0.1551\n",
            "Epoch 72/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3508 - val_loss: 0.1548\n",
            "Epoch 73/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.3499 - val_loss: 0.1545\n",
            "Epoch 74/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.3491 - val_loss: 0.1541\n",
            "Epoch 75/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3482 - val_loss: 0.1538\n",
            "Epoch 76/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3474 - val_loss: 0.1535\n",
            "Epoch 77/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3467 - val_loss: 0.1533\n",
            "Epoch 78/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.3459 - val_loss: 0.1530\n",
            "Epoch 79/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3451 - val_loss: 0.1527\n",
            "Epoch 80/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3444 - val_loss: 0.1525\n",
            "Epoch 81/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.3437 - val_loss: 0.1522\n",
            "Epoch 82/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3430 - val_loss: 0.1519\n",
            "Epoch 83/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3423 - val_loss: 0.1517\n",
            "Epoch 84/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.3416 - val_loss: 0.1514\n",
            "Epoch 85/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3409 - val_loss: 0.1512\n",
            "Epoch 86/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3402 - val_loss: 0.1509\n",
            "Epoch 87/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3396 - val_loss: 0.1507\n",
            "Epoch 88/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3390 - val_loss: 0.1505\n",
            "Epoch 89/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3383 - val_loss: 0.1503\n",
            "Epoch 90/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.3377 - val_loss: 0.1502\n",
            "Epoch 91/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3371 - val_loss: 0.1500\n",
            "Epoch 92/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3365 - val_loss: 0.1498\n",
            "Epoch 93/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3359 - val_loss: 0.1497\n",
            "Epoch 94/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.3353 - val_loss: 0.1495\n",
            "Epoch 95/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.3348 - val_loss: 0.1494\n",
            "Epoch 96/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3342 - val_loss: 0.1492\n",
            "Epoch 97/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3336 - val_loss: 0.1491\n",
            "Epoch 98/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.3330 - val_loss: 0.1489\n",
            "Epoch 99/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.3325 - val_loss: 0.1487\n",
            "Epoch 100/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.3319 - val_loss: 0.1486\n",
            "Epoch 101/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.3314 - val_loss: 0.1484\n",
            "Epoch 102/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.3308 - val_loss: 0.1482\n",
            "Epoch 103/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.3303 - val_loss: 0.1481\n",
            "Epoch 104/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.3297 - val_loss: 0.1479\n",
            "Epoch 105/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.3292 - val_loss: 0.1477\n",
            "Epoch 106/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.3287 - val_loss: 0.1476\n",
            "Epoch 107/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.3282 - val_loss: 0.1475\n",
            "Epoch 108/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3277 - val_loss: 0.1473\n",
            "Epoch 109/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.3272 - val_loss: 0.1472\n",
            "Epoch 110/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3268 - val_loss: 0.1470\n",
            "Epoch 111/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3263 - val_loss: 0.1468\n",
            "Epoch 112/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.3258 - val_loss: 0.1467\n",
            "Epoch 113/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3253 - val_loss: 0.1466\n",
            "Epoch 114/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.3249 - val_loss: 0.1464\n",
            "Epoch 115/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3244 - val_loss: 0.1462\n",
            "Epoch 116/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3240 - val_loss: 0.1461\n",
            "Epoch 117/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3235 - val_loss: 0.1459\n",
            "Epoch 118/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3231 - val_loss: 0.1457\n",
            "Epoch 119/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3227 - val_loss: 0.1456\n",
            "Epoch 120/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.3222 - val_loss: 0.1454\n",
            "Epoch 121/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3218 - val_loss: 0.1453\n",
            "Epoch 122/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3214 - val_loss: 0.1451\n",
            "Epoch 123/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.3210 - val_loss: 0.1449\n",
            "Epoch 124/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3206 - val_loss: 0.1448\n",
            "Epoch 125/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3202 - val_loss: 0.1446\n",
            "Epoch 126/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3198 - val_loss: 0.1445\n",
            "Epoch 127/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3194 - val_loss: 0.1445\n",
            "Epoch 128/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3191 - val_loss: 0.1444\n",
            "Epoch 129/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.3187 - val_loss: 0.1444\n",
            "Epoch 130/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.3183 - val_loss: 0.1444\n",
            "Epoch 131/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3180 - val_loss: 0.1443\n",
            "Epoch 132/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3176 - val_loss: 0.1443\n",
            "Epoch 133/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3173 - val_loss: 0.1443\n",
            "Epoch 134/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3169 - val_loss: 0.1443\n",
            "Epoch 135/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3165 - val_loss: 0.1442\n",
            "Epoch 136/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3162 - val_loss: 0.1441\n",
            "Epoch 137/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.3158 - val_loss: 0.1441\n",
            "Epoch 138/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3155 - val_loss: 0.1441\n",
            "Epoch 139/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3152 - val_loss: 0.1440\n",
            "Epoch 140/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.3148 - val_loss: 0.1439\n",
            "Epoch 141/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3145 - val_loss: 0.1439\n",
            "Epoch 142/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.3141 - val_loss: 0.1438\n",
            "Epoch 143/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3138 - val_loss: 0.1438\n",
            "Epoch 144/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3134 - val_loss: 0.1437\n",
            "Epoch 145/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.3131 - val_loss: 0.1436\n",
            "Epoch 146/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.3128 - val_loss: 0.1436\n",
            "Epoch 147/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.3125 - val_loss: 0.1435\n",
            "Epoch 148/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3122 - val_loss: 0.1434\n",
            "Epoch 149/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3118 - val_loss: 0.1434\n",
            "Epoch 150/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3115 - val_loss: 0.1433\n",
            "Epoch 151/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3112 - val_loss: 0.1432\n",
            "Epoch 152/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.3109 - val_loss: 0.1431\n",
            "Epoch 153/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3105 - val_loss: 0.1430\n",
            "Epoch 154/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.3102 - val_loss: 0.1430\n",
            "Epoch 155/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3099 - val_loss: 0.1429\n",
            "Epoch 156/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3096 - val_loss: 0.1428\n",
            "Epoch 157/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.3093 - val_loss: 0.1427\n",
            "Epoch 158/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3089 - val_loss: 0.1426\n",
            "Epoch 159/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3086 - val_loss: 0.1425\n",
            "Epoch 160/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3083 - val_loss: 0.1424\n",
            "Epoch 161/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3080 - val_loss: 0.1422\n",
            "Epoch 162/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3077 - val_loss: 0.1422\n",
            "Epoch 163/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3074 - val_loss: 0.1421\n",
            "Epoch 164/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3071 - val_loss: 0.1420\n",
            "Epoch 165/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3068 - val_loss: 0.1419\n",
            "Epoch 166/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3064 - val_loss: 0.1418\n",
            "Epoch 167/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3061 - val_loss: 0.1417\n",
            "Epoch 168/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3058 - val_loss: 0.1416\n",
            "Epoch 169/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3055 - val_loss: 0.1414\n",
            "Epoch 170/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.3052 - val_loss: 0.1413\n",
            "Epoch 171/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.3049 - val_loss: 0.1412\n",
            "Epoch 172/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3046 - val_loss: 0.1411\n",
            "Epoch 173/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3043 - val_loss: 0.1410\n",
            "Epoch 174/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3040 - val_loss: 0.1408\n",
            "Epoch 175/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3037 - val_loss: 0.1407\n",
            "Epoch 176/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3034 - val_loss: 0.1406\n",
            "Epoch 177/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3031 - val_loss: 0.1405\n",
            "Epoch 178/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.3028 - val_loss: 0.1404\n",
            "Epoch 179/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3025 - val_loss: 0.1402\n",
            "Epoch 180/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3022 - val_loss: 0.1401\n",
            "Epoch 181/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3019 - val_loss: 0.1400\n",
            "Epoch 182/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3016 - val_loss: 0.1399\n",
            "Epoch 183/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3013 - val_loss: 0.1398\n",
            "Epoch 184/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3010 - val_loss: 0.1396\n",
            "Epoch 185/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3007 - val_loss: 0.1395\n",
            "Epoch 186/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.3004 - val_loss: 0.1393\n",
            "Epoch 187/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.3001 - val_loss: 0.1392\n",
            "Epoch 188/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.2998 - val_loss: 0.1390\n",
            "Epoch 189/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.2995 - val_loss: 0.1388\n",
            "Epoch 190/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.2993 - val_loss: 0.1385\n",
            "Epoch 191/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 0.2990 - val_loss: 0.1384\n",
            "Epoch 192/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.2988 - val_loss: 0.1382\n",
            "Epoch 193/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.2985 - val_loss: 0.1380\n",
            "Epoch 194/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.2982 - val_loss: 0.1378\n",
            "Epoch 195/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.2979 - val_loss: 0.1377\n",
            "Epoch 196/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.2976 - val_loss: 0.1375\n",
            "Epoch 197/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.2973 - val_loss: 0.1374\n",
            "Epoch 198/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.2971 - val_loss: 0.1372\n",
            "Epoch 199/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.2968 - val_loss: 0.1370\n",
            "Epoch 200/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.2965 - val_loss: 0.1368\n",
            "Epoch 1/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 183ms/step - loss: 0.8246 - val_loss: 0.1316\n",
            "Epoch 2/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.8169 - val_loss: 0.1276\n",
            "Epoch 3/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.8101 - val_loss: 0.1236\n",
            "Epoch 4/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.8034 - val_loss: 0.1199\n",
            "Epoch 5/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.7966 - val_loss: 0.1166\n",
            "Epoch 6/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.7897 - val_loss: 0.1136\n",
            "Epoch 7/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.7828 - val_loss: 0.1110\n",
            "Epoch 8/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.7757 - val_loss: 0.1088\n",
            "Epoch 9/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.7685 - val_loss: 0.1069\n",
            "Epoch 10/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.7611 - val_loss: 0.1053\n",
            "Epoch 11/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.7536 - val_loss: 0.1040\n",
            "Epoch 12/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.7459 - val_loss: 0.1029\n",
            "Epoch 13/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.7380 - val_loss: 0.1021\n",
            "Epoch 14/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.7299 - val_loss: 0.1014\n",
            "Epoch 15/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.7217 - val_loss: 0.1010\n",
            "Epoch 16/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.7133 - val_loss: 0.1007\n",
            "Epoch 17/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.7047 - val_loss: 0.1005\n",
            "Epoch 18/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.6960 - val_loss: 0.1005\n",
            "Epoch 19/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.6871 - val_loss: 0.1005\n",
            "Epoch 20/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.6782 - val_loss: 0.1007\n",
            "Epoch 21/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.6692 - val_loss: 0.1009\n",
            "Epoch 22/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.6602 - val_loss: 0.1011\n",
            "Epoch 23/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.6512 - val_loss: 0.1015\n",
            "Epoch 24/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.6423 - val_loss: 0.1018\n",
            "Epoch 25/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.6334 - val_loss: 0.1022\n",
            "Epoch 26/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.6247 - val_loss: 0.1025\n",
            "Epoch 27/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.6162 - val_loss: 0.1029\n",
            "Epoch 28/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.6079 - val_loss: 0.1033\n",
            "Epoch 29/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.5998 - val_loss: 0.1037\n",
            "Epoch 30/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.5921 - val_loss: 0.1041\n",
            "Epoch 31/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.5846 - val_loss: 0.1044\n",
            "Epoch 32/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.5775 - val_loss: 0.1047\n",
            "Epoch 33/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.5707 - val_loss: 0.1050\n",
            "Epoch 34/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.5643 - val_loss: 0.1052\n",
            "Epoch 35/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.5582 - val_loss: 0.1054\n",
            "Epoch 36/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.5524 - val_loss: 0.1055\n",
            "Epoch 37/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.5469 - val_loss: 0.1056\n",
            "Epoch 38/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.5417 - val_loss: 0.1057\n",
            "Epoch 39/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.5367 - val_loss: 0.1057\n",
            "Epoch 40/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.5319 - val_loss: 0.1057\n",
            "Epoch 41/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.5273 - val_loss: 0.1057\n",
            "Epoch 42/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.5229 - val_loss: 0.1056\n",
            "Epoch 43/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.5186 - val_loss: 0.1056\n",
            "Epoch 44/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.5145 - val_loss: 0.1056\n",
            "Epoch 45/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.5104 - val_loss: 0.1056\n",
            "Epoch 46/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.5065 - val_loss: 0.1057\n",
            "Epoch 47/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.5026 - val_loss: 0.1058\n",
            "Epoch 48/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.4989 - val_loss: 0.1059\n",
            "Epoch 49/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.4953 - val_loss: 0.1061\n",
            "Epoch 50/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.4917 - val_loss: 0.1064\n",
            "Epoch 51/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.4882 - val_loss: 0.1068\n",
            "Epoch 52/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.4849 - val_loss: 0.1072\n",
            "Epoch 53/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.4816 - val_loss: 0.1076\n",
            "Epoch 54/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.4785 - val_loss: 0.1081\n",
            "Epoch 55/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.4754 - val_loss: 0.1087\n",
            "Epoch 56/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.4724 - val_loss: 0.1093\n",
            "Epoch 57/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.4696 - val_loss: 0.1100\n",
            "Epoch 58/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.4668 - val_loss: 0.1107\n",
            "Epoch 59/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.4642 - val_loss: 0.1114\n",
            "Epoch 60/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.4616 - val_loss: 0.1121\n",
            "Epoch 61/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.4592 - val_loss: 0.1128\n",
            "Epoch 62/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.4568 - val_loss: 0.1135\n",
            "Epoch 63/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.4545 - val_loss: 0.1143\n",
            "Epoch 64/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.4523 - val_loss: 0.1150\n",
            "Epoch 65/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.4502 - val_loss: 0.1157\n",
            "Epoch 66/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.4482 - val_loss: 0.1164\n",
            "Epoch 67/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.4462 - val_loss: 0.1170\n",
            "Epoch 68/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.4443 - val_loss: 0.1177\n",
            "Epoch 69/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.4425 - val_loss: 0.1183\n",
            "Epoch 70/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.4408 - val_loss: 0.1189\n",
            "Epoch 71/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.4391 - val_loss: 0.1195\n",
            "Epoch 72/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.4375 - val_loss: 0.1200\n",
            "Epoch 73/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.4359 - val_loss: 0.1206\n",
            "Epoch 74/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.4344 - val_loss: 0.1211\n",
            "Epoch 75/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.4330 - val_loss: 0.1216\n",
            "Epoch 76/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.4316 - val_loss: 0.1220\n",
            "Epoch 77/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.4302 - val_loss: 0.1225\n",
            "Epoch 78/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.4289 - val_loss: 0.1229\n",
            "Epoch 79/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.4277 - val_loss: 0.1233\n",
            "Epoch 80/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.4265 - val_loss: 0.1237\n",
            "Epoch 81/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.4253 - val_loss: 0.1241\n",
            "Epoch 82/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.4242 - val_loss: 0.1245\n",
            "Epoch 83/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.4231 - val_loss: 0.1249\n",
            "Epoch 84/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.4220 - val_loss: 0.1252\n",
            "Epoch 85/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.4210 - val_loss: 0.1255\n",
            "Epoch 86/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.4200 - val_loss: 0.1259\n",
            "Epoch 87/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.4191 - val_loss: 0.1262\n",
            "Epoch 88/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.4181 - val_loss: 0.1265\n",
            "Epoch 89/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.4172 - val_loss: 0.1268\n",
            "Epoch 90/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.4164 - val_loss: 0.1271\n",
            "Epoch 91/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.4155 - val_loss: 0.1274\n",
            "Epoch 92/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.4147 - val_loss: 0.1276\n",
            "Epoch 93/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.4139 - val_loss: 0.1279\n",
            "Epoch 94/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.4131 - val_loss: 0.1281\n",
            "Epoch 95/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.4124 - val_loss: 0.1284\n",
            "Epoch 96/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.4116 - val_loss: 0.1286\n",
            "Epoch 97/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.4109 - val_loss: 0.1288\n",
            "Epoch 98/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.4102 - val_loss: 0.1290\n",
            "Epoch 99/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.4095 - val_loss: 0.1292\n",
            "Epoch 100/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.4089 - val_loss: 0.1294\n",
            "Epoch 101/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.4082 - val_loss: 0.1296\n",
            "Epoch 102/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.4076 - val_loss: 0.1298\n",
            "Epoch 103/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.4069 - val_loss: 0.1299\n",
            "Epoch 104/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.4063 - val_loss: 0.1301\n",
            "Epoch 105/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.4057 - val_loss: 0.1302\n",
            "Epoch 106/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.4051 - val_loss: 0.1304\n",
            "Epoch 107/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.4045 - val_loss: 0.1305\n",
            "Epoch 108/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.4040 - val_loss: 0.1306\n",
            "Epoch 109/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.4034 - val_loss: 0.1307\n",
            "Epoch 110/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.4028 - val_loss: 0.1308\n",
            "Epoch 111/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.4023 - val_loss: 0.1309\n",
            "Epoch 112/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.4018 - val_loss: 0.1309\n",
            "Epoch 113/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.4012 - val_loss: 0.1310\n",
            "Epoch 114/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.4007 - val_loss: 0.1310\n",
            "Epoch 115/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.4002 - val_loss: 0.1311\n",
            "Epoch 116/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3997 - val_loss: 0.1311\n",
            "Epoch 117/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.3992 - val_loss: 0.1311\n",
            "Epoch 118/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3987 - val_loss: 0.1312\n",
            "Epoch 119/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3982 - val_loss: 0.1312\n",
            "Epoch 120/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.3977 - val_loss: 0.1312\n",
            "Epoch 121/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.3972 - val_loss: 0.1312\n",
            "Epoch 122/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3967 - val_loss: 0.1311\n",
            "Epoch 123/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.3963 - val_loss: 0.1311\n",
            "Epoch 124/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3958 - val_loss: 0.1311\n",
            "Epoch 125/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3953 - val_loss: 0.1311\n",
            "Epoch 126/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3949 - val_loss: 0.1310\n",
            "Epoch 127/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3944 - val_loss: 0.1310\n",
            "Epoch 128/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3940 - val_loss: 0.1309\n",
            "Epoch 129/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3935 - val_loss: 0.1308\n",
            "Epoch 130/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.3931 - val_loss: 0.1308\n",
            "Epoch 131/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3926 - val_loss: 0.1307\n",
            "Epoch 132/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3922 - val_loss: 0.1306\n",
            "Epoch 133/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3917 - val_loss: 0.1305\n",
            "Epoch 134/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.3913 - val_loss: 0.1304\n",
            "Epoch 135/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3909 - val_loss: 0.1303\n",
            "Epoch 136/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3904 - val_loss: 0.1302\n",
            "Epoch 137/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.3900 - val_loss: 0.1301\n",
            "Epoch 138/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.3896 - val_loss: 0.1300\n",
            "Epoch 139/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3891 - val_loss: 0.1298\n",
            "Epoch 140/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3887 - val_loss: 0.1297\n",
            "Epoch 141/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3883 - val_loss: 0.1296\n",
            "Epoch 142/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3879 - val_loss: 0.1294\n",
            "Epoch 143/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3875 - val_loss: 0.1293\n",
            "Epoch 144/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3870 - val_loss: 0.1292\n",
            "Epoch 145/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3866 - val_loss: 0.1290\n",
            "Epoch 146/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3862 - val_loss: 0.1289\n",
            "Epoch 147/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3858 - val_loss: 0.1287\n",
            "Epoch 148/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3854 - val_loss: 0.1286\n",
            "Epoch 149/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.3850 - val_loss: 0.1284\n",
            "Epoch 150/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.3846 - val_loss: 0.1282\n",
            "Epoch 151/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.3842 - val_loss: 0.1281\n",
            "Epoch 152/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.3838 - val_loss: 0.1279\n",
            "Epoch 153/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3834 - val_loss: 0.1277\n",
            "Epoch 154/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.3830 - val_loss: 0.1276\n",
            "Epoch 155/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3826 - val_loss: 0.1274\n",
            "Epoch 156/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3822 - val_loss: 0.1272\n",
            "Epoch 157/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.3818 - val_loss: 0.1270\n",
            "Epoch 158/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3814 - val_loss: 0.1268\n",
            "Epoch 159/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.3810 - val_loss: 0.1266\n",
            "Epoch 160/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.3806 - val_loss: 0.1265\n",
            "Epoch 161/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.3802 - val_loss: 0.1263\n",
            "Epoch 162/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.3798 - val_loss: 0.1261\n",
            "Epoch 163/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 0.3794 - val_loss: 0.1259\n",
            "Epoch 164/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.3790 - val_loss: 0.1257\n",
            "Epoch 165/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.3786 - val_loss: 0.1255\n",
            "Epoch 166/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.3782 - val_loss: 0.1253\n",
            "Epoch 167/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.3778 - val_loss: 0.1251\n",
            "Epoch 168/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 0.3774 - val_loss: 0.1249\n",
            "Epoch 169/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.3770 - val_loss: 0.1247\n",
            "Epoch 170/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3766 - val_loss: 0.1245\n",
            "Epoch 171/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3762 - val_loss: 0.1243\n",
            "Epoch 172/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.3758 - val_loss: 0.1241\n",
            "Epoch 173/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.3754 - val_loss: 0.1239\n",
            "Epoch 174/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.3750 - val_loss: 0.1237\n",
            "Epoch 175/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.3746 - val_loss: 0.1235\n",
            "Epoch 176/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.3743 - val_loss: 0.1233\n",
            "Epoch 177/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.3739 - val_loss: 0.1231\n",
            "Epoch 178/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.3735 - val_loss: 0.1229\n",
            "Epoch 179/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.3731 - val_loss: 0.1227\n",
            "Epoch 180/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.3727 - val_loss: 0.1225\n",
            "Epoch 181/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3723 - val_loss: 0.1223\n",
            "Epoch 182/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.3719 - val_loss: 0.1221\n",
            "Epoch 183/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3715 - val_loss: 0.1219\n",
            "Epoch 184/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.3712 - val_loss: 0.1216\n",
            "Epoch 185/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3708 - val_loss: 0.1214\n",
            "Epoch 186/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.3704 - val_loss: 0.1212\n",
            "Epoch 187/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3700 - val_loss: 0.1210\n",
            "Epoch 188/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.3696 - val_loss: 0.1208\n",
            "Epoch 189/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3692 - val_loss: 0.1206\n",
            "Epoch 190/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3688 - val_loss: 0.1204\n",
            "Epoch 191/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3684 - val_loss: 0.1202\n",
            "Epoch 192/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3681 - val_loss: 0.1200\n",
            "Epoch 193/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3677 - val_loss: 0.1198\n",
            "Epoch 194/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3673 - val_loss: 0.1196\n",
            "Epoch 195/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3669 - val_loss: 0.1193\n",
            "Epoch 196/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3665 - val_loss: 0.1191\n",
            "Epoch 197/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.3661 - val_loss: 0.1189\n",
            "Epoch 198/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3658 - val_loss: 0.1187\n",
            "Epoch 199/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.3654 - val_loss: 0.1185\n",
            "Epoch 200/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3650 - val_loss: 0.1183\n",
            "Epoch 1/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 191ms/step - loss: 0.4733 - val_loss: 0.2375\n",
            "Epoch 2/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.4694 - val_loss: 0.2434\n",
            "Epoch 3/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.4661 - val_loss: 0.2487\n",
            "Epoch 4/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.4630 - val_loss: 0.2534\n",
            "Epoch 5/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.4602 - val_loss: 0.2572\n",
            "Epoch 6/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.4576 - val_loss: 0.2602\n",
            "Epoch 7/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.4551 - val_loss: 0.2621\n",
            "Epoch 8/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.4528 - val_loss: 0.2631\n",
            "Epoch 9/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.4505 - val_loss: 0.2631\n",
            "Epoch 10/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.4483 - val_loss: 0.2622\n",
            "Epoch 11/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.4461 - val_loss: 0.2605\n",
            "Epoch 12/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.4439 - val_loss: 0.2581\n",
            "Epoch 13/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.4418 - val_loss: 0.2551\n",
            "Epoch 14/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.4397 - val_loss: 0.2518\n",
            "Epoch 15/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.4376 - val_loss: 0.2482\n",
            "Epoch 16/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.4356 - val_loss: 0.2444\n",
            "Epoch 17/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.4336 - val_loss: 0.2407\n",
            "Epoch 18/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.4316 - val_loss: 0.2370\n",
            "Epoch 19/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.4298 - val_loss: 0.2335\n",
            "Epoch 20/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.4279 - val_loss: 0.2301\n",
            "Epoch 21/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.4261 - val_loss: 0.2270\n",
            "Epoch 22/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.4244 - val_loss: 0.2242\n",
            "Epoch 23/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.4227 - val_loss: 0.2215\n",
            "Epoch 24/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.4210 - val_loss: 0.2191\n",
            "Epoch 25/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.4194 - val_loss: 0.2169\n",
            "Epoch 26/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.4178 - val_loss: 0.2148\n",
            "Epoch 27/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.4163 - val_loss: 0.2128\n",
            "Epoch 28/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.4147 - val_loss: 0.2109\n",
            "Epoch 29/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.4133 - val_loss: 0.2091\n",
            "Epoch 30/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.4118 - val_loss: 0.2073\n",
            "Epoch 31/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.4104 - val_loss: 0.2056\n",
            "Epoch 32/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.4091 - val_loss: 0.2038\n",
            "Epoch 33/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.4078 - val_loss: 0.2020\n",
            "Epoch 34/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.4065 - val_loss: 0.2002\n",
            "Epoch 35/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.4053 - val_loss: 0.1984\n",
            "Epoch 36/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.4041 - val_loss: 0.1966\n",
            "Epoch 37/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.4029 - val_loss: 0.1948\n",
            "Epoch 38/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.4018 - val_loss: 0.1930\n",
            "Epoch 39/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.4007 - val_loss: 0.1912\n",
            "Epoch 40/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.3997 - val_loss: 0.1895\n",
            "Epoch 41/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.3987 - val_loss: 0.1879\n",
            "Epoch 42/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.3977 - val_loss: 0.1863\n",
            "Epoch 43/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.3968 - val_loss: 0.1847\n",
            "Epoch 44/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.3959 - val_loss: 0.1832\n",
            "Epoch 45/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.3950 - val_loss: 0.1818\n",
            "Epoch 46/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.3942 - val_loss: 0.1804\n",
            "Epoch 47/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.3934 - val_loss: 0.1790\n",
            "Epoch 48/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.3926 - val_loss: 0.1777\n",
            "Epoch 49/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.3919 - val_loss: 0.1764\n",
            "Epoch 50/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.3912 - val_loss: 0.1752\n",
            "Epoch 51/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.3905 - val_loss: 0.1740\n",
            "Epoch 52/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3899 - val_loss: 0.1729\n",
            "Epoch 53/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.3893 - val_loss: 0.1718\n",
            "Epoch 54/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.3887 - val_loss: 0.1707\n",
            "Epoch 55/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.3881 - val_loss: 0.1696\n",
            "Epoch 56/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3876 - val_loss: 0.1686\n",
            "Epoch 57/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3871 - val_loss: 0.1676\n",
            "Epoch 58/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3866 - val_loss: 0.1666\n",
            "Epoch 59/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.3861 - val_loss: 0.1657\n",
            "Epoch 60/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3857 - val_loss: 0.1648\n",
            "Epoch 61/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.3853 - val_loss: 0.1639\n",
            "Epoch 62/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.3849 - val_loss: 0.1630\n",
            "Epoch 63/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3845 - val_loss: 0.1622\n",
            "Epoch 64/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.3842 - val_loss: 0.1614\n",
            "Epoch 65/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.3838 - val_loss: 0.1606\n",
            "Epoch 66/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3835 - val_loss: 0.1599\n",
            "Epoch 67/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.3832 - val_loss: 0.1592\n",
            "Epoch 68/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.3830 - val_loss: 0.1585\n",
            "Epoch 69/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.3827 - val_loss: 0.1578\n",
            "Epoch 70/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3825 - val_loss: 0.1572\n",
            "Epoch 71/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3822 - val_loss: 0.1566\n",
            "Epoch 72/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.3820 - val_loss: 0.1560\n",
            "Epoch 73/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.3818 - val_loss: 0.1554\n",
            "Epoch 74/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3817 - val_loss: 0.1549\n",
            "Epoch 75/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3815 - val_loss: 0.1543\n",
            "Epoch 76/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3814 - val_loss: 0.1538\n",
            "Epoch 77/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3812 - val_loss: 0.1533\n",
            "Epoch 78/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.3811 - val_loss: 0.1529\n",
            "Epoch 79/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.3810 - val_loss: 0.1524\n",
            "Epoch 80/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.3809 - val_loss: 0.1520\n",
            "Epoch 81/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3808 - val_loss: 0.1516\n",
            "Epoch 82/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.3807 - val_loss: 0.1512\n",
            "Epoch 83/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.3806 - val_loss: 0.1508\n",
            "Epoch 84/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.3806 - val_loss: 0.1504\n",
            "Epoch 85/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.3805 - val_loss: 0.1501\n",
            "Epoch 86/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3804 - val_loss: 0.1497\n",
            "Epoch 87/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3804 - val_loss: 0.1494\n",
            "Epoch 88/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3804 - val_loss: 0.1491\n",
            "Epoch 89/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.3803 - val_loss: 0.1488\n",
            "Epoch 90/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.3803 - val_loss: 0.1485\n",
            "Epoch 91/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.3803 - val_loss: 0.1483\n",
            "Epoch 92/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.3803 - val_loss: 0.1480\n",
            "Epoch 93/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.3803 - val_loss: 0.1478\n",
            "Epoch 94/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.3803 - val_loss: 0.1475\n",
            "Epoch 95/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.3803 - val_loss: 0.1473\n",
            "Epoch 96/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3803 - val_loss: 0.1471\n",
            "Epoch 97/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.3803 - val_loss: 0.1469\n",
            "Epoch 98/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3804 - val_loss: 0.1467\n",
            "Epoch 99/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3804 - val_loss: 0.1465\n",
            "Epoch 100/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.3804 - val_loss: 0.1464\n",
            "Epoch 101/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3804 - val_loss: 0.1462\n",
            "Epoch 102/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3805 - val_loss: 0.1460\n",
            "Epoch 103/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3805 - val_loss: 0.1459\n",
            "Epoch 104/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3805 - val_loss: 0.1458\n",
            "Epoch 105/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.3806 - val_loss: 0.1456\n",
            "Epoch 106/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3806 - val_loss: 0.1455\n",
            "Epoch 107/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3807 - val_loss: 0.1454\n",
            "Epoch 108/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3807 - val_loss: 0.1453\n",
            "Epoch 109/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.3808 - val_loss: 0.1452\n",
            "Epoch 110/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3808 - val_loss: 0.1451\n",
            "Epoch 111/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.3808 - val_loss: 0.1450\n",
            "Epoch 112/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.3809 - val_loss: 0.1449\n",
            "Epoch 113/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.3809 - val_loss: 0.1448\n",
            "Epoch 114/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.3810 - val_loss: 0.1448\n",
            "Epoch 115/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.3810 - val_loss: 0.1447\n",
            "Epoch 116/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3811 - val_loss: 0.1446\n",
            "Epoch 117/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.3812 - val_loss: 0.1446\n",
            "Epoch 118/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.3812 - val_loss: 0.1445\n",
            "Epoch 119/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.3813 - val_loss: 0.1445\n",
            "Epoch 120/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.3813 - val_loss: 0.1444\n",
            "Epoch 121/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.3814 - val_loss: 0.1444\n",
            "Epoch 122/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.3814 - val_loss: 0.1443\n",
            "Epoch 123/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.3815 - val_loss: 0.1443\n",
            "Epoch 124/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.3815 - val_loss: 0.1443\n",
            "Epoch 125/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3816 - val_loss: 0.1443\n",
            "Epoch 126/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3816 - val_loss: 0.1442\n",
            "Epoch 127/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3817 - val_loss: 0.1442\n",
            "Epoch 128/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.3817 - val_loss: 0.1442\n",
            "Epoch 129/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.3818 - val_loss: 0.1442\n",
            "Epoch 130/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.3818 - val_loss: 0.1442\n",
            "Epoch 131/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.3819 - val_loss: 0.1442\n",
            "Epoch 132/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.3819 - val_loss: 0.1441\n",
            "Epoch 133/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.3820 - val_loss: 0.1441\n",
            "Epoch 134/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.3820 - val_loss: 0.1441\n",
            "Epoch 135/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.3821 - val_loss: 0.1441\n",
            "Epoch 136/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.3821 - val_loss: 0.1441\n",
            "Epoch 137/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.3822 - val_loss: 0.1441\n",
            "Epoch 138/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.3822 - val_loss: 0.1442\n",
            "Epoch 139/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 0.3823 - val_loss: 0.1442\n",
            "Epoch 140/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.3823 - val_loss: 0.1442\n",
            "Epoch 141/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3823 - val_loss: 0.1442\n",
            "Epoch 142/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.3824 - val_loss: 0.1442\n",
            "Epoch 143/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 380ms/step - loss: 0.3824 - val_loss: 0.1442\n",
            "Epoch 144/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.3825 - val_loss: 0.1442\n",
            "Epoch 145/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3825 - val_loss: 0.1442\n",
            "Epoch 146/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.3825 - val_loss: 0.1443\n",
            "Epoch 147/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.3826 - val_loss: 0.1443\n",
            "Epoch 148/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3826 - val_loss: 0.1443\n",
            "Epoch 149/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.3826 - val_loss: 0.1443\n",
            "Epoch 150/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.3827 - val_loss: 0.1443\n",
            "Epoch 151/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.3827 - val_loss: 0.1443\n",
            "Epoch 152/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.3827 - val_loss: 0.1444\n",
            "Epoch 153/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.3828 - val_loss: 0.1444\n",
            "Epoch 154/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.3828 - val_loss: 0.1444\n",
            "Epoch 155/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.3828 - val_loss: 0.1444\n",
            "Epoch 156/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.3829 - val_loss: 0.1445\n",
            "Epoch 157/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.3829 - val_loss: 0.1445\n",
            "Epoch 158/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3829 - val_loss: 0.1445\n",
            "Epoch 159/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.3829 - val_loss: 0.1445\n",
            "Epoch 160/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.3830 - val_loss: 0.1446\n",
            "Epoch 161/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3830 - val_loss: 0.1446\n",
            "Epoch 162/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3830 - val_loss: 0.1446\n",
            "Epoch 163/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.3830 - val_loss: 0.1447\n",
            "Epoch 164/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.3830 - val_loss: 0.1447\n",
            "Epoch 165/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.3831 - val_loss: 0.1447\n",
            "Epoch 166/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.3831 - val_loss: 0.1447\n",
            "Epoch 167/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.3831 - val_loss: 0.1448\n",
            "Epoch 168/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.3831 - val_loss: 0.1448\n",
            "Epoch 169/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3831 - val_loss: 0.1448\n",
            "Epoch 170/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3831 - val_loss: 0.1448\n",
            "Epoch 171/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3832 - val_loss: 0.1449\n",
            "Epoch 172/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.3832 - val_loss: 0.1449\n",
            "Epoch 173/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.3832 - val_loss: 0.1449\n",
            "Epoch 174/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3832 - val_loss: 0.1450\n",
            "Epoch 175/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.3832 - val_loss: 0.1450\n",
            "Epoch 176/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3832 - val_loss: 0.1450\n",
            "Epoch 177/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.3832 - val_loss: 0.1450\n",
            "Epoch 178/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3832 - val_loss: 0.1451\n",
            "Epoch 179/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3832 - val_loss: 0.1451\n",
            "Epoch 180/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.3832 - val_loss: 0.1451\n",
            "Epoch 181/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.3832 - val_loss: 0.1452\n",
            "Epoch 182/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3832 - val_loss: 0.1452\n",
            "Epoch 183/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.3833 - val_loss: 0.1452\n",
            "Epoch 184/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.3833 - val_loss: 0.1452\n",
            "Epoch 185/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.3833 - val_loss: 0.1453\n",
            "Epoch 186/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.3833 - val_loss: 0.1453\n",
            "Epoch 187/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3833 - val_loss: 0.1453\n",
            "Epoch 188/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.3833 - val_loss: 0.1453\n",
            "Epoch 189/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3833 - val_loss: 0.1454\n",
            "Epoch 190/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.3833 - val_loss: 0.1454\n",
            "Epoch 191/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3833 - val_loss: 0.1454\n",
            "Epoch 192/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3833 - val_loss: 0.1454\n",
            "Epoch 193/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.3833 - val_loss: 0.1455\n",
            "Epoch 194/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3832 - val_loss: 0.1455\n",
            "Epoch 195/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.3832 - val_loss: 0.1455\n",
            "Epoch 196/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.3832 - val_loss: 0.1455\n",
            "Epoch 197/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.3832 - val_loss: 0.1456\n",
            "Epoch 198/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.3832 - val_loss: 0.1456\n",
            "Epoch 199/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.3832 - val_loss: 0.1456\n",
            "Epoch 200/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3832 - val_loss: 0.1456\n",
            "Epoch 1/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 199ms/step - loss: 0.6699 - val_loss: 0.1733\n",
            "Epoch 2/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.6611 - val_loss: 0.1778\n",
            "Epoch 3/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.6529 - val_loss: 0.1822\n",
            "Epoch 4/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.6447 - val_loss: 0.1864\n",
            "Epoch 5/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.6365 - val_loss: 0.1906\n",
            "Epoch 6/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.6285 - val_loss: 0.1946\n",
            "Epoch 7/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.6204 - val_loss: 0.1986\n",
            "Epoch 8/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.6125 - val_loss: 0.2023\n",
            "Epoch 9/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.6047 - val_loss: 0.2058\n",
            "Epoch 10/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.5969 - val_loss: 0.2089\n",
            "Epoch 11/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.5893 - val_loss: 0.2118\n",
            "Epoch 12/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.5819 - val_loss: 0.2142\n",
            "Epoch 13/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.5747 - val_loss: 0.2161\n",
            "Epoch 14/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.5676 - val_loss: 0.2175\n",
            "Epoch 15/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.5607 - val_loss: 0.2184\n",
            "Epoch 16/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.5539 - val_loss: 0.2186\n",
            "Epoch 17/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.5474 - val_loss: 0.2182\n",
            "Epoch 18/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.5411 - val_loss: 0.2171\n",
            "Epoch 19/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.5349 - val_loss: 0.2153\n",
            "Epoch 20/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.5289 - val_loss: 0.2130\n",
            "Epoch 21/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.5230 - val_loss: 0.2101\n",
            "Epoch 22/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.5173 - val_loss: 0.2066\n",
            "Epoch 23/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.5117 - val_loss: 0.2027\n",
            "Epoch 24/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.5063 - val_loss: 0.1985\n",
            "Epoch 25/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.5010 - val_loss: 0.1940\n",
            "Epoch 26/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.4959 - val_loss: 0.1893\n",
            "Epoch 27/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.4909 - val_loss: 0.1846\n",
            "Epoch 28/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.4861 - val_loss: 0.1799\n",
            "Epoch 29/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.4815 - val_loss: 0.1753\n",
            "Epoch 30/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.4770 - val_loss: 0.1709\n",
            "Epoch 31/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.4727 - val_loss: 0.1667\n",
            "Epoch 32/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.4686 - val_loss: 0.1628\n",
            "Epoch 33/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.4647 - val_loss: 0.1592\n",
            "Epoch 34/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.4609 - val_loss: 0.1558\n",
            "Epoch 35/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.4573 - val_loss: 0.1528\n",
            "Epoch 36/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.4539 - val_loss: 0.1500\n",
            "Epoch 37/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.4506 - val_loss: 0.1476\n",
            "Epoch 38/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.4475 - val_loss: 0.1454\n",
            "Epoch 39/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.4446 - val_loss: 0.1434\n",
            "Epoch 40/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.4418 - val_loss: 0.1417\n",
            "Epoch 41/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.4392 - val_loss: 0.1401\n",
            "Epoch 42/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.4366 - val_loss: 0.1388\n",
            "Epoch 43/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.4342 - val_loss: 0.1376\n",
            "Epoch 44/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.4320 - val_loss: 0.1365\n",
            "Epoch 45/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.4298 - val_loss: 0.1356\n",
            "Epoch 46/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.4278 - val_loss: 0.1347\n",
            "Epoch 47/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.4259 - val_loss: 0.1340\n",
            "Epoch 48/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.4240 - val_loss: 0.1333\n",
            "Epoch 49/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.4223 - val_loss: 0.1327\n",
            "Epoch 50/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.4207 - val_loss: 0.1322\n",
            "Epoch 51/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.4191 - val_loss: 0.1317\n",
            "Epoch 52/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.4177 - val_loss: 0.1313\n",
            "Epoch 53/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.4163 - val_loss: 0.1310\n",
            "Epoch 54/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.4149 - val_loss: 0.1307\n",
            "Epoch 55/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.4137 - val_loss: 0.1305\n",
            "Epoch 56/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.4125 - val_loss: 0.1303\n",
            "Epoch 57/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.4113 - val_loss: 0.1302\n",
            "Epoch 58/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.4103 - val_loss: 0.1301\n",
            "Epoch 59/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.4092 - val_loss: 0.1301\n",
            "Epoch 60/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.4082 - val_loss: 0.1301\n",
            "Epoch 61/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.4073 - val_loss: 0.1301\n",
            "Epoch 62/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.4063 - val_loss: 0.1302\n",
            "Epoch 63/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.4055 - val_loss: 0.1303\n",
            "Epoch 64/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.4046 - val_loss: 0.1304\n",
            "Epoch 65/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.4038 - val_loss: 0.1306\n",
            "Epoch 66/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.4030 - val_loss: 0.1308\n",
            "Epoch 67/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.4022 - val_loss: 0.1310\n",
            "Epoch 68/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.4015 - val_loss: 0.1313\n",
            "Epoch 69/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.4007 - val_loss: 0.1315\n",
            "Epoch 70/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.4000 - val_loss: 0.1318\n",
            "Epoch 71/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3993 - val_loss: 0.1321\n",
            "Epoch 72/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3987 - val_loss: 0.1324\n",
            "Epoch 73/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.3980 - val_loss: 0.1327\n",
            "Epoch 74/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3974 - val_loss: 0.1330\n",
            "Epoch 75/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.3968 - val_loss: 0.1334\n",
            "Epoch 76/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.3962 - val_loss: 0.1337\n",
            "Epoch 77/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.3956 - val_loss: 0.1341\n",
            "Epoch 78/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.3950 - val_loss: 0.1344\n",
            "Epoch 79/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3945 - val_loss: 0.1348\n",
            "Epoch 80/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.3939 - val_loss: 0.1351\n",
            "Epoch 81/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3934 - val_loss: 0.1355\n",
            "Epoch 82/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.3929 - val_loss: 0.1359\n",
            "Epoch 83/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.3923 - val_loss: 0.1363\n",
            "Epoch 84/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3918 - val_loss: 0.1366\n",
            "Epoch 85/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3914 - val_loss: 0.1370\n",
            "Epoch 86/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.3909 - val_loss: 0.1374\n",
            "Epoch 87/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.3904 - val_loss: 0.1378\n",
            "Epoch 88/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.3900 - val_loss: 0.1382\n",
            "Epoch 89/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3895 - val_loss: 0.1386\n",
            "Epoch 90/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.3891 - val_loss: 0.1390\n",
            "Epoch 91/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 0.3886 - val_loss: 0.1393\n",
            "Epoch 92/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.3882 - val_loss: 0.1397\n",
            "Epoch 93/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.3878 - val_loss: 0.1401\n",
            "Epoch 94/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.3874 - val_loss: 0.1405\n",
            "Epoch 95/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.3870 - val_loss: 0.1409\n",
            "Epoch 96/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 0.3866 - val_loss: 0.1413\n",
            "Epoch 97/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.3863 - val_loss: 0.1416\n",
            "Epoch 98/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 0.3859 - val_loss: 0.1420\n",
            "Epoch 99/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3855 - val_loss: 0.1424\n",
            "Epoch 100/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3852 - val_loss: 0.1427\n",
            "Epoch 101/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.3848 - val_loss: 0.1431\n",
            "Epoch 102/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.3845 - val_loss: 0.1435\n",
            "Epoch 103/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.3841 - val_loss: 0.1438\n",
            "Epoch 104/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3838 - val_loss: 0.1442\n",
            "Epoch 105/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.3835 - val_loss: 0.1445\n",
            "Epoch 106/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.3832 - val_loss: 0.1448\n",
            "Epoch 107/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.3829 - val_loss: 0.1452\n",
            "Epoch 108/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.3826 - val_loss: 0.1455\n",
            "Epoch 109/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.3823 - val_loss: 0.1458\n",
            "Epoch 110/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3820 - val_loss: 0.1461\n",
            "Epoch 111/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.3817 - val_loss: 0.1464\n",
            "Epoch 112/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.3814 - val_loss: 0.1467\n",
            "Epoch 113/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.3811 - val_loss: 0.1470\n",
            "Epoch 114/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3809 - val_loss: 0.1473\n",
            "Epoch 115/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.3806 - val_loss: 0.1476\n",
            "Epoch 116/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3803 - val_loss: 0.1479\n",
            "Epoch 117/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.3801 - val_loss: 0.1482\n",
            "Epoch 118/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3798 - val_loss: 0.1484\n",
            "Epoch 119/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3796 - val_loss: 0.1487\n",
            "Epoch 120/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.3794 - val_loss: 0.1490\n",
            "Epoch 121/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.3791 - val_loss: 0.1492\n",
            "Epoch 122/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3789 - val_loss: 0.1495\n",
            "Epoch 123/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.3787 - val_loss: 0.1497\n",
            "Epoch 124/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.3784 - val_loss: 0.1499\n",
            "Epoch 125/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.3782 - val_loss: 0.1502\n",
            "Epoch 126/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.3780 - val_loss: 0.1504\n",
            "Epoch 127/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.3778 - val_loss: 0.1506\n",
            "Epoch 128/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.3776 - val_loss: 0.1508\n",
            "Epoch 129/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.3774 - val_loss: 0.1510\n",
            "Epoch 130/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.3772 - val_loss: 0.1512\n",
            "Epoch 131/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.3770 - val_loss: 0.1514\n",
            "Epoch 132/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.3768 - val_loss: 0.1516\n",
            "Epoch 133/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.3766 - val_loss: 0.1518\n",
            "Epoch 134/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3764 - val_loss: 0.1519\n",
            "Epoch 135/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.3762 - val_loss: 0.1521\n",
            "Epoch 136/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.3761 - val_loss: 0.1523\n",
            "Epoch 137/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3759 - val_loss: 0.1524\n",
            "Epoch 138/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3757 - val_loss: 0.1526\n",
            "Epoch 139/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.3755 - val_loss: 0.1527\n",
            "Epoch 140/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.3754 - val_loss: 0.1528\n",
            "Epoch 141/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.3752 - val_loss: 0.1530\n",
            "Epoch 142/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3750 - val_loss: 0.1531\n",
            "Epoch 143/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3749 - val_loss: 0.1532\n",
            "Epoch 144/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.3747 - val_loss: 0.1533\n",
            "Epoch 145/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.3746 - val_loss: 0.1534\n",
            "Epoch 146/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3744 - val_loss: 0.1535\n",
            "Epoch 147/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3742 - val_loss: 0.1536\n",
            "Epoch 148/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.3741 - val_loss: 0.1537\n",
            "Epoch 149/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.3739 - val_loss: 0.1538\n",
            "Epoch 150/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.3738 - val_loss: 0.1539\n",
            "Epoch 151/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.3737 - val_loss: 0.1540\n",
            "Epoch 152/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.3735 - val_loss: 0.1541\n",
            "Epoch 153/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3734 - val_loss: 0.1542\n",
            "Epoch 154/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.3732 - val_loss: 0.1542\n",
            "Epoch 155/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3731 - val_loss: 0.1543\n",
            "Epoch 156/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.3730 - val_loss: 0.1543\n",
            "Epoch 157/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.3728 - val_loss: 0.1544\n",
            "Epoch 158/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.3727 - val_loss: 0.1544\n",
            "Epoch 159/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.3726 - val_loss: 0.1545\n",
            "Epoch 160/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.3724 - val_loss: 0.1545\n",
            "Epoch 161/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.3723 - val_loss: 0.1546\n",
            "Epoch 162/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.3722 - val_loss: 0.1546\n",
            "Epoch 163/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.3720 - val_loss: 0.1546\n",
            "Epoch 164/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.3719 - val_loss: 0.1547\n",
            "Epoch 165/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3718 - val_loss: 0.1547\n",
            "Epoch 166/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.3717 - val_loss: 0.1547\n",
            "Epoch 167/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.3716 - val_loss: 0.1547\n",
            "Epoch 168/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.3714 - val_loss: 0.1547\n",
            "Epoch 169/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.3713 - val_loss: 0.1548\n",
            "Epoch 170/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3712 - val_loss: 0.1548\n",
            "Epoch 171/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.3711 - val_loss: 0.1548\n",
            "Epoch 172/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.3710 - val_loss: 0.1548\n",
            "Epoch 173/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3709 - val_loss: 0.1548\n",
            "Epoch 174/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.3707 - val_loss: 0.1548\n",
            "Epoch 175/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.3706 - val_loss: 0.1548\n",
            "Epoch 176/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.3705 - val_loss: 0.1547\n",
            "Epoch 177/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.3704 - val_loss: 0.1547\n",
            "Epoch 178/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.3703 - val_loss: 0.1547\n",
            "Epoch 179/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.3702 - val_loss: 0.1547\n",
            "Epoch 180/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - loss: 0.3701 - val_loss: 0.1547\n",
            "Epoch 181/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.3700 - val_loss: 0.1547\n",
            "Epoch 182/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 0.3699 - val_loss: 0.1546\n",
            "Epoch 183/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 0.3698 - val_loss: 0.1546\n",
            "Epoch 184/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.3697 - val_loss: 0.1546\n",
            "Epoch 185/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 0.3696 - val_loss: 0.1545\n",
            "Epoch 186/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.3695 - val_loss: 0.1545\n",
            "Epoch 187/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 0.3694 - val_loss: 0.1545\n",
            "Epoch 188/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.3692 - val_loss: 0.1544\n",
            "Epoch 189/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.3691 - val_loss: 0.1544\n",
            "Epoch 190/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.3690 - val_loss: 0.1543\n",
            "Epoch 191/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.3689 - val_loss: 0.1543\n",
            "Epoch 192/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.3688 - val_loss: 0.1543\n",
            "Epoch 193/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.3687 - val_loss: 0.1542\n",
            "Epoch 194/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.3687 - val_loss: 0.1542\n",
            "Epoch 195/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.3686 - val_loss: 0.1541\n",
            "Epoch 196/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3685 - val_loss: 0.1541\n",
            "Epoch 197/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.3684 - val_loss: 0.1540\n",
            "Epoch 198/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3683 - val_loss: 0.1539\n",
            "Epoch 199/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.3682 - val_loss: 0.1539\n",
            "Epoch 200/200\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.3681 - val_loss: 0.1538\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_val_pred_real  = inv_y(model.predict(X_val_z,  verbose=0))\n",
        "y_test_pred_real = inv_y(model.predict(X_test_z, verbose=0))\n",
        "\n",
        "val_mse_real.append(mean_squared_error(y_val,  y_val_pred_real))\n",
        "test_mse_real.append(mean_squared_error(y_test, y_test_pred_real))\n"
      ],
      "metadata": {
        "id": "1S20YMKiowLv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "transfer_functions = {\n",
        "    'relu': 'ReLU',\n",
        "    'tanh': 'Tanh',\n",
        "    'sigmoid': 'Sigmoid',\n",
        "    'softplus': 'Softplus'\n",
        "}\n",
        "\n",
        "mse_results = []\n",
        "\n",
        "for activation, name in transfer_functions.items():\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=(X_train.shape[1],)))\n",
        "    model.add(Dense(16, activation=activation))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(1, activation='tanh'))\n",
        "    model.compile(optimizer='adam', loss='mse', metrics=['mae', 'mape'])\n",
        "    model.fit(X_train, y_train, batch_size=4, epochs=50, verbose=0)\n",
        "    y_pred = model.predict(X_test)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    mse_results.append(mse)\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(list(transfer_functions.values()), mse_results, marker='o', linestyle='-', color='blue')\n",
        "plt.title('Mean MSE of Mw vs Transfer Function')\n",
        "plt.xlabel('Transfer Function')\n",
        "plt.ylabel('Mean Squared Error')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        },
        "id": "q6gl3rnYqlGv",
        "outputId": "c2abad4a-29e1-473c-af14-03577ef5975e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = y.ravel()\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import KFold, cross_val_predict\n",
        "\n",
        "pipe = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"lr\", LinearRegression())\n",
        "])\n",
        "\n",
        "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "y_pred = cross_val_predict(pipe, X, y, cv=cv)"
      ],
      "metadata": {
        "id": "1GcDKbtxQtBf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import PredictionErrorDisplay\n",
        "\n",
        "fig, axs = plt.subplots(ncols=2, figsize=(8, 4))\n",
        "\n",
        "# نمودار Actual vs Predicted\n",
        "PredictionErrorDisplay.from_predictions(\n",
        "    y_true=y,\n",
        "    y_pred=y_pred,\n",
        "    kind=\"actual_vs_predicted\",\n",
        "    subsample=None,          # ← تغییر نسبت به 25\n",
        "    ax=axs[0],\n",
        "    random_state=42,\n",
        ")\n",
        "axs[0].set_title(\"Actual vs. Predicted values\")\n",
        "\n",
        "# نمودار Residual vs Predicted\n",
        "PredictionErrorDisplay.from_predictions(\n",
        "    y_true=y,\n",
        "    y_pred=y_pred,\n",
        "    kind=\"residual_vs_predicted\",\n",
        "    subsample=None,          # ← تغییر نسبت به 25\n",
        "    ax=axs[1],\n",
        "    random_state=42,\n",
        ")\n",
        "axs[1].set_title(\"Residuals vs. Predicted Values\")\n",
        "\n",
        "fig.suptitle(\"Cross-validated predictions (OOF)\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Sc0aC1gjQ1jT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "outputId": "8ec727ad-999b-4e46-eb1f-043cc9fc9840"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "from sklearn.metrics import (\n",
        "    r2_score, mean_absolute_percentage_error, mean_squared_error,\n",
        "    mean_squared_log_error, explained_variance_score, max_error,\n",
        "    median_absolute_error\n",
        ")"
      ],
      "metadata": {
        "id": "lSdoqlpABM_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"Python.csv\", engine=\"python\", sep=r\";\")\n",
        "df.columns = (df.columns\n",
        "              .str.replace('\\ufeff', '', regex=False)   # حذف BOM\n",
        "              .str.strip()\n",
        "              .str.replace(r'\\s+', ' ', regex=True))    # یکی‌کردن فاصله‌ها\n",
        "\n",
        "print(\"ستون‌های موجود:\", list(df.columns))  # کمک برای چک کردن\n",
        "\n",
        "# 2) نگاشتِ نام‌ها به‌صورت Case-Insensitive (بی‌حساسیت به بزرگی/کوچکی حروف)\n",
        "def pick_cols(df, names):\n",
        "    lookup = {c.casefold(): c for c in df.columns}\n",
        "    missing = [n for n in names if n.casefold() not in lookup]\n",
        "    if missing:\n",
        "        raise KeyError(f\"ستون‌های پیدا نشدند: {missing}\\nموجود: {list(df.columns)}\")\n",
        "    return [lookup[n.casefold()] for n in names]\n",
        "\n",
        "FEATURES_REQ = ['factor A', 'factor B', 'factor C', 'factor D']\n",
        "TARGETS_REQ  = ['Response 1 (Mn)', 'Response 2 (Mw)']\n",
        "\n",
        "FEATURES = pick_cols(df, FEATURES_REQ)\n",
        "TARGETS  = pick_cols(df, TARGETS_REQ)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfh8uAOpBRx8",
        "outputId": "33b53f88-bd4d-4807-e662-36c202916bbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ستون‌های موجود: ['factor A', 'factor B', 'factor C', 'factor D', 'Response 1 (Mn)', 'Response 2 (Mw)']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df[FEATURES].to_numpy(dtype=float)\n",
        "Y = df[TARGETS].to_numpy(dtype=float)\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(\n",
        "    X, Y, test_size=0.2, random_state=42, shuffle=True\n",
        ")\n",
        "\n",
        "X_trval, X_test, Y_trval, Y_test = train_test_split(\n",
        "    X, Y, test_size=5, random_state=42, shuffle=True\n",
        ")\n",
        "\n",
        "n_samples = X.shape[0]\n",
        "\n",
        "print(f\"Training set: {X_train.shape[0]} samples\")\n",
        "print(f\"Validation set: {X_trval.shape[0]} samples\")\n",
        "print(f\"Test set: {X_test.shape[0]} samples\")\n",
        "print(f\"Total: {n_samples} samples\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zi8cqqx5Cx3H",
        "outputId": "38f85a31-de20-44b4-d5d4-aa1cf7a82d5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set: 20 samples\n",
            "Validation set: 20 samples\n",
            "Test set: 5 samples\n",
            "Total: 25 samples\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for col in FEATURES + TARGETS:\n",
        "    df[col] = pd.to_numeric(df[col].astype(str).str.replace(',', '.').str.strip(),\n",
        "                            errors='coerce')\n",
        "\n",
        "# 4) ساخت X و Y\n",
        "X = df[FEATURES].to_numpy(dtype=float)\n",
        "Y = df[TARGETS].to_numpy(dtype=float)\n",
        "\n",
        "print(\"X shape:\", X.shape, \"Y shape:\", Y.shape)\n",
        "n_samples = X.shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPRNstwkDhbW",
        "outputId": "df2f32ad-f685-46eb-9a20-99b18e79fd93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape: (25, 4) Y shape: (25, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_svr = make_pipeline(StandardScaler(),SVR(kernel='poly', C=1 , epsilon= 0.1, gamma='scale')\n",
        ")\n",
        "model = MultiOutputRegressor(base_svr)\n",
        "model.fit(X_train, Y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "twyeH5O4Dotf",
        "outputId": "ca34a8e1-1fc0-4b30-d156-bdfae9faad59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultiOutputRegressor(estimator=Pipeline(steps=[('standardscaler',\n",
              "                                                StandardScaler()),\n",
              "                                               ('svr',\n",
              "                                                SVR(C=1, kernel='poly'))]))"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultiOutputRegressor(estimator=Pipeline(steps=[(&#x27;standardscaler&#x27;,\n",
              "                                                StandardScaler()),\n",
              "                                               (&#x27;svr&#x27;,\n",
              "                                                SVR(C=1, kernel=&#x27;poly&#x27;))]))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>MultiOutputRegressor</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.multioutput.MultiOutputRegressor.html\">?<span>Documentation for MultiOutputRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>MultiOutputRegressor(estimator=Pipeline(steps=[(&#x27;standardscaler&#x27;,\n",
              "                                                StandardScaler()),\n",
              "                                               (&#x27;svr&#x27;,\n",
              "                                                SVR(C=1, kernel=&#x27;poly&#x27;))]))</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>estimator: Pipeline</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
              "                (&#x27;svr&#x27;, SVR(C=1, kernel=&#x27;poly&#x27;))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>StandardScaler</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>StandardScaler()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>SVR</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.svm.SVR.html\">?<span>Documentation for SVR</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>SVR(C=1, kernel=&#x27;poly&#x27;)</pre></div> </div></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, Y_train)\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
        "Y_pred = model.predict(X_test)\n",
        "print(\"Test predictions shape:\", Y_pred.shape)\n",
        "def overall_metrics(y_true, y_pred):\n",
        "    r2   = r2_score(y_true, y_pred, multioutput='uniform_average')\n",
        "    evs  = explained_variance_score(y_true, y_pred, multioutput='uniform_average')\n",
        "    mape = mean_absolute_percentage_error(y_true, y_pred, multioutput='uniform_average')\n",
        "    mse  = mean_squared_error(y_true, y_pred, multioutput='uniform_average')\n",
        "    try:\n",
        "        msle = mean_squared_log_error(y_true, y_pred, multioutput='uniform_average')\n",
        "    except ValueError:\n",
        "        msle = np.nan\n",
        "    # Median AE را دستی روی هر خروجی بگیریم و میانگین کنیم\n",
        "    mae_med = np.mean([median_absolute_error(y_true[:,i], y_pred[:,i]) for i in range(y_true.shape[1])])\n",
        "    # Max Error را روی کل عناصر محاسبه کنیم\n",
        "    maxerr = np.max(np.abs(y_true - y_pred))\n",
        "    return evs, maxerr, mape, mse, msle, mae_med, r2\n",
        "evs, maxerr, mape, mse, msle, mae_med, r2 = overall_metrics(Y_test, Y_pred)\n",
        "print(\"SVM Results:\")\n",
        "print(f\"Explained Variance: {evs:.6f}\")\n",
        "print(f\"Max Error: {maxerr:.6f}\")\n",
        "print(f\"MAPE: {mape:.6f}\")\n",
        "print(f\"MSE: {mse:.6f}\")\n",
        "print(f\"MSLE: {msle:.6f}\")\n",
        "print(f\"Median AE: {mae_med:.6f}\")\n",
        "print(f\"R²: {r2:.6f}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YraoHVwDw4J",
        "outputId": "4421057f-cdb6-428d-bb47-5043acbf706b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test predictions shape: (5, 2)\n",
            "SVM Results:\n",
            "Explained Variance: 0.371681\n",
            "Max Error: 0.093440\n",
            "MAPE: 0.000045\n",
            "MSE: 0.003752\n",
            "MSLE: 0.000000\n",
            "Median AE: 0.050647\n",
            "R²: 0.368801\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.DataFrame({\n",
        "    \"Actual_Mn\":     Y_test[:,0],\n",
        "    \"Actual_Mw\":     Y_test[:,1],\n",
        "    \"Predicted_Mn\":  Y_pred[:,0],\n",
        "    \"Predicted_Mw\":  Y_pred[:,1],\n",
        "})\n",
        "print(\"Actual vs Predicted Comparison (Test):\")\n",
        "print(test_df.to_string(index=False))\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEO-A2hxD4Gn",
        "outputId": "48511749-a2ba-4458-d9eb-385ee112c9e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual vs Predicted Comparison (Test):\n",
            " Actual_Mn  Actual_Mw  Predicted_Mn  Predicted_Mw\n",
            "   1127.27    1321.73   1127.320647   1321.780647\n",
            "   1127.35    1321.81   1127.317766   1321.777766\n",
            "   1127.19    1321.65   1127.268218   1321.728218\n",
            "   1127.42    1321.88   1127.326560   1321.786560\n",
            "   1127.30    1321.76   1127.317493   1321.777493\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "r2_list, mse_list, mape_list = [], [], []\n",
        "\n",
        "for tr_idx, va_idx in kf.split(X):\n",
        "    X_tr, X_va = X[tr_idx], X[va_idx]\n",
        "    Y_tr, Y_va = Y[tr_idx], Y[va_idx]\n",
        "    m = MultiOutputRegressor(make_pipeline(StandardScaler(), SVR(kernel='poly', C=1, epsilon=0.1, gamma='scale')))\n",
        "    m.fit(X_tr, Y_tr)\n",
        "    Y_va_pred = m.predict(X_va)\n",
        "    r2_list.append(r2_score(Y_va, Y_va_pred, multioutput='uniform_average'))\n",
        "    mse_list.append(mean_squared_error(Y_va, Y_va_pred, multioutput='uniform_average'))\n",
        "    mape_list.append(mean_absolute_percentage_error(Y_va, Y_va_pred, multioutput='uniform_average'))\n",
        "\n",
        "r2_arr   = np.array(r2_list)\n",
        "mse_arr  = np.array(mse_list)\n",
        "mape_arr = np.array(mape_list)\n",
        "\n",
        "print(\"\\n5-FOLD CROSS VALIDATION RESULTS\")\n",
        "print(\"============================================================\")\n",
        "print(f\"R² Mean: {r2_arr.mean():.4f} (±{r2_arr.std():.4f})\")\n",
        "print(f\"MSE Mean: {mse_arr.mean():.4f} (±{mse_arr.std():.4f})\")\n",
        "print(f\"MAPE Mean: {mape_arr.mean():.4f} (±{mape_arr.std():.4f})\\n\")\n",
        "\n",
        "print(\"Individual R² scores:\", np.array2string(r2_arr, precision=4))\n",
        "print(\"Individual MSE scores:\", np.array2string(mse_arr, precision=4))\n",
        "print(\"Individual MAPE scores:\", np.array2string(mape_arr, precision=4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9ZqWuSLEAg5",
        "outputId": "e6692530-1e7e-4374-beb8-2f15329db49c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "5-FOLD CROSS VALIDATION RESULTS\n",
            "============================================================\n",
            "R² Mean: -2.4861 (±4.4807)\n",
            "MSE Mean: 0.0052 (±0.0020)\n",
            "MAPE Mean: 0.0001 (±0.0000)\n",
            "\n",
            "Individual R² scores: [  0.3688  -0.2553  -1.2842 -11.3763   0.1165]\n",
            "Individual MSE scores: [0.0038 0.0065 0.0063 0.0074 0.002 ]\n",
            "Individual MAPE scores: [4.4712e-05 5.6870e-05 5.1566e-05 6.7652e-05 3.0318e-05]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_all = MultiOutputRegressor(make_pipeline(StandardScaler(), SVR(kernel='rbf', C=10.0, epsilon=0.01, gamma='scale')))\n",
        "model_all.fit(X, Y)\n",
        "Y_all_pred = model_all.predict(X)\n",
        "\n",
        "all_df = pd.DataFrame({\n",
        "    \"Sample\": np.arange(1, n_samples+1),\n",
        "    \"Actual_Mn\": Y[:,0],\n",
        "    \"Actual_Mw\": Y[:,1],\n",
        "    \"Predicted_Mn\": Y_all_pred[:,0],\n",
        "    \"Predicted_Mw\": Y_all_pred[:,1],\n",
        "})\n",
        "all_df[\"Error_Mn\"] = (all_df[\"Actual_Mn\"] - all_df[\"Predicted_Mn\"]).abs()\n",
        "all_df[\"Error_Mw\"] = (all_df[\"Actual_Mw\"] - all_df[\"Predicted_Mw\"]).abs()\n",
        "\n",
        "print(\"\\nActual vs Predicted Comparison (All samples):\")\n",
        "for i, row in all_df.iterrows():\n",
        "    a_mn, a_mw = row[\"Actual_Mn\"], row[\"Actual_Mw\"]\n",
        "    p_mn, p_mw = row[\"Predicted_Mn\"], row[\"Predicted_Mw\"]\n",
        "    print(f\"Sample {int(row['Sample']):2d}: Actual=[ {a_mn:7.2f}, {a_mw:7.2f} ] | Predicted=[ {p_mn:7.2f}, {p_mw:7.2f} ]\")\n",
        "\n",
        "print(\"\\nDetailed Comparison Table:\")\n",
        "print(all_df.to_string(index=False))\n",
        "# ==== end ===="
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IChleMR4EFQ3",
        "outputId": "10271a20-93f8-40b2-b538-4481a9020798"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Actual vs Predicted Comparison (All samples):\n",
            "Sample  1: Actual=[ 1127.19, 1321.65 ] | Predicted=[ 1127.20, 1321.66 ]\n",
            "Sample  2: Actual=[ 1127.20, 1321.66 ] | Predicted=[ 1127.21, 1321.67 ]\n",
            "Sample  3: Actual=[ 1127.21, 1321.67 ] | Predicted=[ 1127.33, 1321.79 ]\n",
            "Sample  4: Actual=[ 1127.22, 1321.68 ] | Predicted=[ 1127.23, 1321.69 ]\n",
            "Sample  5: Actual=[ 1127.23, 1321.69 ] | Predicted=[ 1127.30, 1321.76 ]\n",
            "Sample  6: Actual=[ 1127.24, 1321.70 ] | Predicted=[ 1127.31, 1321.77 ]\n",
            "Sample  7: Actual=[ 1127.25, 1321.71 ] | Predicted=[ 1127.26, 1321.72 ]\n",
            "Sample  8: Actual=[ 1127.26, 1321.72 ] | Predicted=[ 1127.27, 1321.73 ]\n",
            "Sample  9: Actual=[ 1127.27, 1321.73 ] | Predicted=[ 1127.28, 1321.74 ]\n",
            "Sample 10: Actual=[ 1127.28, 1321.74 ] | Predicted=[ 1127.29, 1321.75 ]\n",
            "Sample 11: Actual=[ 1127.29, 1321.75 ] | Predicted=[ 1127.28, 1321.74 ]\n",
            "Sample 12: Actual=[ 1127.30, 1321.76 ] | Predicted=[ 1127.31, 1321.77 ]\n",
            "Sample 13: Actual=[ 1127.31, 1321.77 ] | Predicted=[ 1127.32, 1321.78 ]\n",
            "Sample 14: Actual=[ 1127.32, 1321.78 ] | Predicted=[ 1127.34, 1321.80 ]\n",
            "Sample 15: Actual=[ 1127.33, 1321.79 ] | Predicted=[ 1127.31, 1321.77 ]\n",
            "Sample 16: Actual=[ 1127.34, 1321.80 ] | Predicted=[ 1127.33, 1321.79 ]\n",
            "Sample 17: Actual=[ 1127.35, 1321.81 ] | Predicted=[ 1127.34, 1321.80 ]\n",
            "Sample 18: Actual=[ 1127.36, 1321.82 ] | Predicted=[ 1127.35, 1321.81 ]\n",
            "Sample 19: Actual=[ 1127.37, 1321.83 ] | Predicted=[ 1127.36, 1321.82 ]\n",
            "Sample 20: Actual=[ 1127.38, 1321.84 ] | Predicted=[ 1127.37, 1321.83 ]\n",
            "Sample 21: Actual=[ 1127.39, 1321.85 ] | Predicted=[ 1127.38, 1321.84 ]\n",
            "Sample 22: Actual=[ 1127.40, 1321.86 ] | Predicted=[ 1127.29, 1321.75 ]\n",
            "Sample 23: Actual=[ 1127.41, 1321.87 ] | Predicted=[ 1127.40, 1321.86 ]\n",
            "Sample 24: Actual=[ 1127.42, 1321.88 ] | Predicted=[ 1127.30, 1321.76 ]\n",
            "Sample 25: Actual=[ 1127.43, 1321.89 ] | Predicted=[ 1127.42, 1321.88 ]\n",
            "\n",
            "Detailed Comparison Table:\n",
            " Sample  Actual_Mn  Actual_Mw  Predicted_Mn  Predicted_Mw  Error_Mn  Error_Mw\n",
            "      1    1127.19    1321.65   1127.199959   1321.659959  0.009959  0.009959\n",
            "      2    1127.20    1321.66   1127.210334   1321.670334  0.010334  0.010334\n",
            "      3    1127.21    1321.67   1127.330189   1321.790189  0.120189  0.120189\n",
            "      4    1127.22    1321.68   1127.230125   1321.690125  0.010125  0.010125\n",
            "      5    1127.23    1321.69   1127.297105   1321.757105  0.067105  0.067105\n",
            "      6    1127.24    1321.70   1127.309089   1321.769089  0.069089  0.069089\n",
            "      7    1127.25    1321.71   1127.260441   1321.720441  0.010441  0.010441\n",
            "      8    1127.26    1321.72   1127.270042   1321.730042  0.010042  0.010042\n",
            "      9    1127.27    1321.73   1127.280134   1321.740134  0.010134  0.010134\n",
            "     10    1127.28    1321.74   1127.289654   1321.749654  0.009654  0.009654\n",
            "     11    1127.29    1321.75   1127.279448   1321.739448  0.010552  0.010552\n",
            "     12    1127.30    1321.76   1127.309844   1321.769844  0.009844  0.009844\n",
            "     13    1127.31    1321.77   1127.320125   1321.780125  0.010125  0.010125\n",
            "     14    1127.32    1321.78   1127.340116   1321.800116  0.020116  0.020116\n",
            "     15    1127.33    1321.79   1127.309089   1321.769089  0.020911  0.020911\n",
            "     16    1127.34    1321.80   1127.330189   1321.790189  0.009811  0.009811\n",
            "     17    1127.35    1321.81   1127.340116   1321.800116  0.009884  0.009884\n",
            "     18    1127.36    1321.82   1127.349577   1321.809577  0.010423  0.010423\n",
            "     19    1127.37    1321.83   1127.360067   1321.820067  0.009933  0.009933\n",
            "     20    1127.38    1321.84   1127.370311   1321.830311  0.009689  0.009689\n",
            "     21    1127.39    1321.85   1127.379637   1321.839637  0.010363  0.010363\n",
            "     22    1127.40    1321.86   1127.289654   1321.749654  0.110346  0.110346\n",
            "     23    1127.41    1321.87   1127.399985   1321.859985  0.010015  0.010015\n",
            "     24    1127.42    1321.88   1127.297105   1321.757105  0.122895  0.122895\n",
            "     25    1127.43    1321.89   1127.420013   1321.880013  0.009987  0.009987\n"
          ]
        }
      ]
    }
  ]
}